var documenterSearchIndex = {"docs":
[{"location":"showcase/missing_physics/#autocomplete","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"One of the most time-consuming parts of modeling is building the model. How do you know when your model is correct? When you solve an inverse problem to calibrate your model to data, who you gonna call if there are no parameters that make the model the data? This is the problem that the Universal Differential Equation (UDE) approach solves: the ability to start from the model you have, and suggest minimal mechanistic extensions that would allow the model to fit the data. In this showcase, we will show how to take a partially correct model and auto-complete it to find the missing physics.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"note: Note\nFor a scientific background on the universal differential equation approach, check out Universal Differential Equations for Scientific Machine Learning","category":"page"},{"location":"showcase/missing_physics/#Starting-Point:-The-Packages-To-Use","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Starting Point: The Packages To Use","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"There are many packages which are used as part of this showcase. Let's detail what they are and how they are used. For the neural network training:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Module Description\nOrdinaryDiffEq.jl (DifferentialEquations.jl) The numerical differential equation solvers\nSciMLSensitivity.jl The adjoint methods, defines gradients of ODE solvers\nOptimization.jl The optimization library\nOptimizationOptimisers.jl The optimization solver package with Adam\nOptimizationOptimJL.jl The optimization solver package with LBFGS\nLineSearches.jl Line search algorithms package to be used with LBFGS","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"For the symbolic model discovery:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Module Description\nModelingToolkit.jl The symbolic modeling environment\nDataDrivenDiffEq.jl The symbolic regression interface\nDataDrivenSparse.jl The sparse regression symbolic regression solvers\nZygote.jl The automatic differentiation library for fast gradients","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Julia standard libraries:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Module Description\nLinearAlgebra Required for the norm function\nStatistics Required for the mean function","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"And external libraries:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Module Description\nLux.jl The deep learning (neural network) framework\nComponentArrays.jl For the ComponentArray type to match Lux to SciML\nPlots.jl The plotting and visualization library\nStableRNGs.jl Stable random seeding","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"note: Note\nThe deep learning framework Flux.jl could be used in place of Lux, though most tutorials in SciML generally prefer Lux.jl due to its explicit parameter interface, leading to nicer code. Both share the same internal implementations of core kernels, and thus have very similar feature support and performance.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# SciML Tools\nusing OrdinaryDiffEq, ModelingToolkit, DataDrivenDiffEq, SciMLSensitivity, DataDrivenSparse\nusing Optimization, OptimizationOptimisers, OptimizationOptimJL, LineSearches\n\n# Standard Libraries\nusing LinearAlgebra, Statistics\n\n# External Libraries\nusing ComponentArrays, Lux, Zygote, Plots, StableRNGs\ngr()\n\n# Set a random seed for reproducible behaviour\nrng = StableRNG(1111)","category":"page"},{"location":"showcase/missing_physics/#Problem-Setup","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Problem Setup","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"In order to know that we have automatically discovered the correct model, we will use generated data from a known model. This model will be the Lotka-Volterra equations. These equations are given by:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"beginaligned\nfracdxdt = alpha x - beta x y      \nfracdydt = -delta y + gamma x y    \nendaligned","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"This is a model of rabbits and wolves. alpha x is the exponential growth of rabbits in isolation, -beta x y and gamma x y are the interaction effects of wolves eating rabbits, and -delta y is the term for how wolves die hungry in isolation.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now assume that we have never seen rabbits and wolves in the same room. We only know the two effects alpha x and -delta y. Can we use Scientific Machine Learning to automatically discover an extension to what we already know? That is what we will solve with the universal differential equation.","category":"page"},{"location":"showcase/missing_physics/#Generating-the-Training-Data","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Generating the Training Data","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"First, let's generate training data from the Lotka-Volterra equations. This is straightforward and standard DifferentialEquations.jl usage. Our sample data is thus generated as follows:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"function lotka!(du, u, p, t)\n    α, β, γ, δ = p\n    du[1] = α * u[1] - β * u[2] * u[1]\n    du[2] = γ * u[1] * u[2] - δ * u[2]\nend\n\n# Define the experimental parameter\ntspan = (0.0, 5.0)\nu0 = 5.0f0 * rand(rng, 2)\np_ = [1.3, 0.9, 0.8, 1.8]\nprob = ODEProblem(lotka!, u0, tspan, p_)\nsolution = solve(prob, Vern7(), abstol = 1e-12, reltol = 1e-12, saveat = 0.25)\n\n# Add noise in terms of the mean\nX = Array(solution)\nt = solution.t\n\nx̄ = mean(X, dims = 2)\nnoise_magnitude = 5e-3\nXₙ = X .+ (noise_magnitude * x̄) .* randn(rng, eltype(X), size(X))\n\nplot(solution, alpha = 0.75, color = :black, label = [\"True Data\" nothing])\nscatter!(t, transpose(Xₙ), color = :red, label = [\"Noisy Data\" nothing])","category":"page"},{"location":"showcase/missing_physics/#Definition-of-the-Universal-Differential-Equation","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Definition of the Universal Differential Equation","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now let's define our UDE. We will use Lux.jl to define the neural network as follows:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"rbf(x) = exp.(-(x .^ 2))\n\n# Multilayer FeedForward\nconst U = Lux.Chain(Lux.Dense(2, 5, rbf), Lux.Dense(5, 5, rbf), Lux.Dense(5, 5, rbf),\n    Lux.Dense(5, 2))\n# Get the initial parameters and state variables of the model\np, st = Lux.setup(rng, U)\nconst _st = st","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"We then define the UDE as a dynamical system that is u' = known(u) + NN(u) like:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# Define the hybrid model\nfunction ude_dynamics!(du, u, p, t, p_true)\n    û = U(u, p, _st)[1] # Network prediction\n    du[1] = p_true[1] * u[1] + û[1]\n    du[2] = -p_true[4] * u[2] + û[2]\nend\n\n# Closure with the known parameter\nnn_dynamics!(du, u, p, t) = ude_dynamics!(du, u, p, t, p_)\n# Define the problem\nprob_nn = ODEProblem(nn_dynamics!, Xₙ[:, 1], tspan, p)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Notice that the most important part of this is that the neural network does not have hard-coded weights. The weights of the neural network are the parameters of the ODE system. This means that if we change the parameters of the ODE system, then we will have updated the internal neural networks to new weights. Keep that in mind for the next part.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"... and tada: now we have a neural network integrated into our dynamical system!","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"note: Note\nEven if the known physics is only approximate or correct, it can be helpful to improve the fitting process! Check out this JuliaCon talk which dives into this issue.","category":"page"},{"location":"showcase/missing_physics/#Setting-Up-the-Training-Loop","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Setting Up the Training Loop","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now let's build a training loop around our UDE. First, let's make a function predict which runs our simulation at new neural network weights. Recall that the weights of the neural network are the parameters of the ODE, so what we need to do in predict is update our ODE to our new parameters and then run it.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"For this update step, we will use the remake function from the SciMLProblem interface. remake works by specifying key = value pairs to update in the problem fields. Thus to update u0, we would add a keyword argument u0 = .... To update the parameters, we'd do p = .... The field names can be acquired from the problem documentation (or the docstrings!).","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Knowing this, our predict function looks like:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"function predict(θ, X = Xₙ[:, 1], T = t)\n    _prob = remake(prob_nn, u0 = X, tspan = (T[1], T[end]), p = θ)\n    Array(solve(_prob, Vern7(), saveat = T,\n        abstol = 1e-6, reltol = 1e-6,\n        sensealg = QuadratureAdjoint(autojacvec = ReverseDiffVJP(true))))\nend","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"There are many choices for the combination of sensitivity algorithm and automatic differentiation library (see Choosing a Sensitivity Algorithm. For example, you could have used sensealg=ForwardDiffSensitivity().","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now, for our loss function, we solve the ODE at our new parameters and check its L2 loss against the dataset. Using our predict function, this looks like:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"function loss(θ)\n    X̂ = predict(θ)\n    mean(abs2, Xₙ .- X̂)\nend","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Lastly, what we will need to track our optimization is to define a callback as defined by the OptimizationProblem's solve interface. Because our function only returns one value, the loss l, the callback will be a function of the current parameters θ and l. Let's setup a callback prints every 50 steps the current loss:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"losses = Float64[]\n\ncallback = function (state, l)\n    push!(losses, l)\n    if length(losses) % 50 == 0\n        println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n    end\n    return false\nend","category":"page"},{"location":"showcase/missing_physics/#Training","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Training","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now we're ready to train! To run the training process, we will need to build an OptimizationProblem. Because we have a lot of parameters, we will use Zygote.jl. Optimization.jl makes the choice of automatic differentiation easy, just by specifying an adtype in the OptimizationFunction construction","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Knowing this, we can build our OptimizationProblem as follows:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, ComponentVector{Float64}(p))","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now... we optimize it. We will use a mixed strategy. First, let's do some iterations of ADAM because it's better at finding a good general area of parameter space, but then we will move to BFGS which will quickly hone in on a local minimum. Note that if we only use ADAM it will take a ton of iterations, and if we only use BFGS we normally end up in a bad local minimum, so this combination tends to be a good one for UDEs.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Thus we first solve the optimization problem with ADAM. Choosing a learning rate of 0.1 (tuned to be as high as possible that doesn't tend to make the loss shoot up), we see:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"res1 = Optimization.solve(\n    optprob, OptimizationOptimisers.Adam(), callback = callback, maxiters = 5000)\nprintln(\"Training loss after $(length(losses)) iterations: $(losses[end])\")","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now we use the optimization result of the first run as the initial condition of the second optimization, and run it with BFGS. This looks like:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"optprob2 = Optimization.OptimizationProblem(optf, res1.u)\nres2 = Optimization.solve(\n    optprob2, LBFGS(linesearch = BackTracking()), callback = callback, maxiters = 1000)\nprintln(\"Final training loss after $(length(losses)) iterations: $(losses[end])\")\n\n# Rename the best candidate\np_trained = res2.u","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"and bingo, we have a trained UDE.","category":"page"},{"location":"showcase/missing_physics/#Visualizing-the-Trained-UDE","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Visualizing the Trained UDE","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"How well did our neural network do? Let's take a look:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# Plot the losses\npl_losses = plot(1:5000, losses[1:5000], yaxis = :log10, xaxis = :log10,\n    xlabel = \"Iterations\", ylabel = \"Loss\", label = \"ADAM\", color = :blue)\nplot!(5001:length(losses), losses[5001:end], yaxis = :log10, xaxis = :log10,\n    xlabel = \"Iterations\", ylabel = \"Loss\", label = \"LBFGS\", color = :red)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Next, we compare the original data to the output of the UDE predictor. Note that we can even create more samples from the underlying model by simply adjusting the time steps!","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"## Analysis of the trained network\n# Plot the data and the approximation\nts = first(solution.t):(mean(diff(solution.t)) / 2):last(solution.t)\nX̂ = predict(p_trained, Xₙ[:, 1], ts)\n# Trained on noisy data vs real solution\npl_trajectory = plot(ts, transpose(X̂), xlabel = \"t\", ylabel = \"x(t), y(t)\", color = :red,\n    label = [\"UDE Approximation\" nothing])\nscatter!(solution.t, transpose(Xₙ), color = :black, label = [\"Measurements\" nothing])","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Let's see how well the unknown term has been approximated:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# Ideal unknown interactions of the predictor\nȲ = [-p_[2] * (X̂[1, :] .* X̂[2, :])'; p_[3] * (X̂[1, :] .* X̂[2, :])']\n# Neural network guess\nŶ = U(X̂, p_trained, st)[1]\n\npl_reconstruction = plot(ts, transpose(Ŷ), xlabel = \"t\", ylabel = \"U(x,y)\", color = :red,\n    label = [\"UDE Approximation\" nothing])\nplot!(ts, transpose(Ȳ), color = :black, label = [\"True Interaction\" nothing])","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"And have a nice look at all the information:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# Plot the error\npl_reconstruction_error = plot(ts, norm.(eachcol(Ȳ - Ŷ)), yaxis = :log, xlabel = \"t\",\n    ylabel = \"L2-Error\", label = nothing, color = :red)\npl_missing = plot(pl_reconstruction, pl_reconstruction_error, layout = (2, 1))\n\npl_overall = plot(pl_trajectory, pl_missing)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"That looks pretty good. And if we are happy with deep learning, we can leave it at that: we have trained a neural network to capture our missing dynamics.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"But...","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Can we also make it print out the LaTeX for what the missing equations were? Find out more after the break!","category":"page"},{"location":"showcase/missing_physics/#Symbolic-regression-via-sparse-regression-(SINDy-based)","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Symbolic regression via sparse regression (SINDy based)","text":"","category":"section"},{"location":"showcase/missing_physics/#This-part-of-the-showcase-is-still-a-work-in-progress...-shame-on-us.-But-be-back-in-a-jiffy-and-we'll-have-it-done.","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"This part of the showcase is still a work in progress... shame on us. But be back in a jiffy and we'll have it done.","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Okay, that was a quick break, and that's good because this next part is pretty cool. Let's use DataDrivenDiffEq.jl to transform our trained neural network from machine learning mumbo jumbo into predictions of missing mechanistic equations. To do this, we first generate a symbolic basis that represents the space of mechanistic functions we believe this neural network should map to. Let's choose a bunch of polynomial functions:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"@variables u[1:2]\nb = polynomial_basis(u, 4)\nbasis = Basis(b, u);","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now let's define our DataDrivenProblems for the sparse regressions. To assess the capability of the sparse regression, we will look at 3 cases:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"What if we trained no neural network and tried to automatically uncover the equations from the original noisy data? This is the approach in the literature known as structural identification of dynamical systems (SINDy). We will call this the full problem. This will assess whether this incorporation of prior information was helpful.\nWhat if we trained the neural network using the ideal right-hand side missing derivative functions? This is the value computed in the plots above as Ȳ. This will tell us whether the symbolic discovery could work in ideal situations.\nDo the symbolic regression directly on the function y = NN(x), i.e. the trained learned neural network. This is what we really want, and will tell us how to extend our known equations.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"To define the full problem, we need to define a DataDrivenProblem that has the time series of the solution X, the time points of the solution t, and the derivative at each time point of the solution, obtained by the ODE solution's interpolation. We can just use an interpolation to get the derivative:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"full_problem = ContinuousDataDrivenProblem(Xₙ, t)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Now for the other two symbolic regressions, we are regressing input/outputs of the missing terms, and thus we directly define the datasets as the input/output mappings like:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"ideal_problem = DirectDataDrivenProblem(X̂, Ȳ)\nnn_problem = DirectDataDrivenProblem(X̂, Ŷ)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Let's solve the data-driven problems using sparse regression. We will use the ADMM method, which requires we define a set of shrinking cutoff values λ, and we do this like:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"λ = 1e-1\nopt = ADMM(λ)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"This is one of many methods for sparse regression, consult the DataDrivenDiffEq.jl documentation for more information on the algorithm choices. Taking this, let's solve each of the sparse regressions:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"options = DataDrivenCommonOptions(maxiters = 10_000,\n    normalize = DataNormalization(ZScoreTransform),\n    selector = bic, digits = 1,\n    data_processing = DataProcessing(split = 0.9,\n        batchsize = 30,\n        shuffle = true,\n        rng = StableRNG(1111)))\n\nfull_res = solve(full_problem, basis, opt, options = options)\nfull_eqs = get_basis(full_res)\nprintln(full_res)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"options = DataDrivenCommonOptions(maxiters = 10_000,\n    normalize = DataNormalization(ZScoreTransform),\n    selector = bic, digits = 1,\n    data_processing = DataProcessing(split = 0.9,\n        batchsize = 30,\n        shuffle = true,\n        rng = StableRNG(1111)))\n\nideal_res = solve(ideal_problem, basis, opt, options = options)\nideal_eqs = get_basis(ideal_res)\nprintln(ideal_res)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"options = DataDrivenCommonOptions(maxiters = 10_000,\n    normalize = DataNormalization(ZScoreTransform),\n    selector = bic, digits = 1,\n    data_processing = DataProcessing(split = 0.9,\n        batchsize = 30,\n        shuffle = true,\n        rng = StableRNG(1111)))\n\nnn_res = solve(nn_problem, basis, opt, options = options)\nnn_eqs = get_basis(nn_res)\nprintln(nn_res)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Note that we passed the identical options into each of the solve calls to get the same data for each call.","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"We already saw that the full problem has failed to identify the correct equations of motion. To have a closer look, we can inspect the corresponding equations:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"for eqs in (full_eqs, ideal_eqs, nn_eqs)\n    println(eqs)\n    println(get_parameter_map(eqs))\n    println()\nend","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"Next, we want to predict with our model. To do so, we embed the basis into a function like before:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# Define the recovered, hybrid model\nfunction recovered_dynamics!(du, u, p, t)\n    û = nn_eqs(u, p) # Recovered equations\n    du[1] = p_[1] * u[1] + û[1]\n    du[2] = -p_[4] * u[2] + û[2]\nend\n\nestimation_prob = ODEProblem(recovered_dynamics!, u0, tspan, get_parameter_values(nn_eqs))\nestimate = solve(estimation_prob, Tsit5(), saveat = solution.t)\n\n# Plot\nplot(solution)\nplot!(estimate)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"We are still a bit off, so we fine tune the parameters by simply minimizing the residuals between the UDE predictor and our recovered parametrized equations:","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"function parameter_loss(p)\n    Y = reduce(hcat, map(Base.Fix2(nn_eqs, p), eachcol(X̂)))\n    sum(abs2, Ŷ .- Y)\nend\n\noptf = Optimization.OptimizationFunction((x, p) -> parameter_loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, get_parameter_values(nn_eqs))\nparameter_res = Optimization.solve(optprob, Optim.LBFGS(), maxiters = 1000)","category":"page"},{"location":"showcase/missing_physics/#Simulation","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Simulation","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"# Look at long term prediction\nt_long = (0.0, 50.0)\nestimation_prob = ODEProblem(recovered_dynamics!, u0, t_long, parameter_res)\nestimate_long = solve(estimation_prob, Tsit5(), saveat = 0.1) # Using higher tolerances here results in exit of julia\nplot(estimate_long)","category":"page"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"true_prob = ODEProblem(lotka!, u0, t_long, p_)\ntrue_solution_long = solve(true_prob, Tsit5(), saveat = estimate_long.t)\nplot!(true_solution_long)","category":"page"},{"location":"showcase/missing_physics/#Post-Processing-and-Plots","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Post Processing and Plots","text":"","category":"section"},{"location":"showcase/missing_physics/","page":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","title":"Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations","text":"c1 = 3 # RGBA(174/255,192/255,201/255,1) # Maroon\nc2 = :orange # RGBA(132/255,159/255,173/255,1) # Red\nc3 = :blue # RGBA(255/255,90/255,0,1) # Orange\nc4 = :purple # RGBA(153/255,50/255,204/255,1) # Purple\n\np1 = plot(t, abs.(Array(solution) .- estimate)' .+ eps(Float32),\n    lw = 3, yaxis = :log, title = \"Timeseries of UODE Error\",\n    color = [3 :orange], xlabel = \"t\",\n    label = [\"x(t)\" \"y(t)\"],\n    titlefont = \"Helvetica\", legendfont = \"Helvetica\",\n    legend = :topright)\n\n# Plot L₂\np2 = plot3d(X̂[1, :], X̂[2, :], Ŷ[2, :], lw = 3,\n    title = \"Neural Network Fit of U2(t)\", color = c1,\n    label = \"Neural Network\", xaxis = \"x\", yaxis = \"y\",\n    titlefont = \"Helvetica\", legendfont = \"Helvetica\",\n    legend = :bottomright)\nplot!(X̂[1, :], X̂[2, :], Ȳ[2, :], lw = 3, label = \"True Missing Term\", color = c2)\n\np3 = scatter(solution, color = [c1 c2], label = [\"x data\" \"y data\"],\n    title = \"Extrapolated Fit From Short Training Data\",\n    titlefont = \"Helvetica\", legendfont = \"Helvetica\",\n    markersize = 5)\n\nplot!(p3, true_solution_long, color = [c1 c2], linestyle = :dot, lw = 5,\n    label = [\"True x(t)\" \"True y(t)\"])\nplot!(p3, estimate_long, color = [c3 c4], lw = 1,\n    label = [\"Estimated x(t)\" \"Estimated y(t)\"])\nplot!(p3, [2.99, 3.01], [0.0, 10.0], lw = 1, color = :black, label = nothing)\nannotate!([(1.5, 13, text(\"Training \\nData\", 10, :center, :top, :black, \"Helvetica\"))])\nl = @layout [grid(1, 2)\n             grid(1, 1)]\nplot(p1, p2, p3, layout = l)","category":"page"},{"location":"highlevels/function_approximation/#Function-Approximation","page":"Function Approximation","title":"Function Approximation","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"While SciML is not an ecosystem for machine learning, SciML has many libraries for doing machine learning with its equation solver libraries and machine learning libraries which are integrated into the equation solvers.","category":"page"},{"location":"highlevels/function_approximation/#Surrogates.jl:-Easy-Generation-of-Differentiable-Surrogate-Models","page":"Function Approximation","title":"Surrogates.jl: Easy Generation of Differentiable Surrogate Models","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"Surrogates.jl is a library for generating surrogate approximations to computationally expensive simulations. It has the following high-dimensional function approximators:","category":"page"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"Kriging\nKriging using Stheno\nRadial Basis\nWendland\nLinear\nSecond Order Polynomial\nSupport Vector Machines (Wait for LIBSVM resolution)\nNeural Networks\nRandom Forests\nLobachevsky splines\nInverse-distance\nPolynomial expansions\nVariable fidelity\nMixture of experts (Waiting GaussianMixtures package to work on v1.5)\nEarth\nGradient Enhanced Kriging","category":"page"},{"location":"highlevels/function_approximation/#ReservoirComputing.jl:-Fast-and-Flexible-Reservoir-Computing-Methods","page":"Function Approximation","title":"ReservoirComputing.jl: Fast and Flexible Reservoir Computing Methods","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"ReservoirComputing.jl is a library for doing machine learning using reservoir computing techniques, such as with methods like Echo State Networks (ESNs). Its reservoir computing methods make it stabilized for usage with difficult equations like stiff dynamics, chaotic equations, and more.","category":"page"},{"location":"highlevels/function_approximation/#Third-Party-Libraries-to-Note","page":"Function Approximation","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/function_approximation/#Flux.jl:-the-ML-library-that-doesn't-make-you-tensor","page":"Function Approximation","title":"Flux.jl: the ML library that doesn't make you tensor","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"Flux.jl is the most popular machine learning library in the Julia programming language. SciML's libraries are heavily tested with it and its automatic differentiation engine Zygote.jl for composability and compatibility.","category":"page"},{"location":"highlevels/function_approximation/#Lux.jl:-Explicitly-Parameterized-Neural-Networks-in-Julia","page":"Function Approximation","title":"Lux.jl: Explicitly Parameterized Neural Networks in Julia","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"Lux.jl is a library for fully explicitly parameterized neural networks. Thus, while alternative interfaces are required to use Flux with many equation solvers (i.e. Flux.destructure), Lux.jl's explicit design marries effortlessly with the SciML equation solver libraries. For this reason, SciML's library are also heavily tested with Lux to ensure compatibility with neural network definitions from here.","category":"page"},{"location":"highlevels/function_approximation/#SimpleChains.jl:-Fast-Small-Scale-Machine-Learning","page":"Function Approximation","title":"SimpleChains.jl: Fast Small-Scale Machine Learning","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"SimpleChains.jl is a library specialized for small-scale machine learning. It uses non-allocating mutating forms to be highly efficient for the cases where matrix multiplication kernels cannot overcome the common overheads of machine learning libraries. Thus for SciML cases with small neural networks (<100 node layers) and non-batched usage (many/most use cases), SimpleChains.jl can be the fastest choice for the neural network definitions.","category":"page"},{"location":"highlevels/function_approximation/#NNLib.jl:-Neural-Network-Primitives-with-Multiple-Backends","page":"Function Approximation","title":"NNLib.jl: Neural Network Primitives with Multiple Backends","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"NNLib.jl is the core library which defines the handling of common functions, like conv and how they map to device accelerators such as the NVIDIA cudnn. This library can thus be used to directly grab many of the core functions used in machine learning, such as common activation functions and gather/scatter operations, without depending on the given style of any machine learning library.","category":"page"},{"location":"highlevels/function_approximation/#GeometricFlux.jl:-Geometric-Deep-Learning-and-Graph-Neural-Networks","page":"Function Approximation","title":"GeometricFlux.jl: Geometric Deep Learning and Graph Neural Networks","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"GeometricFlux.jl is a library for graph neural networks and geometric deep learning. It is the one that is used and tested by the SciML developers for mixing with equation solver applications.","category":"page"},{"location":"highlevels/function_approximation/#AbstractGPs.jl:-Fast-and-Flexible-Gaussian-Processes","page":"Function Approximation","title":"AbstractGPs.jl: Fast and Flexible Gaussian Processes","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"AbstractGPs.jl is the fast and flexible Gaussian Process library that is used by the SciML packages and recommended for downstream usage.","category":"page"},{"location":"highlevels/function_approximation/#MLDatasets.jl:-Common-Machine-Learning-Datasets","page":"Function Approximation","title":"MLDatasets.jl: Common Machine Learning Datasets","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"MLDatasets.jl  is a common interface for accessing common machine learning datasets. For example, if you want to run a test on MNIST data, MLDatasets is the quickest way to obtain it.","category":"page"},{"location":"highlevels/function_approximation/#MLUtils.jl:-Utility-Functions-for-Machine-Learning-Pipelines","page":"Function Approximation","title":"MLUtils.jl: Utility Functions for Machine Learning Pipelines","text":"","category":"section"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"MLUtils.jl is a library of utility functions for making writing common machine learning pipelines easier. This includes functionality for:","category":"page"},{"location":"highlevels/function_approximation/","page":"Function Approximation","title":"Function Approximation","text":"An extensible dataset interface  (numobs and getobs).\nData iteration and data loaders (eachobs and DataLoader).\nLazy data views (obsview).\nResampling procedures (undersample and oversample).\nTrain/test splits (splitobs)\nData partitioning and aggregation tools (batch, unbatch, chunk, group_counts, group_indices).\nFolds for cross-validation (kfolds, leavepout).\nDatasets lazy transformations (mapobs, filterobs, groupobs, joinobs, shuffleobs).\nToy datasets for demonstration purpose.\nOther data handling utilities (flatten, normalise, unsqueeze, stack, unstack).","category":"page"},{"location":"highlevels/interfaces/#The-SciML-Interface-Libraries","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"","category":"section"},{"location":"highlevels/interfaces/#SciMLBase.jl:-The-SciML-Common-Interface","page":"The SciML Interface Libraries","title":"SciMLBase.jl: The SciML Common Interface","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"SciMLBase.jl defines the core interfaces of the SciML libraries, such as the definitions of abstract types like SciMLProblem, along with their instantiations like ODEProblem. While SciMLBase.jl is insufficient to solve any equations, it holds all the equation definitions, and thus downstream libraries which wish to allow for using SciML solvers without depending on any solvers can directly depend on SciMLBase.jl.","category":"page"},{"location":"highlevels/interfaces/#SciMLOperators.jl:-The-AbstractSciMLOperator-Interface","page":"The SciML Interface Libraries","title":"SciMLOperators.jl: The AbstractSciMLOperator Interface","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"SciMLOperators.jl defines the interface for how matrix-free linear and affine operators are defined and used throughout the SciML ecosystem.","category":"page"},{"location":"highlevels/interfaces/#DiffEqNoiseProcess.jl:-The-SciML-Common-Noise-Interface","page":"The SciML Interface Libraries","title":"DiffEqNoiseProcess.jl: The SciML Common Noise Interface","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"DiffEqNoiseProcess.jl defines the common interface for stochastic noise processes used by the equation solvers of the SciML ecosystem.","category":"page"},{"location":"highlevels/interfaces/#CommonSolve.jl:-The-Common-Definition-of-Solve","page":"The SciML Interface Libraries","title":"CommonSolve.jl: The Common Definition of Solve","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"CommonSolve.jl is the library that defines the solve, solve!, and init interfaces which are used throughout all the SciML equation solvers. It's defined as an extremely lightweight library so that other ecosystems can build on the same solve definition without clashing with SciML when both export.","category":"page"},{"location":"highlevels/interfaces/#Static.jl:-A-Shared-Interface-for-Static-Compile-Time-Computation","page":"The SciML Interface Libraries","title":"Static.jl: A Shared Interface for Static Compile-Time Computation","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"Static.jl is a set of statically parameterized types for performing operations in a statically-defined (compiler-optimized) way with respect to values.","category":"page"},{"location":"highlevels/interfaces/#DiffEqBase.jl:-A-Library-of-Shared-Components-for-Differential-Equation-Solvers","page":"The SciML Interface Libraries","title":"DiffEqBase.jl: A Library of Shared Components for Differential Equation Solvers","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"DiffEqBase.jl is the core shared component of the DifferentialEquations.jl ecosystem. It's not intended for non-developer users to interface directly with, instead it's used for the common functionality for uniformity of implementation between the solver libraries.","category":"page"},{"location":"highlevels/interfaces/#Third-Party-Libraries-to-Note","page":"The SciML Interface Libraries","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/interfaces/#ArrayInterface.jl:-Extensions-to-the-Julia-AbstractArray-Interface","page":"The SciML Interface Libraries","title":"ArrayInterface.jl: Extensions to the Julia AbstractArray Interface","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"ArrayInterface.jl are traits and functions which extend the Julia Base AbstractArray interface, giving a much larger set of queries to allow for writing high-performance generic code over all array types. For example, functions include can_change_size to know if an AbstractArray type is compatible with resize!, fast_scalar_indexing to know whether direct scalar indexing A[i] is optimized, and functions like findstructralnz to get the structural non-zeros of arbitrary sparse and structured matrices.","category":"page"},{"location":"highlevels/interfaces/#Adapt.jl:-Conversion-to-Allow-Chip-Generic-Programs","page":"The SciML Interface Libraries","title":"Adapt.jl: Conversion to Allow Chip-Generic Programs","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"Adapt.jl makes it possible to write code that is generic to the compute devices, i.e. code that works on both CPUs and GPUs. It defines the adapt function which acts like convert(T, x), but without the restriction of returning a T. This allows you to “convert” wrapper types, like Adjoint to be GPU compatible (for example) without throwing away the wrapper.","category":"page"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"Example usage:","category":"page"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"adapt(CuArray, ::Adjoint{Array})::Adjoint{CuArray}","category":"page"},{"location":"highlevels/interfaces/#AbstractFFTs.jl:-High-Level-Shared-Interface-for-Fast-Fourier-Transformation-Libraries","page":"The SciML Interface Libraries","title":"AbstractFFTs.jl: High Level Shared Interface for Fast Fourier Transformation Libraries","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"AbstractFFTs.jl defines the common interface for Fast Fourier Transformations (FFTs) in Julia. Similar to SciMLBase.jl, AbstractFFTs.jl is not a solver library but instead a shared API which is extended by solver libraries such as FFTW.jl. Code written using AbstractFFTs.jl can be made compatible with FFT libraries without having an explicit dependency on a solver.","category":"page"},{"location":"highlevels/interfaces/#GPUArrays.jl:-Common-Interface-for-GPU-Based-Array-Types","page":"The SciML Interface Libraries","title":"GPUArrays.jl: Common Interface for GPU-Based Array Types","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"GPUArrays.jl defines the shared higher-level operations for GPU-based array types, like CUDA.jl's CuArray and AMDGPU.jl's ROCmArray. Packages in SciML use the designation x isa AbstractGPUArray in order to find out if a user's operation is on the GPU and specialize computations.","category":"page"},{"location":"highlevels/interfaces/#RecipesBase.jl:-Standard-Plotting-Recipe-Interface","page":"The SciML Interface Libraries","title":"RecipesBase.jl: Standard Plotting Recipe Interface","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"RecipesBase.jl defines the common interface for plotting recipes, composable transformations of Julia data types into simpler data types for visualization with libraries such as Plots.jl and Makie.jl. SciML libraries attempt to always include plot recipes wherever possible for ease of visualization.","category":"page"},{"location":"highlevels/interfaces/#Tables.jl:-Common-Interface-for-Tabular-Data-Types","page":"The SciML Interface Libraries","title":"Tables.jl: Common Interface for Tabular Data Types","text":"","category":"section"},{"location":"highlevels/interfaces/","page":"The SciML Interface Libraries","title":"The SciML Interface Libraries","text":"Tables.jl is a common interface for defining tabular data structures, such as DataFrames.jl. SciML's libraries extend the Tables.jl interface to allow for automated conversions into data frame libraries without explicit dependence on any singular implementation.","category":"page"},{"location":"highlevels/parameter_analysis/#Parameter-Analysis-Utilities","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"","category":"section"},{"location":"highlevels/parameter_analysis/#GlobalSensitivity.jl:-Global-Sensitivity-Analysis","page":"Parameter Analysis Utilities","title":"GlobalSensitivity.jl: Global Sensitivity Analysis","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"Derivatives calculate the local sensitivity of a model, i.e. the change in the simulation's outcome if one were to change the parameter with respect to some chosen part of the parameter space. But how does a simulation's output change “in general” with respect to a given parameter? That is what global sensitivity analysis (GSA) computes, and thus GlobalSensitivity.jl is the way to answer that question. GlobalSensitivity.jl includes a wide array of methods, including:","category":"page"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"Morris's method\nSobol's method\nRegression methods (PCC, SRC, Pearson)\neFAST\nDelta Moment-Independent method\nDerivative-based Global Sensitivity Measures (DGSM)\nEASI\nFractional Factorial method\nRandom Balance Design FAST method","category":"page"},{"location":"highlevels/parameter_analysis/#StructuralIdentifiability.jl:-Identifiability-Analysis-Made-Simple","page":"Parameter Analysis Utilities","title":"StructuralIdentifiability.jl: Identifiability Analysis Made Simple","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"Performing parameter estimation from a data set means attempting to recover parameters like reaction rates by fitting some model to the data. But how do you know whether you have enough data to even consider getting the “correct” parameters back? StructuralIdentifiability.jl allows for running a structural identifiability analysis on a given model to determine whether it's theoretically possible to recover the correct parameters. It can state whether a given type of output data can be used to globally recover the parameters (i.e. only a unique parameter set for the model produces a given output), whether the parameters are only locally identifiable (i.e. there are finitely many parameter sets which could generate the seen data), or whether it's unidentifiable (there are infinitely many parameters which generate the same output data).","category":"page"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"For more information on what StructuralIdentifiability.jl is all about, see the SciMLCon 2022 tutorial video.","category":"page"},{"location":"highlevels/parameter_analysis/#MinimallyDisruptiveCurves.jl","page":"Parameter Analysis Utilities","title":"MinimallyDisruptiveCurves.jl","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"MinimallyDisruptiveCurves.jl is a library for finding relationships between parameters of models, finding the curves on which the solution is constant.","category":"page"},{"location":"highlevels/parameter_analysis/#Third-Party-Libraries-to-Note","page":"Parameter Analysis Utilities","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/parameter_analysis/#SIAN.jl:-Structural-Identifiability-Analyzer","page":"Parameter Analysis Utilities","title":"SIAN.jl: Structural Identifiability Analyzer","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"SIAN.jl is a structural identifiability analysis package which uses an entirely different algorithm from StructuralIdentifiability.jl. For information on the differences between the two approaches, see the Structural Identifiability Tools in Julia tutorial.","category":"page"},{"location":"highlevels/parameter_analysis/#DynamicalSystems.jl:-A-Suite-of-Dynamical-Systems-Analysis","page":"Parameter Analysis Utilities","title":"DynamicalSystems.jl: A Suite of Dynamical Systems Analysis","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"DynamicalSystems.jl is an entire ecosystem of dynamical systems analysis methods, for computing measures of chaos (dimension estimation, Lyapunov coefficients), generating delay embeddings, and much more. It uses the SciML tools for its internal equation solving and thus shares much of its API, adding a layer of new tools for extended analyses.","category":"page"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"For more information, watch the tutorial Introduction to DynamicalSystems.jl.","category":"page"},{"location":"highlevels/parameter_analysis/#BifurcationKit.jl","page":"Parameter Analysis Utilities","title":"BifurcationKit.jl","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"BifurcationKit.jl is a tool for performing bifurcation analysis. It uses and composes with many SciML equation solvers.","category":"page"},{"location":"highlevels/parameter_analysis/#ReachabilityAnalysis.jl","page":"Parameter Analysis Utilities","title":"ReachabilityAnalysis.jl","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"ReachabilityAnalysis.jl is a library for performing reachability analysis of dynamical systems, determining for a given uncertainty interval the full set of possible outcomes from a dynamical system.","category":"page"},{"location":"highlevels/parameter_analysis/#ControlSystems.jl","page":"Parameter Analysis Utilities","title":"ControlSystems.jl","text":"","category":"section"},{"location":"highlevels/parameter_analysis/","page":"Parameter Analysis Utilities","title":"Parameter Analysis Utilities","text":"ControlSystems.jl is a library for building and analyzing control systems.","category":"page"},{"location":"showcase/optimization_under_uncertainty/#optimization_under_uncertainty","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"","category":"section"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"This tutorial showcases how to leverage the efficient Koopman expectation method from SciMLExpectations to perform optimization under uncertainty. We demonstrate this by using a bouncing ball model with an uncertain model parameter. We also demonstrate its application to problems with probabilistic constraints, in particular a special class of constraints called chance constraints.","category":"page"},{"location":"showcase/optimization_under_uncertainty/#System-Model","page":"Optimization Under Uncertainty","title":"System Model","text":"","category":"section"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"First let's consider a 2D bouncing ball, where the states are the horizontal position x, horizontal velocity dotx, vertical position y, and vertical velocity doty. This model has two system parameters, acceleration due to gravity and coefficient of restitution (models energy loss when the ball impacts the ground). We can simulate such a system using ContinuousCallback as","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"using DifferentialEquations, Plots\n\nfunction ball!(du, u, p, t)\n    du[1] = u[2]\n    du[2] = 0.0\n    du[3] = u[4]\n    du[4] = -p[1]\nend\n\nground_condition(u, t, integrator) = u[3]\nground_affect!(integrator) = integrator.u[4] = -integrator.p[2] * integrator.u[4]\nground_cb = ContinuousCallback(ground_condition, ground_affect!)\n\nu0 = [0.0, 2.0, 50.0, 0.0]\ntspan = (0.0, 50.0)\np = [9.807, 0.9]\n\nprob = ODEProblem(ball!, u0, tspan, p)\nsol = solve(prob, Tsit5(), callback = ground_cb)\nplot(sol, vars = (1, 3), label = nothing, xlabel = \"x\", ylabel = \"y\")","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"For this particular problem, we wish to measure the impact distance from a point y=25 on a wall at x=25. So, we introduce an additional callback that terminates the simulation on wall impact.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"stop_condition(u, t, integrator) = u[1] - 25.0\nstop_cb = ContinuousCallback(stop_condition, terminate!)\ncbs = CallbackSet(ground_cb, stop_cb)\n\ntspan = (0.0, 1500.0)\nprob = ODEProblem(ball!, u0, tspan, p)\nsol = solve(prob, Tsit5(), callback = cbs)\nplot(sol, vars = (1, 3), label = nothing, xlabel = \"x\", ylabel = \"y\")","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"To help visualize this problem, we plot as follows, where the star indicates a desired impact location","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"rectangle(xc, yc, w, h) = Shape(xc .+ [-w, w, w, -w] ./ 2.0, yc .+ [-h, -h, h, h] ./ 2.0)\n\nbegin\n    plot(sol, vars = (1, 3), label = nothing, lw = 3, c = :black)\n    xlabel!(\"x [m]\")\n    ylabel!(\"y [m]\")\n    plot!(rectangle(27.5, 25, 5, 50), c = :red, label = nothing)\n    scatter!([25], [25], marker = :star, ms = 10, label = nothing, c = :green)\n    ylims!(0.0, 50.0)\nend","category":"page"},{"location":"showcase/optimization_under_uncertainty/#Considering-Uncertainty","page":"Optimization Under Uncertainty","title":"Considering Uncertainty","text":"","category":"section"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We now wish to introduce uncertainty in p[2], the coefficient of restitution. This is defined via a continuous univariate distribution from Distributions.jl. We can then run a Monte Carlo simulation of 100 trajectories via the EnsembleProblem interface.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"using Distributions\n\ncor_dist = truncated(Normal(0.9, 0.02), 0.9 - 3 * 0.02, 1.0)\ntrajectories = 100\n\nprob_func(prob, i, repeat) = remake(prob, p = [p[1], rand(cor_dist)])\nensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\nensemblesol = solve(ensemble_prob, Tsit5(), EnsembleThreads(), trajectories = trajectories,\n    callback = cbs)\n\nbegin # plot\n    plot(ensemblesol, vars = (1, 3), lw = 1)\n    xlabel!(\"x [m]\")\n    ylabel!(\"y [m]\")\n    plot!(rectangle(27.5, 25, 5, 50), c = :red, label = nothing)\n    scatter!([25], [25], marker = :star, ms = 10, label = nothing, c = :green)\n    plot!(sol, vars = (1, 3), label = nothing, lw = 3, c = :black, ls = :dash)\n    xlims!(0.0, 27.5)\nend","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Here, we plot the first 350 Monte Carlo simulations along with the trajectory corresponding to the mean of the distribution (dashed line).","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We now wish to compute the expected squared impact distance from the star. This is called an “observation” of our system or an “observable” of interest.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We define this observable as","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"obs(sol, p) = abs2(sol[3, end] - 25)","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"With the observable defined, we can compute the expected squared miss distance from our Monte Carlo simulation results as","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"mean_ensemble = mean([obs(sol, p) for sol in ensemblesol])","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Alternatively, we can use the Koopman() algorithm in SciMLExpectations.jl to compute this expectation much more efficiently as","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"using SciMLExpectations\ngd = GenericDistribution(cor_dist)\nh(x, u, p) = u, [p[1]; x[1]]\nsm = SystemMap(prob, Tsit5(), callback = cbs)\nexprob = ExpectationProblem(sm, obs, h, gd; nout = 1)\nsol = solve(exprob, Koopman(), ireltol = 1e-5)\nsol.u","category":"page"},{"location":"showcase/optimization_under_uncertainty/#Optimization-Under-Uncertainty","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"","category":"section"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We now wish to optimize the initial position (x_0y_0) and horizontal velocity (dotx_0) of the system to minimize the expected squared miss distance from the star, where x_0inleft-1000right, y_0inleft13right, and dotx_0inleft1050right. We will demonstrate this using a gradient-based optimization approach from NLopt.jl using ForwardDiff.jl AD through the expectation calculation.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"using Optimization, OptimizationNLopt, OptimizationMOI\nmake_u0(θ) = [θ[1], θ[2], θ[3], 0.0]\nfunction 𝔼_loss(θ, pars)\n    prob = ODEProblem(ball!, make_u0(θ), tspan, p)\n    sm = SystemMap(prob, Tsit5(), callback = cbs)\n    exprob = ExpectationProblem(sm, obs, h, gd; nout = 1)\n    sol = solve(exprob, Koopman(), ireltol = 1e-5)\n    sol.u\nend\nopt_f = OptimizationFunction(𝔼_loss, Optimization.AutoForwardDiff())\nopt_ini = [-1.0, 2.0, 50.0]\nopt_lb = [-100.0, 1.0, 10.0]\nopt_ub = [0.0, 3.0, 50.0]\nopt_prob = OptimizationProblem(opt_f, opt_ini; lb = opt_lb, ub = opt_ub)\noptimizer = OptimizationMOI.MOI.OptimizerWithAttributes(NLopt.Optimizer,\n    \"algorithm\" => :LD_MMA)\nopt_sol = solve(opt_prob, optimizer)\nminx = opt_sol.u","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Let's now visualize 100 Monte Carlo simulations","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"ensembleprob = EnsembleProblem(remake(prob, u0 = make_u0(minx)), prob_func = prob_func)\nensemblesol = solve(ensembleprob, Tsit5(), EnsembleThreads(), trajectories = 100,\n    callback = cbs)\n\nbegin\n    plot(ensemblesol, vars = (1, 3), lw = 1, alpha = 0.1)\n    plot!(solve(remake(prob, u0 = make_u0(minx)), Tsit5(), callback = cbs),\n        vars = (1, 3), label = nothing, c = :black, lw = 3, ls = :dash)\n    xlabel!(\"x [m]\")\n    ylabel!(\"y [m]\")\n    plot!(rectangle(27.5, 25, 5, 50), c = :red, label = nothing)\n    scatter!([25], [25], marker = :star, ms = 10, label = nothing, c = :green)\n    ylims!(0.0, 50.0)\n    xlims!(minx[1], 27.5)\nend","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Looks pretty good! But, how long did it take? Let's benchmark.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"@time solve(opt_prob, optimizer)","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Not bad for bound constrained optimization under uncertainty of a hybrid system!","category":"page"},{"location":"showcase/optimization_under_uncertainty/#Probabilistic-Constraints","page":"Optimization Under Uncertainty","title":"Probabilistic Constraints","text":"","category":"section"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"With this approach, we can also consider probabilistic constraints. Let us now consider a wall at x=20 with height 25.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"constraint = [20.0, 25.0]\nbegin\n    plot(rectangle(27.5, 25, 5, 50), c = :red, label = nothing)\n    xlabel!(\"x [m]\")\n    ylabel!(\"y [m]\")\n    plot!([constraint[1], constraint[1]], [0.0, constraint[2]], lw = 5, c = :black,\n        label = nothing)\n    scatter!([25], [25], marker = :star, ms = 10, label = nothing, c = :green)\n    ylims!(0.0, 50.0)\n    xlims!(minx[1], 27.5)\nend","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We now wish to minimize the same loss function as before, but introduce an inequality constraint such that the solution must have less than a 1% chance of colliding with the wall at x=20. This class of probabilistic constraints is called a chance constraint.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"To do this, we first introduce a new callback and solve the system using the previous optimal solution","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"constraint_condition(u, t, integrator) = u[1] - constraint[1]\nfunction constraint_affect!(integrator)\n    integrator.u[3] < constraint[2] ? terminate!(integrator) : nothing\nend\nconstraint_cb = ContinuousCallback(constraint_condition, constraint_affect!,\n    save_positions = (true, false));\nconstraint_cbs = CallbackSet(ground_cb, stop_cb, constraint_cb)\n\nensemblesol = solve(ensembleprob, Tsit5(), EnsembleThreads(), trajectories = 500,\n    callback = constraint_cbs)\n\nbegin\n    plot(ensemblesol, vars = (1, 3), lw = 1, alpha = 0.1)\n    plot!(solve(remake(prob, u0 = make_u0(minx)), Tsit5(), callback = constraint_cbs),\n        vars = (1, 3), label = nothing, c = :black, lw = 3, ls = :dash)\n\n    xlabel!(\"x [m]\")\n    ylabel!(\"y [m]\")\n    plot!(rectangle(27.5, 25, 5, 50), c = :red, label = nothing)\n    plot!([constraint[1], constraint[1]], [0.0, constraint[2]], lw = 5, c = :black)\n    scatter!([25], [25], marker = :star, ms = 10, label = nothing, c = :green)\n    ylims!(0.0, 50.0)\n    xlims!(minx[1], 27.5)\nend","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"That doesn't look good!","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We now need a second observable for the system. To compute a probability of impact, we use an indicator function for if a trajectory impacts the wall. In other words, this functions returns 1 if the trajectory hits the wall and 0 otherwise.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"function constraint_obs(sol, p)\n    sol((constraint[1] - sol[1, 1]) / sol[2, 1])[3] <= constraint[2] ? one(sol[1, end]) :\n    zero(sol[1, end])\nend","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Using the previously computed optimal initial conditions, let's compute the probability of hitting this wall","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"sm = SystemMap(remake(prob, u0 = make_u0(minx)), Tsit5(), callback = cbs)\nexprob = ExpectationProblem(sm, constraint_obs, h, gd; nout = 1)\nsol = solve(exprob, Koopman(), ireltol = 1e-5)\nsol.u","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We then set up the constraint function for NLopt just as before.","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"function 𝔼_constraint(res, θ, pars)\n    prob = ODEProblem(ball!, make_u0(θ), tspan, p)\n    sm = SystemMap(prob, Tsit5(), callback = cbs)\n    exprob = ExpectationProblem(sm, constraint_obs, h, gd; nout = 1)\n    sol = solve(exprob, Koopman(), ireltol = 1e-5)\n    res .= sol.u\nend\nopt_lcons = [-Inf]\nopt_ucons = [0.01]\noptimizer = OptimizationMOI.MOI.OptimizerWithAttributes(NLopt.Optimizer,\n    \"algorithm\" => :LD_MMA)\nopt_f = OptimizationFunction(𝔼_loss, Optimization.AutoForwardDiff(), cons = 𝔼_constraint)\nopt_prob = OptimizationProblem(opt_f, opt_ini; lb = opt_lb, ub = opt_ub, lcons = opt_lcons,\n    ucons = opt_ucons)\nopt_sol = solve(opt_prob, optimizer)\nminx2 = opt_sol.u","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"The probability of impacting the wall is now","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"container = zeros(1)\n𝔼_constraint(container, minx2, nothing)\nλ = container[1]","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"We can check if this is within tolerance by","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"λ <= 0.01 + 1e-5","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"Again, we plot some Monte Carlo simulations from this result as follows","category":"page"},{"location":"showcase/optimization_under_uncertainty/","page":"Optimization Under Uncertainty","title":"Optimization Under Uncertainty","text":"ensembleprob = EnsembleProblem(remake(prob, u0 = make_u0(minx2)), prob_func = prob_func)\nensemblesol = solve(ensembleprob, Tsit5(), EnsembleThreads(),\n    trajectories = 500, callback = constraint_cbs)\n\nbegin\n    plot(ensemblesol, vars = (1, 3), lw = 1, alpha = 0.1)\n    plot!(solve(remake(prob, u0 = make_u0(minx2)), Tsit5(), callback = constraint_cbs),\n        vars = (1, 3), label = nothing, c = :black, lw = 3, ls = :dash)\n    plot!([constraint[1], constraint[1]], [0.0, constraint[2]], lw = 5, c = :black)\n\n    xlabel!(\"x [m]\")\n    ylabel!(\"y [m]\")\n    plot!(rectangle(27.5, 25, 5, 50), c = :red, label = nothing)\n    scatter!([25], [25], marker = :star, ms = 10, label = nothing, c = :green)\n    ylims!(0.0, 50.0)\n    xlims!(minx[1], 27.5)\nend","category":"page"},{"location":"getting_started/getting_started/#getting_started","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"","category":"section"},{"location":"getting_started/getting_started/#Quickly:-What-is-Julia's-SciML-Ecosystem?","page":"Getting Started with Julia's SciML","title":"Quickly: What is Julia's SciML Ecosystem?","text":"","category":"section"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"Julia's SciML is:","category":"page"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"SciPy or MATLAB's standard library but in Julia, but\nRuns orders of magnitude faster, even outperforms C and Fortran libraries, and\nIs fully compatible with machine learning and automatic differentiation,\nAll while having an easy-to-use high level interactive development environment.","category":"page"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"Interested?","category":"page"},{"location":"getting_started/getting_started/#Introductory-Tutorials","page":"Getting Started with Julia's SciML","title":"Introductory Tutorials","text":"","category":"section"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"How do I install SciML software?\nBuild and run your first simulation\nSolve your first optimization problem\nFit a simulation to a dataset\nFind the root of an equation (i.e. solve f(x)=0)","category":"page"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"note: Note\nEach of the SciML packages starts with its own introductory tutorial as well! Once you have started to get the hang of a few things, start checking out the introductory tutorials of the different packages. For example, the DifferentialEquations.jl getting started tutorial is a fun one!","category":"page"},{"location":"getting_started/getting_started/#Coming-from...","page":"Getting Started with Julia's SciML","title":"Coming from...","text":"","category":"section"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"Are you familiar with other scientific computing tools? Take a look at the guided introductions below.","category":"page"},{"location":"getting_started/getting_started/","page":"Getting Started with Julia's SciML","title":"Getting Started with Julia's SciML","text":"Introduction to Julia's SciML for the Python User\nIntroduction to Julia's SciML for the MATLAB User\nIntroduction to Julia's SciML for the R User\nIntroduction to Julia's SciML for the C++/Fortran User","category":"page"},{"location":"showcase/symbolic_analysis/#symbolic_analysis","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"The mixture of symbolic computing with numeric computing, which we call symbolic-numeric programming, is one of the central features of the SciML ecosystem. With core aspects like the Symbolics.jl Computer Algebra System and its integration via ModelingToolkit.jl, the SciML ecosystem gracefully mixes analytical symbolic computations with the numerical solver processes to accelerate solvers, give additional information (sparsity, identifiability), automatically fix numerical stability issues, and more.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"In this showcase, we will highlight two aspects of symbolic-numeric programming.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Automated index reduction of DAEs. While arbitrary differential-algebraic equation systems can be written in DifferentialEquations.jl, not all mathematical formulations of a system are equivalent. Some are numerically difficult to solve, or even require special solvers. Some are easy. Can we recognize which formulations are hard and automatically transform them into the easy ones? Yes.\nStructural parameter identifiability. When fitting parameters to data, there's always assumptions about whether there is a unique parameter set that achieves such a data fit. But is this actually the case? The structural identifiability tooling allows one to analytically determine whether, in the limit of infinite data on a subset of observables, one could in theory uniquely identify the parameters (global identifiability), identify the parameters up to a discrete set (local identifiability), or whether there's an infinite manifold of solutions to the inverse problem (nonidentifiable).","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Let's dig into these two cases!","category":"page"},{"location":"showcase/symbolic_analysis/#Automated-Index-Reduction-of-DAEs","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Automated Index Reduction of DAEs","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"In many cases one may accidentally write down a DAE that is not easily solvable by numerical methods. In this tutorial, we will walk through an example of a pendulum which accidentally generates an index-3 DAE, and show how to use the modelingtoolkitize to correct the model definition before solving.","category":"page"},{"location":"showcase/symbolic_analysis/#Copy-Pastable-Example","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Copy-Pastable Example","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"using ModelingToolkit\nusing LinearAlgebra\nusing OrdinaryDiffEq\nusing Plots\n\nfunction pendulum!(du, u, p, t)\n    x, dx, y, dy, T = u\n    g, L = p\n    du[1] = dx\n    du[2] = T * x\n    du[3] = dy\n    du[4] = T * y - g\n    du[5] = x^2 + y^2 - L^2\n    return nothing\nend\npendulum_fun! = ODEFunction(pendulum!, mass_matrix = Diagonal([1, 1, 1, 1, 0]))\nu0 = [1.0, 0, 0, 0, 0]\np = [9.8, 1]\ntspan = (0, 10.0)\npendulum_prob = ODEProblem(pendulum_fun!, u0, tspan, p)\ntraced_sys = modelingtoolkitize(pendulum_prob)\npendulum_sys = structural_simplify(dae_index_lowering(traced_sys))\nprob = ODEProblem(pendulum_sys, [], tspan)\nsol = solve(prob, Rodas5P(), abstol = 1e-8, reltol = 1e-8)\nplot(sol, vars = unknowns(traced_sys))","category":"page"},{"location":"showcase/symbolic_analysis/#Explanation","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Explanation","text":"","category":"section"},{"location":"showcase/symbolic_analysis/#Attempting-to-Solve-the-Equation","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Attempting to Solve the Equation","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"In this tutorial, we will look at the pendulum system:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"beginaligned\n    x^prime = v_x\n    v_x^prime = Tx\n    y^prime = v_y\n    v_y^prime = Ty - g\n    0 = x^2 + y^2 - L^2\nendaligned","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"As a good DifferentialEquations.jl user, one would follow the mass matrix DAE tutorial to arrive at code for simulating the model:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"using OrdinaryDiffEq, LinearAlgebra\nfunction pendulum!(du, u, p, t)\n    x, dx, y, dy, T = u\n    g, L = p\n    du[1] = dx\n    du[2] = T * x\n    du[3] = dy\n    du[4] = T * y - g\n    du[5] = x^2 + y^2 - L^2\nend\npendulum_fun! = ODEFunction(pendulum!, mass_matrix = Diagonal([1, 1, 1, 1, 0]))\nu0 = [1.0, 0, 0, 0, 0];\np = [9.8, 1];\ntspan = (0, 10.0);\npendulum_prob = ODEProblem(pendulum_fun!, u0, tspan, p)\nsolve(pendulum_prob, Rodas5P())","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"However, one will quickly be greeted with the unfortunate message:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"┌ Warning: First function call produced NaNs. Exiting.\n└ @ OrdinaryDiffEq C:\\Users\\accou\\.julia\\packages\\OrdinaryDiffEq\\yCczp\\src\\initdt.jl:76\n┌ Warning: Automatic dt set the starting dt as NaN, causing instability.\n└ @ OrdinaryDiffEq C:\\Users\\accou\\.julia\\packages\\OrdinaryDiffEq\\yCczp\\src\\solve.jl:485\n┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.\n└ @ SciMLBase C:\\Users\\accou\\.julia\\packages\\SciMLBase\\DrPil\\src\\integrator_interface.jl:325","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Did you implement the DAE incorrectly? No. Is the solver broken? No.","category":"page"},{"location":"showcase/symbolic_analysis/#Understanding-DAE-Index","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Understanding DAE Index","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"It turns out that this is a property of the DAE that we are attempting to solve. This kind of DAE is known as an index-3 DAE. For a complete discussion of DAE index, see this article. Essentially, the issue here is that we have 4 differential variables (x, v_x, y, v_y) and one algebraic variable T (which we can know because there is no D(T) term in the equations). An index-1 DAE always satisfies that the Jacobian of the algebraic equations is non-singular. Here, the first 4 equations are differential equations, with the last term the algebraic relationship. However, the partial derivative of x^2 + y^2 - L^2 w.r.t. T is zero, and thus the Jacobian of the algebraic equations is the zero matrix, and thus it's singular. This is a quick way to see whether the DAE is index 1!","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"The problem with higher order DAEs is that the matrices used in Newton solves are singular or close to singular when applied to such problems. Because of this fact, the nonlinear solvers (or Rosenbrock methods) break down, making them difficult to solve. The classic paper DAEs are not ODEs goes into detail on this and shows that many methods are no longer convergent when index is higher than one. So, it's not necessarily the fault of the solver or the implementation: this is known.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"But that's not a satisfying answer, so what do you do about it?","category":"page"},{"location":"showcase/symbolic_analysis/#Transforming-Higher-Order-DAEs-to-Index-1-DAEs","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Transforming Higher Order DAEs to Index-1 DAEs","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"It turns out that higher order DAEs can be transformed into lower order DAEs. If you differentiate the last equation two times and perform a substitution, you can arrive at the following set of equations:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"beginaligned\nx^prime = v_x \nv_x^prime = x T \ny^prime = v_y \nv_y^prime = y T - g \n0 = 2 left(v_x^2 + v_y^2 + y ( y T - g ) + T x^2 right)\nendaligned","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Note that this is mathematically equivalent to the equation that we had before, but the Jacobian w.r.t. T of the algebraic equation is no longer zero because of the substitution. This means that if you wrote down this version of the model, it will be index-1 and solve correctly! In fact, this is how DAE index is commonly defined: the number of differentiations it takes to transform the DAE into an ODE, where an ODE is an index-0 DAE by substituting out all of the algebraic relationships.","category":"page"},{"location":"showcase/symbolic_analysis/#Automating-the-Index-Reduction","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Automating the Index Reduction","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"However, requiring the user to sit there and work through this process on potentially millions of equations is an unfathomable mental overhead. But, we can avoid this by using methods like the Pantelides algorithm for automatically performing this reduction to index 1. While this requires the ModelingToolkit symbolic form, we use modelingtoolkitize to transform the numerical code into symbolic code, run structural_simplify to simplify the system and lower the index, then transform back to numerical code with ODEProblem, and solve with a numerical solver. Let's try that out:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"traced_sys = modelingtoolkitize(pendulum_prob)\npendulum_sys = structural_simplify(traced_sys)\nprob = ODEProblem(pendulum_sys, Pair[], tspan)\nsol = solve(prob, Rodas5P())\n\nusing Plots\nplot(sol, vars = unknowns(traced_sys))","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Note that plotting using unknowns(traced_sys) is done so that any variables which are symbolically eliminated, or any variable reordering done for enhanced parallelism/performance, still show up in the resulting plot and the plot is shown in the same order as the original numerical code.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Note that we can even go a bit further. If we use the ODEProblem constructor, we represent the mass matrix DAE of the index-reduced system, which can be solved via:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"traced_sys = modelingtoolkitize(pendulum_prob)\npendulum_sys = structural_simplify(dae_index_lowering(traced_sys))\nprob = ODEProblem(pendulum_sys, Pair[], tspan)\nsol = solve(prob, Rodas5P(), abstol = 1e-8, reltol = 1e-8)\nplot(sol, vars = unknowns(traced_sys))","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"And there you go: this has transformed the model from being too hard to solve with implicit DAE solvers, to something that is easily solved.","category":"page"},{"location":"showcase/symbolic_analysis/#Parameter-Identifiability-in-ODE-Models","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Parameter Identifiability in ODE Models","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Ordinary differential equations are commonly used for modeling real-world processes. The problem of parameter identifiability is one of the key design challenges for mathematical models. A parameter is said to be identifiable if one can recover its value from experimental data. Structural identifiability is a theoretical property of a model that answers this question. In this tutorial, we will show how to use StructuralIdentifiability.jl with ModelingToolkit.jl to assess identifiability of parameters in ODE models. The theory behind StructuralIdentifiability.jl is presented in paper [4].","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"We will start by illustrating local identifiability in which a parameter is known up to finitely many values, and then proceed to determining global identifiability, that is, which parameters can be identified uniquely.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"To install StructuralIdentifiability.jl, simply run","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"using Pkg\nPkg.add(\"StructuralIdentifiability\")","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"The package has a standalone data structure for ordinary differential equations, but is also compatible with ODESystem type from ModelingToolkit.jl.","category":"page"},{"location":"showcase/symbolic_analysis/#Local-Identifiability","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Local Identifiability","text":"","category":"section"},{"location":"showcase/symbolic_analysis/#Input-System","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Input System","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"We will consider the following model:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"begincases\nfracdx_4dt = - frack_5 x_4k_6 + x_4\nfracdx_5dt = frack_5 x_4k_6 + x_4 - frack_7 x_5(k_8 + x_5 + x_6)\nfracdx_6dt = frack_7 x_5(k_8 + x_5 + x_6) - frack_9  x_6  (k_10 - x_6) k_10\nfracdx_7dt = frack_9  x_6  (k_10 - x_6) k_10\ny_1 = x_4\ny_2 = x_5endcases","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"This model describes the biohydrogenation[1] process[2] with unknown initial conditions.","category":"page"},{"location":"showcase/symbolic_analysis/#Using-the-ODESystem-object","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Using the ODESystem object","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"To define the ode system in Julia, we use ModelingToolkit.jl.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"We first define the parameters, variables, differential equations and the output equations.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"using StructuralIdentifiability, ModelingToolkit\n\n# define parameters and variables\n@variables t x4(t) x5(t) x6(t) x7(t) y1(t) y2(t)\n@parameters k5 k6 k7 k8 k9 k10\nD = Differential(t)\n\n# define equations\neqs = [\n    D(x4) ~ -k5 * x4 / (k6 + x4),\n    D(x5) ~ k5 * x4 / (k6 + x4) - k7 * x5 / (k8 + x5 + x6),\n    D(x6) ~ k7 * x5 / (k8 + x5 + x6) - k9 * x6 * (k10 - x6) / k10,\n    D(x7) ~ k9 * x6 * (k10 - x6) / k10\n]\n\n# define the output functions (quantities that can be measured)\nmeasured_quantities = [y1 ~ x4, y2 ~ x5]\n\n# define the system\nde = ODESystem(eqs, t, name = :Biohydrogenation)","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"After that, we are ready to check the system for local identifiability:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"# query local identifiability\n# we pass the ode-system\nlocal_id_all = assess_local_identifiability(de, measured_quantities = measured_quantities,\n    p = 0.99)\n# [ Info: Preproccessing `ModelingToolkit.ODESystem` object\n# 6-element Vector{Bool}:\n#  1\n#  1\n#  1\n#  1\n#  1\n#  1","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"We can see that all unknowns (except x_7) and all parameters are locally identifiable with probability 0.99.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Let's try to check specific parameters and their combinations","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"to_check = [k5, k7, k10 / k9, k5 + k6]\nlocal_id_some = assess_local_identifiability(de, measured_quantities = measured_quantities,\n    funcs_to_check = to_check, p = 0.99)\n# 4-element Vector{Bool}:\n#  1\n#  1\n#  1\n#  1","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Notice that in this case, everything (except the state variable x_7) is locally identifiable, including combinations such as k_10k_9 k_5+k_6","category":"page"},{"location":"showcase/symbolic_analysis/#Global-Identifiability","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Global Identifiability","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"In this part tutorial, let us cover an example problem of querying the ODE for globally identifiable parameters.","category":"page"},{"location":"showcase/symbolic_analysis/#Input-System-2","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Input System","text":"","category":"section"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Let us consider the following four-dimensional model with two outputs:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"begincases\nx_1(t) = -b  x_1(t) + frac1  c + x_4(t)\nx_2(t) = alpha  x_1(t) - beta  x_2(t)\nx_3(t) = gamma  x_2(t) - delta  x_3(t)\nx_4(t) = sigma  x_4(t)  frac(gamma x_2(t) - delta x_3(t)) x_3(t)\ny(t) = x_1(t)\nendcases","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"We will run a global identifiability check on this enzyme dynamics[3] model. We will use the default settings: the probability of correctness will be p=0.99 and we are interested in identifiability of all possible parameters.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Global identifiability needs information about local identifiability first, but the function we chose here will take care of that extra step for us.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Note: as of writing this tutorial, UTF-symbols such as Greek characters are not supported by one of the project's dependencies, see this issue.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"using StructuralIdentifiability, ModelingToolkit\n@parameters b c a beta g delta sigma\n@variables t x1(t) x2(t) x3(t) x4(t) y(t) y2(t)\nD = Differential(t)\n\neqs = [\n    D(x1) ~ -b * x1 + 1 / (c + x4),\n    D(x2) ~ a * x1 - beta * x2,\n    D(x3) ~ g * x2 - delta * x3,\n    D(x4) ~ sigma * x4 * (g * x2 - delta * x3) / x3\n]\n\nmeasured_quantities = [y ~ x1 + x2, y2 ~ x2]\n\node = ODESystem(eqs, t, name = :GoodwinOsc)\n\n@time global_id = assess_identifiability(ode, measured_quantities = measured_quantities)\n# 30.672594 seconds (100.97 M allocations: 6.219 GiB, 3.15% gc time, 0.01% compilation time)\n# Dict{Num, Symbol} with 7 entries:\n#   a     => :globally\n#   b     => :globally\n#   beta  => :globally\n#   c     => :globally\n#   sigma => :globally\n#   g     => :nonidentifiable\n#   delta => :globally","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"We can see that only parameters a, g are unidentifiable, and everything else can be uniquely recovered.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Let us consider the same system but with two inputs, and we will find out identifiability with probability 0.9 for parameters c and b:","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"using StructuralIdentifiability, ModelingToolkit\n@parameters b c a beta g delta sigma\n@variables t x1(t) x2(t) x3(t) x4(t) y(t) u1(t) [input = true] u2(t) [input = true]\nD = Differential(t)\n\neqs = [\n    D(x1) ~ -b * x1 + 1 / (c + x4),\n    D(x2) ~ a * x1 - beta * x2 - u1,\n    D(x3) ~ g * x2 - delta * x3 + u2,\n    D(x4) ~ sigma * x4 * (g * x2 - delta * x3) / x3\n]\nmeasured_quantities = [y ~ x1 + x2, y2 ~ x2]\n\n# check only 2 parameters\nto_check = [b, c]\n\node = ODESystem(eqs, t, name = :GoodwinOsc)\n\nglobal_id = assess_identifiability(ode, measured_quantities = measured_quantities,\n    funcs_to_check = to_check, p = 0.9)\n# Dict{Num, Symbol} with 2 entries:\n#   b => :globally\n#   c => :globally","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"Both parameters b, c are globally identifiable with probability 0.9 in this case.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"[1]: R. Munoz-Tamayo, L. Puillet, J.B. Daniel, D. Sauvant, O. Martin, M. Taghipoor, P. Blavy Review: To be or not to be an identifiable model. Is this a relevant question in animal science modelling?, Animal, Vol 12 (4), 701-712, 2018. The model is the ODE system (3) in Supplementary Material 2, initial conditions are assumed to be unknown.","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"[2]: Moate P.J., Boston R.C., Jenkins T.C. and Lean I.J., Kinetics of Ruminal Lipolysis of Triacylglycerol and Biohydrogenationof Long-Chain Fatty Acids: New Insights from Old Data, Journal of Dairy Science 91, 731–742, 2008","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"[3]: Goodwin, B.C. Oscillatory behavior in enzymatic control processes, Advances in Enzyme Regulation, Vol 3 (C), 425-437, 1965","category":"page"},{"location":"showcase/symbolic_analysis/","page":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","title":"Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability","text":"[4]: Dong, R., Goodbrake, C., Harrington, H. A., & Pogudin, G. Computing input-output projections of dynamical models with applications to structural identifiability. arXiv preprint arXiv:2111.00991.","category":"page"},{"location":"highlevels/symbolic_learning/#Symbolic-Learning-and-Artificial-Intelligence","page":"Symbolic Learning and Artificial Intelligence","title":"Symbolic Learning and Artificial Intelligence","text":"","category":"section"},{"location":"highlevels/symbolic_learning/","page":"Symbolic Learning and Artificial Intelligence","title":"Symbolic Learning and Artificial Intelligence","text":"Symbolic learning, the classical artificial intelligence, is a set of methods for learning symbolic equations from data and numerical functions. SciML offers an array of symbolic learning utilities which connect with the other machine learning and equation solver functionalities to make it easy to embed prior knowledge and discover missing physics. For more information, see Universal Differential Equations for Scientific Machine Learning.","category":"page"},{"location":"highlevels/symbolic_learning/#DataDrivenDiffEq.jl:-Data-Driven-Modeling-and-Automated-Discovery-of-Dynamical-Systems","page":"Symbolic Learning and Artificial Intelligence","title":"DataDrivenDiffEq.jl: Data-Driven Modeling and Automated Discovery of Dynamical Systems","text":"","category":"section"},{"location":"highlevels/symbolic_learning/","page":"Symbolic Learning and Artificial Intelligence","title":"Symbolic Learning and Artificial Intelligence","text":"DataDrivenDiffEq.jl is a general interface for data-driven modeling, containing a large array of techniques such as:","category":"page"},{"location":"highlevels/symbolic_learning/","page":"Symbolic Learning and Artificial Intelligence","title":"Symbolic Learning and Artificial Intelligence","text":"Koopman operator methods (Dynamic-Mode Decomposition (DMD) and variations)\nSparse Identification of Dynamical Systems (SINDy and variations like iSINDy)\nSparse regression methods (STSLQ, SR3, etc.)\nPDEFind\nWrappers for SymbolicRegression.jl\nAI Feynman\nOccamNet","category":"page"},{"location":"highlevels/symbolic_learning/#SymbolicNumericIntegration.jl:-Symbolic-Integration-via-Numerical-Methods","page":"Symbolic Learning and Artificial Intelligence","title":"SymbolicNumericIntegration.jl: Symbolic Integration via Numerical Methods","text":"","category":"section"},{"location":"highlevels/symbolic_learning/","page":"Symbolic Learning and Artificial Intelligence","title":"Symbolic Learning and Artificial Intelligence","text":"SymbolicNumericIntegration.jl is a package computing the solution to symbolic integration problem using numerical methods (numerical integration mixed with sparse regression).","category":"page"},{"location":"highlevels/symbolic_learning/#Third-Party-Libraries-to-Note","page":"Symbolic Learning and Artificial Intelligence","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/symbolic_learning/#SymbolicRegression.jl","page":"Symbolic Learning and Artificial Intelligence","title":"SymbolicRegression.jl","text":"","category":"section"},{"location":"highlevels/symbolic_learning/","page":"Symbolic Learning and Artificial Intelligence","title":"Symbolic Learning and Artificial Intelligence","text":"SymbolicRegression.jl is a symbolic regression library which uses genetic algorithms with parallelization to achieve fast and robust symbolic learning.","category":"page"},{"location":"highlevels/array_libraries/#Modeling-Array-Libraries","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"","category":"section"},{"location":"highlevels/array_libraries/#RecursiveArrayTools.jl:-Arrays-of-Arrays-and-Even-Deeper","page":"Modeling Array Libraries","title":"RecursiveArrayTools.jl: Arrays of Arrays and Even Deeper","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"Sometimes, when one is creating a model, basic array types are not enough for expressing a complex concept. RecursiveArrayTools.jl gives many types, such as VectorOfArray and ArrayPartition, which allow for easily building nested array models in a way that conforms to the standard AbstractArray interface. While standard Vector{Array{Float64,N}} types may not be compatible with many equation solver libraries, these wrapped forms like VectorOfArray{Vector{Array{Float64,N}}} are, making it easy to use these more exotic array constructions.","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"Note that SciML's interfaces use RecursiveArrayTools.jl extensively, for example, with the timeseries solution types being AbstractVectorOfArray.","category":"page"},{"location":"highlevels/array_libraries/#LabelledArrays.jl:-Named-Variables-in-Arrays-without-Overhead","page":"Modeling Array Libraries","title":"LabelledArrays.jl: Named Variables in Arrays without Overhead","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"Sometimes, you want to use a full domain-specific language like ModelingToolkit. Other times, you wish arrays just had a slightly nicer syntax. Don't you wish you could write the Lorenz equations like:","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"function lorenz_f(du, u, p, t)\n    du.x = p.σ * (u.y - u.x)\n    du.y = u.x * (p.ρ - u.z) - u.y\n    du.z = u.x * u.y - p.β * u.z\nend","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"without losing any efficiency? LabelledArrays.jl provides the array types to do just that. All the . accesses are resolved at compile-time, so it's a zero-overhead interface.","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"note: Note\nWe recommend using ComponentArrays.jl for any instance where nested accesses are required, or where the . accesses need to be views to subsets of the array.","category":"page"},{"location":"highlevels/array_libraries/#MultiScaleArrays.jl:-Multiscale-Modeling-to-Compose-with-Equation-Solvers","page":"Modeling Array Libraries","title":"MultiScaleArrays.jl: Multiscale Modeling to Compose with Equation Solvers","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"(Image: )","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"How do you encode such real-world structures in a manner that is compatible with the SciML equation solver libraries? MultiScaleArrays.jl is an answer. MultiScaleArrays.jl gives a highly flexible interface for defining multi-level types, which generates a corresponding interface as an AbstractArray. MultiScaleArrays.jl's flexibility includes the ease of resizing, allowing for models where the number of equations grows and shrinks as agents (cells) in the model divide and die.","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"note: Note\nWe recommend using ComponentArrays.jl instead in any instance where the resizing functionality is not used.","category":"page"},{"location":"highlevels/array_libraries/#Third-Party-Libraries-to-Note","page":"Modeling Array Libraries","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/array_libraries/#ComponentArrays.jl:-Arrays-with-Arbitrarily-Nested-Named-Components","page":"Modeling Array Libraries","title":"ComponentArrays.jl: Arrays with Arbitrarily Nested Named Components","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"What if you had a set of arrays of arrays with names, but you wanted to represent them on a single contiguous vector so that linear algebra was as fast as possible, while retaining . named accesses with zero-overhead? This is what ComponentArrays.jl provides, and as such it is one of the top recommendations of AbstractArray types to be used. Multi-level definitions such as x = ComponentArray(a=5, b=[(a=20., b=0), (a=33., b=0), (a=44., b=3)], c=c) are common-place, and allow for accessing via x.b.a etc. without any performance loss. ComponentArrays are fully compatible with the SciML equation solvers. They thus can be used as initial conditions. Here's a demonstration of the Lorenz equation using ComponentArrays with Parameters.jl's @unpack:","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"using ComponentArrays\nusing DifferentialEquations\nusing Parameters: @unpack\n\ntspan = (0.0, 20.0)\n\n## Lorenz system\nfunction lorenz!(D, u, p, t; f = 0.0)\n    @unpack σ, ρ, β = p\n    @unpack x, y, z = u\n\n    D.x = σ * (y - x)\n    D.y = x * (ρ - z) - y - f\n    D.z = x * y - β * z\n    return nothing\nend\n\nlorenz_p = (σ = 10.0, ρ = 28.0, β = 8 / 3)\nlorenz_ic = ComponentArray(x = 0.0, y = 0.0, z = 0.0)\nlorenz_prob = ODEProblem(lorenz!, lorenz_ic, tspan, lorenz_p)","category":"page"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"Is that beautiful? Yes, it is.","category":"page"},{"location":"highlevels/array_libraries/#StaticArrays.jl:-Statically-Defined-Arrays","page":"Modeling Array Libraries","title":"StaticArrays.jl: Statically-Defined Arrays","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"StaticArrays.jl is a library for statically-defined arrays. Because these arrays have type-level information for size, they recompile the solvers for every new size. They can be dramatically faster for small sizes (up to approximately size 10), but for larger equations they increase compile time with little to no benefit.","category":"page"},{"location":"highlevels/array_libraries/#CUDA.jl:-NVIDIA-CUDA-Based-GPU-Array-Computations","page":"Modeling Array Libraries","title":"CUDA.jl: NVIDIA CUDA-Based GPU Array Computations","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"CUDA.jl is the library for defining arrays which live on NVIDIA GPUs (CuArray). SciML's libraries will respect the GPU-ness of the inputs, i.e., if the input arrays live on the GPU then the operations will all take place on the GPU or else the libraries will error if it's unable to do so. Thus, using CUDA.jl's CuArray is how one GPU-accelerates any computation with the SciML organization's libraries. Simply use a CuArray as the initial condition to an ODE solve or as the initial guess for a nonlinear solve, and the whole solve will recompile to take place on the GPU.","category":"page"},{"location":"highlevels/array_libraries/#AMDGPU.jl:-AMD-Based-GPU-Array-Computations","page":"Modeling Array Libraries","title":"AMDGPU.jl: AMD-Based GPU Array Computations","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"AMDGPU.jl is the library for defining arrays which live on AMD GPUs (ROCArray). SciML's libraries will respect the GPU-ness of the inputs, i.e., if the input arrays live on the GPU then the operations will all take place on the GPU or else the libraries will error if it's unable to do so. Thus using AMDGPU.jl's ROCArray is how one GPU-accelerates any computation with the SciML organization's libraries. Simply use a ROCArray as the initial condition to an ODE solve or as the initial guess for a nonlinear solve, and the whole solve will recompile to take place on the GPU.","category":"page"},{"location":"highlevels/array_libraries/#FillArrays.jl:-Lazy-Arrays","page":"Modeling Array Libraries","title":"FillArrays.jl: Lazy Arrays","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"FillArrays.jl is a library for defining arrays with lazy values. For example, an O(1) representation of the identity matrix is given by Eye{Int}(5). FillArrays.jl is used extensively throughout the ecosystem to improve runtime and memory performance.","category":"page"},{"location":"highlevels/array_libraries/#BandedMatrices.jl:-Fast-Banded-Matrices","page":"Modeling Array Libraries","title":"BandedMatrices.jl: Fast Banded Matrices","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"Banded matrices show up in many equation solver contexts, such as the Jacobians of many partial differential equations. While the base SparseMatrixCSC sparse matrix type can represent such matrices, BandedMatrices.jl is a specialized format specifically for BandedMatrices which can be used to greatly improve performance of operations on a banded matrix.","category":"page"},{"location":"highlevels/array_libraries/#BlockBandedMatrices.jl:-Fast-Block-Banded-Matrices","page":"Modeling Array Libraries","title":"BlockBandedMatrices.jl: Fast Block-Banded Matrices","text":"","category":"section"},{"location":"highlevels/array_libraries/","page":"Modeling Array Libraries","title":"Modeling Array Libraries","text":"Block banded matrices show up in many equation solver contexts, such as the Jacobians of many systems of partial differential equations. While the base SparseMatrixCSC sparse matrix type can represent such matrices, BlockBandedMatrices.jl is a specialized format specifically for BlockBandedMatrices which can be used to greatly improve performance of operations on a block-banded matrix.","category":"page"},{"location":"comparisons/r/#r","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"","category":"section"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"If you're an R user who has looked into Julia, you're probably wondering where all of the scientific computing packages are. How do I solve ODEs? Solve f(x)=0 for x? Etc. SciML is the ecosystem for doing this with Julia.","category":"page"},{"location":"comparisons/r/#Why-SciML?-High-Level-Workflow-Reasons","page":"Getting Started with Julia's SciML for the R User","title":"Why SciML? High-Level Workflow Reasons","text":"","category":"section"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"Performance - The key reason people are moving from R to Julia's SciML in droves is performance. Even simple ODE solvers are much faster!, demonstrating orders of magnitude performance improvements for differential equations, nonlinear solving, optimization, and more. And the performance advantages continue to grow as more complex algorithms are required.\nComposable Library Components - In R environments, every package feels like a silo. Functions made for one file exchange library cannot easily compose with another. SciML's generic coding with JIT compilation these connections create new optimized code on the fly and allow for a more expansive feature set than can ever be documented. Take new high-precision number types from a package and stick them into a nonlinear solver. Take a package for Intel GPU arrays and stick it into the differential equation solver to use specialized hardware acceleration.\nA Global Harmonious Documentation for Scientific Computing - R's documentation for scientific computing is scattered in a bunch of individual packages where the developers do not talk to each other! This not only leads to documentation differences, but also “style” differences: one package uses tol while the other uses atol. With Julia's SciML, the whole ecosystem is considered together, and inconsistencies are handled at the global level. The goal is to be working in one environment with one language.\nEasier High-Performance and Parallel Computing - With Julia's ecosystem, CUDA will automatically install of the required binaries and cu(A)*cu(B) is then all that's required to GPU-accelerate large-scale linear algebra. MPI is easy to install and use. Distributed computing through password-less SSH. Multithreading is automatic and baked into many libraries, with a specialized algorithm to ensure hierarchical usage does not oversubscribe threads. Basically, libraries give you a lot of parallelism for free, and doing the rest is a piece of cake.\nMix Scientific Computing with Machine Learning - Want to automate the discovery of missing physical laws using neural networks embedded in differentiable simulations? Julia's SciML is the ecosystem with the tooling to integrate machine learning into the traditional high-performance scientific computing domains, from multiphysics simulations to partial differential equations.","category":"page"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"In this plot, deSolve in blue represents R's most commonly used solver:","category":"page"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"(Image: )","category":"page"},{"location":"comparisons/r/#Need-Help-Translating-from-R-to-Julia?","page":"Getting Started with Julia's SciML for the R User","title":"Need Help Translating from R to Julia?","text":"","category":"section"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"The following resources can be particularly helpful when adopting Julia for SciML for the first time:","category":"page"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"The Julia Manual's Noteworthy Differences from R page\nTutorials on Data Wrangling and Plotting in Julia (Sections 4 and 5) written for folks with a background in R.\nDouble-check your results with deSolveDiffEq.jl (automatically converts and runs ODE definitions with R's deSolve solvers)\nUse RCall.jl to more incrementally move code to Julia.\nComparisons between R and Julia from the DataFrames package. And an accessible starting point for Julia's DataFrames.","category":"page"},{"location":"comparisons/r/#R-to-Julia-SciML-Functionality-Translations","page":"Getting Started with Julia's SciML for the R User","title":"R to Julia SciML Functionality Translations","text":"","category":"section"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"The following chart will help you get quickly acquainted with Julia's SciML Tools:","category":"page"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"R Function/Package SciML-Supported Julia packages\ndata.frame DataFrames\nplot Plots, Makie\nggplot2 AlgebraOfGraphics\ndeSolve DifferentialEquations\nStan Turing","category":"page"},{"location":"comparisons/r/#Want-to-See-the-Power-of-Julia?","page":"Getting Started with Julia's SciML for the R User","title":"Want to See the Power of Julia?","text":"","category":"section"},{"location":"comparisons/r/","page":"Getting Started with Julia's SciML for the R User","title":"Getting Started with Julia's SciML for the R User","text":"Check out this R-Bloggers blog post on diffeqr, a package which uses ModelingToolkit to translate R code to Julia, and achieves 350x acceleration over R's popular deSolve ODE solver package. But when the solve is done purely in Julia, it achieves 2777x acceleration over deSolve!","category":"page"},{"location":"showcase/showcase/#showcase","page":"The SciML Showcase","title":"The SciML Showcase","text":"","category":"section"},{"location":"showcase/showcase/","page":"The SciML Showcase","title":"The SciML Showcase","text":"The SciML Showcase is a display of some cool things that can be done by connecting SciML software.","category":"page"},{"location":"showcase/showcase/","page":"The SciML Showcase","title":"The SciML Showcase","text":"note: Note\nThe SciML Showcase is not meant to be training/tutorials, but inspirational demonstrations! If you're looking for simple examples to get started with, check out the getting started section.","category":"page"},{"location":"showcase/showcase/","page":"The SciML Showcase","title":"The SciML Showcase","text":"Want to see some cool things that you can do with SciML? Check out the following:","category":"page"},{"location":"showcase/showcase/","page":"The SciML Showcase","title":"The SciML Showcase","text":"Scientific machine learning: incorporating prior physics into automated model discovery\nAuto-complete mechanistic models by embedding machine learning into differential equations\nBayesian automated model discovery with quantified uncertainties and probability estimates\nDiscovering the Relativistic Corrections to Binary Black Hole Dynamics\nSolving big difficult equations with parallelism, speed, and accuracy\nAutomated Efficient Solution of Nonlinear Partial Differential Equations\nGPU-Accelerated Physics-Informed Neural Network PDE Solvers\nMassively Data-Parallel ODE Solving on GPUs\nGPU-Accelerated Stochastic Partial Differential Equations\nUseful cool wonky things that are hard to find anywhere else\nAutomatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System\nSymbolic-Numeric Analysis of Parameter Identifiability and Model Stability\nOptimization Under Uncertainty","category":"page"},{"location":"highlevels/equation_solvers/#Equation-Solvers","page":"Equation Solvers","title":"Equation Solvers","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"The SciML Equation Solvers cover a large set of SciMLProblems with SciMLAlgorithms that are efficient, numerically stable, and flexible. These methods tie into libraries like SciMLSensitivity.jl to be fully differentiable and compatible with machine learning pipelines, and are designed for integration with applications like parameter estimation, global sensitivity analysis, and more.","category":"page"},{"location":"highlevels/equation_solvers/#LinearSolve.jl:-Unified-Interface-for-Linear-Solvers","page":"Equation Solvers","title":"LinearSolve.jl: Unified Interface for Linear Solvers","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"LinearSolve.jl is the canonical library for solving LinearProblems. It includes:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Fast pure Julia LU factorizations which outperform standard BLAS\nKLU for faster sparse LU factorization on unstructured matrices\nUMFPACK for faster sparse LU factorization on matrices with some repeated structure\nMKLPardiso wrappers for handling many sparse matrices faster than SuiteSparse (KLU, UMFPACK) methods\nGPU-offloading for large dense matrices\nWrappers to all of the Krylov implementations (Krylov.jl, IterativeSolvers.jl, KrylovKit.jl) for easy testing of all of them. LinearSolve.jl handles the API differences, especially with the preconditioner definitions\nA polyalgorithm that smartly chooses between these methods\nA caching interface which automates caching of symbolic factorizations and numerical factorizations as optimally as possible\nCompatible with arbitrary AbstractArray and Number types, such as GPU-based arrays, uncertainty quantification number types, and more.","category":"page"},{"location":"highlevels/equation_solvers/#NonlinearSolve.jl:-Unified-Interface-for-Nonlinear-Solvers","page":"Equation Solvers","title":"NonlinearSolve.jl: Unified Interface for Nonlinear Solvers","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"NonlinearSolve.jl is the canonical library for solving NonlinearProblems. It includes:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Fast non-allocating implementations on static arrays of common methods (Newton-Rhapson)\nBracketing methods (Bisection, Falsi) for methods with known upper and lower bounds (IntervalNonlinearProblem)\nWrappers to common other solvers (NLsolve.jl, MINPACK, KINSOL from Sundials) for trust region methods, line search-based approaches, etc.\nBuilt over the LinearSolve.jl API for maximum flexibility and performance in the solving approach\nCompatible with arbitrary AbstractArray and Number types, such as GPU-based arrays, uncertainty quantification number types, and more.","category":"page"},{"location":"highlevels/equation_solvers/#DifferentialEquations.jl:-Unified-Interface-for-Differential-Equation-Solvers","page":"Equation Solvers","title":"DifferentialEquations.jl: Unified Interface for Differential Equation Solvers","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"DifferentialEquations.jl is the canonical library for solving DEProblems. This includes:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Discrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (DEProblems with callbacks and JumpProblem)","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"The well-optimized DifferentialEquations solvers benchmark as some of the fastest implementations of classic algorithms. It also includes algorithms from recent research which routinely outperform the “standard” C/Fortran methods, and algorithms optimized for high-precision and HPC applications. Simultaneously, it wraps the classic C/Fortran methods, making it easy to switch over to them whenever necessary. Solving differential equations with different methods from different languages and packages can be done by changing one line of code, allowing for easy benchmarking to ensure you are using the fastest method possible.","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"DifferentialEquations.jl integrates with the Julia package sphere. Examples are:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"GPU acceleration through CUDAnative.jl and CuArrays.jl\nAutomated sparsity detection with Symbolics.jl\nAutomatic Jacobian coloring with SparseDiffTools.jl, allowing for fast solutions to problems with sparse or structured (Tridiagonal, Banded, BlockBanded, etc.) Jacobians\nAllowing the specification of linear solvers for maximal efficiency\nProgress meter integration with the Juno IDE for estimated time to solution\nAutomatic plotting of time series and phase plots\nBuilt-in interpolations\nWraps for common C/Fortran methods, like Sundials and Hairer's radau\nArbitrary precision with BigFloats and Arbfloats\nArbitrary array types, allowing the definition of differential equations on matrices and distributed arrays\nUnit-checked arithmetic with Unitful","category":"page"},{"location":"highlevels/equation_solvers/#Optimization.jl:-Unified-Interface-for-Optimization","page":"Equation Solvers","title":"Optimization.jl: Unified Interface for Optimization","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Optimization.jl is the canonical library for solving OptimizationProblems. It includes wrappers of most of the Julia nonlinear optimization ecosystem, allowing one syntax to use all packages in a uniform manner. This covers:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"OptimizationBBO for BlackBoxOptim.jl\nOptimizationEvolutionary for Evolutionary.jl (see also this documentation)\nOptimizationGCMAES for GCMAES.jl\nOptimizationMOI for MathOptInterface.jl (usage of algorithm via MathOptInterface API; see also the API documentation)\nOptimizationMetaheuristics for Metaheuristics.jl (see also this documentation)\nOptimizationMultistartOptimization for MultistartOptimization.jl (see also this documentation)\nOptimizationNLopt for NLopt.jl (usage via the NLopt API; see also the available algorithms)\nOptimizationNOMAD for NOMAD.jl (see also this documentation)\nOptimizationNonconvex for Nonconvex.jl (see also this documentation)\nOptimizationQuadDIRECT for QuadDIRECT.jl\nOptimizationSpeedMapping for SpeedMapping.jl (see also this documentation)","category":"page"},{"location":"highlevels/equation_solvers/#Integrals.jl:-Unified-Interface-for-Numerical-Integration","page":"Equation Solvers","title":"Integrals.jl: Unified Interface for Numerical Integration","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Integrals.jl is the canonical library for solving IntegralsProblems. It includes wrappers of most of the Julia quadrature ecosystem, allowing one syntax to use all packages in a uniform manner. This covers:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Gauss-Kronrod quadrature\nCubature methods (both h and p cubature)\nAdaptive Monte Carlo methods","category":"page"},{"location":"highlevels/equation_solvers/#JumpProcesses.jl:-Stochastic-Simulation-Algorithms-for-Jump-Processes,-Jump-ODEs,-and-Jump-Diffusions","page":"Equation Solvers","title":"JumpProcesses.jl: Stochastic Simulation Algorithms for Jump Processes, Jump-ODEs, and Jump-Diffusions","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"JumpProcesses.jl is the library for Poisson jump processes, also known as chemical master equations or Gillespie simulations, for simulating chemical reaction networks and other applications. It allows for solving with many methods, including:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Direct: the Gillespie Direct method SSA.\nRDirect: A variant of Gillespie's Direct method that uses rejection to sample the next reaction.\nDirectCR: The Composition-Rejection Direct method of Slepoy et al. For large networks and linear chain-type networks, it will often give better performance than Direct. (Requires dependency graph, see below.)\nDirectFW: the Gillespie Direct method SSA with FunctionWrappers. This aggregator uses a different internal storage format for collections of ConstantRateJumps.\nFRM: the Gillespie first reaction method SSA. Direct should generally offer better performance and be preferred to FRM.\nFRMFW: the Gillespie first reaction method SSA with FunctionWrappers.\nNRM: The Gibson-Bruck Next Reaction Method. For some reaction network structures, this may offer better performance than Direct (for example, large, linear chains of reactions). (Requires dependency graph, see below.)\nRSSA: The Rejection SSA (RSSA) method of Thanh et al. With RSSACR, for very large reaction networks, it often offers the best performance of all methods. (Requires dependency graph, see below.)\nRSSACR: The Rejection SSA (RSSA) with Composition-Rejection method of Thanh et al. With RSSA, for very large reaction networks, it often offers the best performance of all methods. (Requires dependency graph, see below.)\nSortingDirect: The Sorting Direct Method of McCollum et al. It will usually offer performance as good as Direct, and for some systems can offer substantially better performance. (Requires dependency graph, see below.)","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"The design of JumpProcesses.jl composes with DifferentialEquations.jl, allowing for discrete stochastic chemical reactions to be easily mixed with differential equation models, allowing for simulation of hybrid systems, jump diffusions, and differential equations driven by Levy processes.","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"In addition, JumpProcesses's interfaces allow for solving with regular jump methods, such as adaptive Tau-Leaping.","category":"page"},{"location":"highlevels/equation_solvers/#Third-Party-Libraries-to-Note","page":"Equation Solvers","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/equation_solvers/#JuMP.jl:-Julia-for-Mathematical-Programming","page":"Equation Solvers","title":"JuMP.jl: Julia for Mathematical Programming","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"While Optimization.jl is the preferred library for nonlinear optimization, for all other forms of optimization Julia for Mathematical Programming (JuMP) is the star. JuMP is the leading choice in Julia for doing:","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"Linear Programming\nQuadratic Programming\nConvex Programming\nConic Programming\nSemidefinite Programming\nMixed-Complementarity Programming\nInteger Programming\nMixed Integer (nonlinear/linear) Programming\n(Mixed Integer) Second Order Conic Programming","category":"page"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"JuMP can also be used for some nonlinear programming, though the Optimization.jl bindings to the JuMP solvers (via MathOptInterface.jl) is generally preferred.","category":"page"},{"location":"highlevels/equation_solvers/#FractionalDiffEq.jl:-Fractional-Differential-Equation-Solvers","page":"Equation Solvers","title":"FractionalDiffEq.jl: Fractional Differential Equation Solvers","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"FractionalDiffEq.jl is a set of high-performance solvers for fractional differential equations.","category":"page"},{"location":"highlevels/equation_solvers/#ManifoldDiffEq.jl:-Solvers-for-Differential-Equations-on-Manifolds","page":"Equation Solvers","title":"ManifoldDiffEq.jl: Solvers for Differential Equations on Manifolds","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"ManifoldDiffEq.jl is a set of high-performance solvers for differential equations on manifolds using methods such as Lie Group actions and frozen coefficients (Crouch-Grossman methods). These solvers can in many cases out-perform the OrdinaryDiffEq.jl nonautonomous operator ODE solvers by using methods specialized on manifold definitions of ManifoldsBase.","category":"page"},{"location":"highlevels/equation_solvers/#Manopt.jl:-Optimization-on-Manifolds","page":"Equation Solvers","title":"Manopt.jl: Optimization on Manifolds","text":"","category":"section"},{"location":"highlevels/equation_solvers/","page":"Equation Solvers","title":"Equation Solvers","text":"ManOpt.jl allows for easy and efficient solving of nonlinear optimization problems on manifolds.","category":"page"},{"location":"comparisons/matlab/#matlab","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"","category":"section"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"If you're a MATLAB user who has looked into Julia for some performance improvements, you may have noticed that the standard library does not have all of the “batteries” included with a base MATLAB installation. Where's the ODE solver? Where's fmincon and fsolve? Those scientific computing functionalities are the pieces provided by the Julia SciML ecosystem!","category":"page"},{"location":"comparisons/matlab/#Why-SciML?-High-Level-Workflow-Reasons","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Why SciML? High-Level Workflow Reasons","text":"","category":"section"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"Performance - The key reason people are moving from MATLAB to Julia's SciML in droves is performance. Even simple ODE solvers are much faster!, demonstrating orders of magnitude performance improvements for differential equations, nonlinear solving, optimization, and more. And the performance advantages continue to grow as more complex algorithms are required.\nJulia is quick to learn from MATLAB - Most ODE codes can be translated in a few minutes. If you need help, check out the QuantEcon MATLAB-Python-Julia Cheat Sheet.\nPackage Management and Versioning - Julia's package manager takes care of dependency management, testing, and continuous delivery in order to make the installation and maintenance process smoother. For package users, this means it's easier to get packages with complex functionality in your hands.\nFree and Open Source - If you want to know how things are being computed, just look at our GitHub organization. Lots of individuals use Julia's SciML to research how the algorithms actually work because of how accessible and tweakable the ecosystem is!\nComposable Library Components - In MATLAB environments, every package feels like a silo. Functions made for one file exchange library cannot easily compose with another. SciML's generic coding with JIT compilation these connections create new optimized code on the fly and allow for a more expansive feature set than can ever be documented. Take new high-precision number types from a package and stick them into a nonlinear solver. Take a package for Intel GPU arrays and stick it into the differential equation solver to use specialized hardware acceleration.\nEasier High-Performance and Parallel Computing - With Julia's ecosystem, CUDA will automatically install of the required binaries and cu(A)*cu(B) is then all that's required to GPU-accelerate large-scale linear algebra. MPI is easy to install and use. Distributed computing through password-less SSH. Multithreading is automatic and baked into many libraries, with a specialized algorithm to ensure hierarchical usage does not oversubscribe threads. Basically, libraries give you a lot of parallelism for free, and doing the rest is a piece of cake.\nMix Scientific Computing with Machine Learning - Want to automate the discovery of missing physical laws using neural networks embedded in differentiable simulations? Julia's SciML is the ecosystem with the tooling to integrate machine learning into the traditional high-performance scientific computing domains, from multiphysics simulations to partial differential equations.","category":"page"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"In this plot, MATLAB in orange represents MATLAB's most commonly used solvers:","category":"page"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"(Image: )","category":"page"},{"location":"comparisons/matlab/#Need-a-case-study?","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Need a case study?","text":"","category":"section"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"Check out this talk from NASA Scientists getting a 15,000x acceleration by switching from Simulink to Julia's ModelingToolkit!","category":"page"},{"location":"comparisons/matlab/#Need-Help-Translating-from-MATLAB-to-Julia?","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Need Help Translating from MATLAB to Julia?","text":"","category":"section"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"The following resources can be particularly helpful when adopting Julia for SciML for the first time:","category":"page"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"QuantEcon MATLAB-Python-Julia Cheat Sheet\nThe Julia Manual's Noteworthy Differences from MATLAB page\nDouble-check your results with MATLABDiffEq.jl (automatically converts and runs ODE definitions with MATLAB's solvers)\nUse MATLAB.jl to more incrementally move code to Julia.","category":"page"},{"location":"comparisons/matlab/#MATLAB-to-Julia-SciML-Functionality-Translations","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"MATLAB to Julia SciML Functionality Translations","text":"","category":"section"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"The following chart will help you get quickly acquainted with Julia's SciML Tools:","category":"page"},{"location":"comparisons/matlab/","page":"Getting Started with  Julia's SciML for the MATLAB User","title":"Getting Started with  Julia's SciML for the MATLAB User","text":"MATLAB Function SciML-Supported Julia packages\nplot Plots, Makie\nsparse SparseArrays\ninterp1 DataInterpolations\n\\, gmres, cg LinearSolve\nfsolve NonlinearSolve\nquad Integrals\nfmincon Optimization\nodeXX DifferentialEquations\node45 Tsit5\node113 VCABM\node23s Rosenbrock23\node15s QNDF or FBDF\node15i IDA\nbvp4c and bvp5c DifferentialEquations\nSimulink, Simscape ModelingToolkit\nfft FFTW\nchebfun ApproxFun","category":"page"},{"location":"highlevels/inverse_problems/#parameter_estimation","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"Parameter estimation for models and equations, also known as dynamic data analysis, solving the inverse problem, or Bayesian posterior estimation (when done probabilistically), is provided by the SciML tools for the equations in its set. In this introduction, we briefly present the relevant packages that facilitate parameter estimation, namely:","category":"page"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"SciMLSensitivity.jl\nDiffEqFlux.jl\nTuring.jl\nDataDrivenDiffEq.jl\nDiffEqParamEstim.jl\nDiffEqBayes.jl","category":"page"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"We also provide information regarding the respective strengths of these packages so that you can easily decide which one suits your needs best.","category":"page"},{"location":"highlevels/inverse_problems/#SciMLSensitivity.jl:-Local-Sensitivity-Analysis-and-Automatic-Differentiation-Support-for-Solvers","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"SciMLSensitivity.jl: Local Sensitivity Analysis and Automatic Differentiation Support for Solvers","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"SciMLSensitivity.jl is the system for local sensitivity, which all other inverse problem methods rely on. This package defines the interactions between the equation solvers and automatic differentiation, defining fast overloads for forward and adjoint (reverse) sensitivity analysis for fast gradient and Jacobian calculations with respect to model inputs. Its documentation covers how to use direct differentiation of equation solvers in conjunction with tools like Optimization.jl to perform model calibration of ODEs against data, PDE-constrained optimization, nonlinear optimal controls analysis, and much more. As a lower level tool, this library is very versatile, feature-rich, and high-performance, giving all the tools required but not directly providing a higher level interface.","category":"page"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"note: Note\nSensitivity analysis is kept in a separate library from the solvers (SciMLSensitivity.jl), in order to not require all equation solvers to have a dependency on all automatic differentiation libraries. If automatic differentiation is applied to a solver library without importing SciMLSensitivity.jl, an error is thrown letting the user know to import SciMLSensitivity.jl for the functionality to exist.","category":"page"},{"location":"highlevels/inverse_problems/#DataDrivenDiffEq.jl:-Data-Driven-Modeling-and-Equation-Discovery","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"DataDrivenDiffEq.jl: Data-Driven Modeling and Equation Discovery","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"The distinguishing feature of this package is that its ultimate goal is to identify the differential equation model that generated the input data. Depending on the user's needs, the package can provide structural identification of a given differential equation (output in a symbolic form) or structural estimation (output as a function for prediction purposes).","category":"page"},{"location":"highlevels/inverse_problems/#DiffEqParamEstim.jl:-Simplified-Parameter-Estimation-Interface","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"DiffEqParamEstim.jl: Simplified Parameter Estimation Interface","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"This package is for simplified parameter estimation. While not as flexible of a system like DiffEqFlux.jl, it provides ready-made functions for doing standard optimization procedures like L2 fitting and MAP estimates. Among other features, it allows for the optimization of parameters in ODEs, stochastic problems, and delay differential equations.","category":"page"},{"location":"highlevels/inverse_problems/#DiffEqBayes.jl:-Simplified-Bayesian-Estimation-Interface","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"DiffEqBayes.jl: Simplified Bayesian Estimation Interface","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"As the name suggests, this package has been designed to provide the estimation of differential equations parameters by Bayesian methods. It works in conjunction with Turing.jl, CmdStan.jl, DynamicHMC.jl, and ApproxBayes.jl. While not as flexible as direct usage of DiffEqFlux.jl or Turing.jl, DiffEqBayes.jl can be an approachable interface for those not familiar with Bayesian estimation, and provides a nice way to use Stan from pure Julia.","category":"page"},{"location":"highlevels/inverse_problems/#Third-Party-Tools-of-Note","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Third-Party Tools of Note","text":"","category":"section"},{"location":"highlevels/inverse_problems/#Turing.jl:-A-Flexible-Probabilistic-Programming-Language-for-Bayesian-Analysis","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Turing.jl: A Flexible Probabilistic Programming Language for Bayesian Analysis","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"In the context of differential equations and parameter estimation, Turing.jl allows for a Bayesian estimation of differential equations (used in conjunction with the high-level package DiffEqBayes.jl). For more examples on combining Turing.jl with DiffEqBayes.jl, see the documentation below. It is important to note that Turing.jl can also perform Bayesian estimation without relying on DiffEqBayes.jl (for an example, consult this tutorial).","category":"page"},{"location":"highlevels/inverse_problems/#Topopt.jl:-Topology-Optimization-in-Julia","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Topopt.jl: Topology Optimization in Julia","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"Topopt.jl solves topology optimization problems which are inverse problems on partial differential equations, solving for an optimal domain.","category":"page"},{"location":"highlevels/inverse_problems/#Recommended-Automatic-Differentiation-Libraries","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Recommended Automatic Differentiation Libraries","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"Solving inverse problems commonly requires using automatic differentiation (AD). SciML includes extensive support for automatic differentiation throughout its solvers, though some AD libraries are more tested than others. The following libraries are the current recommendations of the SciML developers.","category":"page"},{"location":"highlevels/inverse_problems/#ForwardDiff.jl:-Operator-Overloading-Forward-Mode-Automatic-Differentiation","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"ForwardDiff.jl: Operator-Overloading Forward Mode Automatic Differentiation","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"ForwardDiff.jl is a library for operator-overloading based forward-mode automatic differentiation. It's commonly used as the default method for generating Jacobians throughout the SciML solver libraries.","category":"page"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"note: Note\nBecause ForwardDiff.jl uses an operator overloading approach, uses of ForwardDiff.jl require that any caches for non-allocating mutating code allows for Dual numbers. To allow such code to be ForwardDiff.jl-compatible, see PreallocationTools.jl.","category":"page"},{"location":"highlevels/inverse_problems/#Enzyme.jl:-LLVM-Level-Forward-and-Reverse-Mode-Automatic-Differentiation","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Enzyme.jl: LLVM-Level Forward and Reverse Mode Automatic Differentiation","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"Enzyme.jl is an LLVM-level AD library for forward and reverse automatic differentiation. It supports many features required for high performance, such as being able to differentiate mutating and interleave compiler optimization with the AD passes. However, it does not support all of the Julia runtime, and thus some code with many dynamic behaviors and garbage collection (GC) invocations can be incompatible with Enzyme. Enzyme.jl is quickly becoming the new standard AD for SciML.","category":"page"},{"location":"highlevels/inverse_problems/#Zygote.jl:-Julia-Level-Source-to-Source-Reverse-Mode-Automatic-Differentiation","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Zygote.jl: Julia-Level Source-to-Source Reverse Mode Automatic Differentiation","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"Zygote.jl is the current standard user-level reverse-mode automatic differentiation library for the SciML solvers. User-level means that many library tutorials, like in SciMLSensitivity.jl and DiffEqFlux.jl, showcase user code using Zygote.jl. This is because Zygote.jl is the AD engine associated with the Flux machine learning library. However, Zygote.jl has many limitations which limits its performance in equation solver contexts, such as an inability to handle mutation and introducing many small allocations and type-instabilities. For this reason, the SciML equation solvers define differentiation overloads using ChainRules.jl, meaning that the equation solvers tend not to use Zygote.jl internally even if the user code uses Zygote.gradient. In this manner, the speed and performance of more advanced techniques can be preserved while using the Julia standard.","category":"page"},{"location":"highlevels/inverse_problems/#FiniteDiff.jl:-Fast-Finite-Difference-Approximations","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"FiniteDiff.jl: Fast Finite Difference Approximations","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"FiniteDiff.jl is the preferred fallback library for numerical differentiation and is commonly used by SciML solver libraries when automatic differentiation is disabled.","category":"page"},{"location":"highlevels/inverse_problems/#SparseDiffTools.jl:-Tools-for-Fast-Automatic-Differentiation-with-Sparse-Operators","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"SparseDiffTools.jl: Tools for Fast Automatic Differentiation with Sparse Operators","text":"","category":"section"},{"location":"highlevels/inverse_problems/","page":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","title":"Parameter Estimation, Bayesian Analysis, and Inverse Problems","text":"SparseDiffTools.jl is a library for sparse automatic differentiation. It's used internally by many of the SciML equation solver libraries, which explicitly expose interfaces for colorvec color vectors generated by SparseDiffTools.jl's methods. SparseDiffTools.jl also includes many features useful to users, such as operators for matrix-free Jacobian-vector and Hessian-vector products.","category":"page"},{"location":"getting_started/find_root/#find_root","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"A nonlinear system f(u) = 0 is specified by defining a function f(u,p), where p are the parameters of the system. Many problems can be written in such a way that solving a nonlinear rootfinding problem gives the solution. For example:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Do you want to know u such that 4^u + 6^u = 7^u? Then solve f(u) = 4^u + 6^u - 7^u = 0 for u!\nIf you have an ODE u = f(u), what is the point where the solution will be completely still, i.e. u' = 0?","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"All of these problems are solved by using a numerical rootfinder. Let's solve our first rootfind problem!","category":"page"},{"location":"getting_started/find_root/#Required-Dependencies","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Required Dependencies","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"The following parts of the SciML Ecosystem will be used in this tutorial:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Module Description\nModelingToolkit.jl The symbolic modeling environment\nNonlinearSolve.jl The numerical solvers for nonlinear equations","category":"page"},{"location":"getting_started/find_root/#Problem-Setup","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Problem Setup","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"For example, the following solves the vector equation:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"beginaligned\n0 = σ*(y-x)\n0 = x*(ρ-z)-y\n0 = x*y - β*z\nendaligned","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"With the parameter values sigma = 100, rho = 260, beta = 83.","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"# Import the packages\nusing ModelingToolkit, NonlinearSolve\n\n# Define the nonlinear system\n@variables x=1.0 y=0.0 z=0.0\n@parameters σ=10.0 ρ=26.0 β=8 / 3\n\neqs = [0 ~ σ * (y - x),\n    0 ~ x * (ρ - z) - y,\n    0 ~ x * y - β * z]\n@mtkbuild ns = NonlinearSystem(eqs, [x, y, z], [σ, ρ, β])\n\n# Convert the symbolic system into a numerical system\nprob = NonlinearProblem(ns, [])\n\n# Solve the numerical problem\nsol = solve(prob, NewtonRaphson())\n\n# Analyze the solution\n@show sol[[x, y, z]], sol.resid","category":"page"},{"location":"getting_started/find_root/#Step-by-Step-Solution","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Step-by-Step Solution","text":"","category":"section"},{"location":"getting_started/find_root/#Step-1:-Import-the-Packages","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Step 1: Import the Packages","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"To do this tutorial, we will need a few components:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"ModelingToolkit.jl, our modeling environment\nNonlinearSolve.jl, the nonlinear system solvers","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"To start, let's add these packages as demonstrated in the installation tutorial:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"using Pkg\nPkg.add([\"ModelingToolkit\", \"NonlinearSolve\"])","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Now we're ready. Let's load in these packages:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"# Import the packages\nusing ModelingToolkit, NonlinearSolve","category":"page"},{"location":"getting_started/find_root/#Step-2:-Define-the-Nonlinear-System","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Step 2: Define the Nonlinear System","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Now let's define our nonlinear system. We use the ModelingToolkit.@variabes statement to declare our 3 state variables:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"# Define the nonlinear system\n@variables x=1.0 y=0.0 z=0.0","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Notice that we are using the form state = initial condition. This is a nice shorthand for coupling an initial condition to our states. We now must similarly define our parameters, which we can associate default values via the form parameter = default value. This looks like:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"@parameters σ=10.0 ρ=26.0 β=8 / 3","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Now we create an array of equations to define our nonlinear system that must be satisfied. This looks as follows:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"note: Note\nNote that in ModelingToolkit and Symbolics, ~ is used for equation equality. This is separate from = which is the “assignment operator” in the Julia programming language. For example, x = x + 1 is a valid assignment in a programming language, and it is invalid for that to represent “equality”, which is why a separate operator is used!","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"eqs = [0 ~ σ * (y - x),\n    0 ~ x * (ρ - z) - y,\n    0 ~ x * y - β * z]","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Finally, we bring these pieces together, the equation along with its states and parameters, define our NonlinearSystem:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"@mtkbuild ns = NonlinearSystem(eqs, [x, y, z], [σ, ρ, β])","category":"page"},{"location":"getting_started/find_root/#Step-3:-Convert-the-Symbolic-Problem-to-a-Numerical-Problem","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Step 3: Convert the Symbolic Problem to a Numerical Problem","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Now that we have created our system, let's turn it into a numerical problem to approximate. This is done with the NonlinearProblem constructor, that transforms it from a symbolic ModelingToolkit representation to a numerical NonlinearSolve representation. We need to tell it the numerical details for whether to override any of the default values for the initial conditions and parameters.","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"In this case, we will use the default values for all our variables, so we will pass a blank override []. This looks like:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"# Convert the symbolic system into a numerical system\nprob = NonlinearProblem(ns, [])","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"If we did want to change the initial condition of x to 2.0 and the parameter σ to 4.0, we would do [x => 2.0, σ => 4.0]. This looks like:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"prob2 = NonlinearProblem(ns, [x => 2.0, σ => 4.0])","category":"page"},{"location":"getting_started/find_root/#Step-4:-Solve-the-Numerical-Problem","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Step 4: Solve the Numerical Problem","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Now we solve the nonlinear system. For this, we choose a solver from the NonlinearSolve.jl's solver options. We will choose NewtonRaphson as follows:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"# Solve the numerical problem\nsol = solve(prob, NewtonRaphson())","category":"page"},{"location":"getting_started/find_root/#Step-5:-Analyze-the-Solution","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Step 5: Analyze the Solution","text":"","category":"section"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"Now let's check out the solution. First of all, what kind of thing is the sol? We can see that by asking for its type:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"typeof(sol)","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"From this, we can see that it is an NonlinearSolution. We can see the documentation for how to use the NonlinearSolution by checking the NonlinearSolve.jl solution type page. For example, the solution is stored as .u. What is the solution to our nonlinear system, and what is the final residual value? We can check it as follows:","category":"page"},{"location":"getting_started/find_root/","page":"Find the root of an equation (i.e. solve f(u)=0)","title":"Find the root of an equation (i.e. solve f(u)=0)","text":"# Analyze the solution\n@show sol[[x, y, z]], sol.resid","category":"page"},{"location":"highlevels/uncertainty_quantification/#Uncertainty-Quantification","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"There's always uncertainty in our models. Whether it's in the form of the model's equations or in the model's parameters, the uncertainty in our simulation's output often needs to be quantified. The following tools automate this process.","category":"page"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"For Measurements.jl vs MonteCarloMeasurements.jl vs Intervals.jl, and the relation to other methods, see the Uncertainty Programming chapter of the SciML Book.","category":"page"},{"location":"highlevels/uncertainty_quantification/#PolyChaos.jl:-Intrusive-Polynomial-Chaos-Expansions-Made-Unintrusive","page":"Uncertainty Quantification","title":"PolyChaos.jl: Intrusive Polynomial Chaos Expansions Made Unintrusive","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"PolyChaos.jl is a library for calculating intrusive polynomial chaos expansions (PCE) on arbitrary Julia functions. This allows for inputting representations of probability distributions into functions to compute the output distribution in an expansion representation. While normally this would require deriving the PCE-expanded equations by hand, PolyChaos.jl does this at the compiler level using Julia's multiple dispatch, giving a high-performance implementation to a normally complex and tedious mathematical transformation.","category":"page"},{"location":"highlevels/uncertainty_quantification/#SciMLExpectations.jl:-Fast-Calculations-of-Expectations-of-Equation-Solutions","page":"Uncertainty Quantification","title":"SciMLExpectations.jl: Fast Calculations of Expectations of Equation Solutions","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"SciMLExpectations.jl is a library for accelerating the calculation of expectations of equation solutions with respect to input probability distributions, allowing for applications like robust optimization with respect to uncertainty. It uses Koopman operator techniques to calculate these expectations without requiring the propagation of uncertainties through a solver, effectively performing the adjoint of uncertainty quantification and being much more efficient in the process.","category":"page"},{"location":"highlevels/uncertainty_quantification/#Third-Party-Libraries-to-Note","page":"Uncertainty Quantification","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/#Measurements.jl:-Automated-Linear-Error-Propagation","page":"Uncertainty Quantification","title":"Measurements.jl: Automated Linear Error Propagation","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Measurements.jl is a library for automating linear error propagation. Uncertain numbers are defined as x = 3.8 ± 0.4 and are pushed through calculations using a normal distribution approximation in order to compute an approximate uncertain output. Measurements.jl uses a dictionary-based approach to keep track of correlations to improve the accuracy over naive implementations, though note that linear error propagation theory still has some major issues handling some types of equations, as described in detail in the MonteCarloMeasurements.jl documentation.","category":"page"},{"location":"highlevels/uncertainty_quantification/#MonteCarloMeasurements.jl:-Automated-Monte-Carlo-Error-Propagation","page":"Uncertainty Quantification","title":"MonteCarloMeasurements.jl: Automated Monte Carlo Error Propagation","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"MonteCarloMeasurements.jl is a library for automating the uncertainty quantification of equation solution using Monte Carlo methods. It defines number types which sample from an input distribution to receive a representative set of parameters that propagate through the solver to calculate a representative set of possible solutions. Note that Monte Carlo techniques can be expensive but are exact, in the sense that as the number of sample points increases to infinity it will compute a correct approximation of the output uncertainty.","category":"page"},{"location":"highlevels/uncertainty_quantification/#ProbNumDiffEq.jl:-Probabilistic-Numerics-Based-Differential-Equation-Solvers","page":"Uncertainty Quantification","title":"ProbNumDiffEq.jl: Probabilistic Numerics Based Differential Equation Solvers","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"ProbNumDiffEq.jl is a set of probabilistic numerical ODE solvers which compute the solution of a differential equation along with a posterior distribution to estimate its numerical approximation error. Thus these specialized integrators compute an uncertainty output similar to the ProbInts technique of DiffEqUncertainty, but use specialized integration techniques in order to do it much faster for specific kinds of equations.","category":"page"},{"location":"highlevels/uncertainty_quantification/#TaylorIntegration.jl:-Taylor-Series-Integration-for-Rigorous-Numerical-Bounds","page":"Uncertainty Quantification","title":"TaylorIntegration.jl: Taylor Series Integration for Rigorous Numerical Bounds","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"TaylorIntegration.jl is a library for Taylor series integrators, which has special functionality for computing the interval bound of possible solutions with respect to numerical approximation error.","category":"page"},{"location":"highlevels/uncertainty_quantification/#IntervalArithmetic.jl:-Rigorous-Numerical-Intervals","page":"Uncertainty Quantification","title":"IntervalArithmetic.jl: Rigorous Numerical Intervals","text":"","category":"section"},{"location":"highlevels/uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"IntervalArithmetic.jl is a library for performing interval arithmetic calculations on arbitrary Julia code. Interval arithmetic computes rigorous computations with respect to finite-precision floating-point arithmetic, i.e. its intervals are guaranteed to include the true solution. However, interval arithmetic intervals can grow at exponential rates in many problems, thus being unsuitable for analyses in many equation solver contexts.","category":"page"},{"location":"getting_started/installation/#installation","page":"Installing SciML Software","title":"Installing SciML Software","text":"","category":"section"},{"location":"getting_started/installation/#Step-1:-Install-Julia","page":"Installing SciML Software","title":"Step 1: Install Julia","text":"","category":"section"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"Download Julia using this website.","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"note: Note\nSome Linux distributions do weird and incorrect things with Julia installations! Please install Julia using the binaries provided by the official JuliaLang website!","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"To ensure that you have installed Julia correctly, open it up and type versioninfo() in the REPL. It should look like the following:","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"(Image: )","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"(with the CPU/OS/etc. details matching your computer!)","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"If you got stuck in this installation process, ask for help on the Julia Discourse or in the Julia Zulip chatrooms","category":"page"},{"location":"getting_started/installation/#Optional-Step-1.5:-Get-VS-Code-Setup-with-the-Julia-Extension","page":"Installing SciML Software","title":"Optional Step 1.5: Get VS Code Setup with the Julia Extension","text":"","category":"section"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"You can run SciML with Julia in any development environment you please, but our recommended environment is VS Code. For more information on using Julia with VS Code, check out the Julia VS Code Extension website. Let's install it!","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"First download VS Code from the official website.","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"Next, open Visual Studio Code and click Extensions.","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"(Image: )","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"Then, search for “Julia” in the search bar on the top of the extension tab, click on the “Julia” extension, and click the install button on the tab that opens up.","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"(Image: )","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"To make sure your installation is correct, try running some code. Open a new file by either going to the top left navigation bar File |> New Text File, or hitting Ctrl+n. Name your new file test.jl (important: the Julia VS Code functionality only turns on when using a .jl file!). Next, type 1+1 and hit Ctrl+Enter. A Julia REPL should pop up and the result 2 should be displayed. Your environment should look something like this:","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"(Image: )","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"For more help on using the VS Code editor with Julia, check out the VS Code in Julia documentation. Useful keyboard commands can be found here.","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"Once again, if you got stuck in this installation process, ask for help on the Julia Discourse or in the Julia Zulip chatrooms","category":"page"},{"location":"getting_started/installation/#Step-2:-Install-a-SciML-Package","page":"Installing SciML Software","title":"Step 2: Install a SciML Package","text":"","category":"section"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"SciML is over 130 Julia packages. That's too much stuff to give someone in a single download! Thus instead, the SciML organization divides its functionality into composable modules that can be mixed and matched as required. Installing SciML ecosystem functionality is equivalent to installation of such packages.","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"For example, do you need the differential equation solver? Then install DifferentialEquations via the command:","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"using Pkg;\nPkg.add(\"DifferentialEquations\");","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"in the Julia REPL. Or, for a more robust REPL experience, hit the ] command to make the blue pkg> REPL environment start, and type in add DifferentialEquations. The package REPL environment will have nice extras like auto-complete that will be useful in the future. This command should run an installation sequence and precompile all of the packages (precompile = \"run a bunch of performance optimizations!\"). Don't be surprised if this installation process takes ~10 minutes on older computers. During the installation, it should look like this:","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"(Image: )","category":"page"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"And that's it!","category":"page"},{"location":"getting_started/installation/#How-do-I-test-that-my-installed-correctly?","page":"Installing SciML Software","title":"How do I test that my installed correctly?","text":"","category":"section"},{"location":"getting_started/installation/","page":"Installing SciML Software","title":"Installing SciML Software","text":"The best way is to build and run your first simulation!","category":"page"},{"location":"highlevels/plots_visualization/#SciML-Supported-Plotting-and-Visualization-Libraries","page":"SciML-Supported Plotting and Visualization Libraries","title":"SciML-Supported Plotting and Visualization Libraries","text":"","category":"section"},{"location":"highlevels/plots_visualization/","page":"SciML-Supported Plotting and Visualization Libraries","title":"SciML-Supported Plotting and Visualization Libraries","text":"The following libraries are the plotting and visualization libraries which are supported and co-developed by the SciML developers. Other libraries may be used, though these are the libraries used in the tutorials and which have special hooks to ensure ergonomic usage with SciML tooling.","category":"page"},{"location":"highlevels/plots_visualization/#Plots.jl","page":"SciML-Supported Plotting and Visualization Libraries","title":"Plots.jl","text":"","category":"section"},{"location":"highlevels/plots_visualization/","page":"SciML-Supported Plotting and Visualization Libraries","title":"SciML-Supported Plotting and Visualization Libraries","text":"Plots.jl is the current standard plotting system for the SciML ecosystem. SciML types attempt to include plot recipes for as many types as possible, allowing for automatic visualization with the Plots.jl system. All current tutorials and documentation default to using Plots.jl.","category":"page"},{"location":"highlevels/plots_visualization/#Makie.jl","page":"SciML-Supported Plotting and Visualization Libraries","title":"Makie.jl","text":"","category":"section"},{"location":"highlevels/plots_visualization/","page":"SciML-Supported Plotting and Visualization Libraries","title":"SciML-Supported Plotting and Visualization Libraries","text":"Makie.jl is a high-performance interactive plotting system for the Julia programming language. It's planned to be the default plotting system used by the SciML organization in the near future.","category":"page"},{"location":"highlevels/model_libraries_and_importers/#Model-Libraries-and-Importers","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"","category":"section"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"Models are passed on from generation to generation. Many models are not built from scratch but have a legacy of the known physics, biology, and chemistry embedded into them. Julia's SciML offers a range of pre-built modeling tools, from reusable acausal components to direct imports from common file formats.","category":"page"},{"location":"highlevels/model_libraries_and_importers/#ModelingToolkitStandardLibrary.jl:-A-Standard-Library-for-ModelingToolkit","page":"Model Libraries and Importers","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"","category":"section"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"Given the composable nature of acausal modeling systems, it's helpful to not have to define every component from scratch and instead build off a common base of standard components. ModelingToolkitStandardLibrary.jl is that library. It provides components for standard models to start building everything from circuits and engines to robots.","category":"page"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"(Image: )","category":"page"},{"location":"highlevels/model_libraries_and_importers/#DiffEqCallbacks.jl:-Pre-Made-Callbacks-for-DifferentialEquations.jl","page":"Model Libraries and Importers","title":"DiffEqCallbacks.jl: Pre-Made Callbacks for DifferentialEquations.jl","text":"","category":"section"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"DiffEqCallbacks.jl has many event handling and callback definitions which allow for quickly building up complex differential equation models. It includes:","category":"page"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"Callbacks for specialized output and saving procedures\nCallbacks for enforcing domain constraints, positivity, and manifolds\nTimed callbacks for periodic dosing, presetting of tstops, and more\nCallbacks for determining and terminating at steady state\nCallbacks for controlling stepsizes and enforcing CFL conditions\nCallbacks for quantifying uncertainty with respect to numerical errors","category":"page"},{"location":"highlevels/model_libraries_and_importers/#SBMLToolkit.jl:-SBML-Import","page":"Model Libraries and Importers","title":"SBMLToolkit.jl: SBML Import","text":"","category":"section"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"SBMLToolkit.jl is a library for reading SBML files into the standard formats for Catalyst.jl and ModelingToolkit.jl. There are well over one thousand biological models available in the BioModels Repository.","category":"page"},{"location":"highlevels/model_libraries_and_importers/#CellMLToolkit.jl:-CellML-Import","page":"Model Libraries and Importers","title":"CellMLToolkit.jl: CellML Import","text":"","category":"section"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"CellMLToolkit.jl is a library for reading CellML files into the standard formats for ModelingToolkit.jl. There are several hundred biological models available in the CellML Model Repository.","category":"page"},{"location":"highlevels/model_libraries_and_importers/#ReactionNetworkImporters.jl:-BioNetGen-Import","page":"Model Libraries and Importers","title":"ReactionNetworkImporters.jl: BioNetGen Import","text":"","category":"section"},{"location":"highlevels/model_libraries_and_importers/","page":"Model Libraries and Importers","title":"Model Libraries and Importers","text":"ReactionNetworkImporters.jl is a library for reading BioNetGen .net files and various stoichiometry matrix representations into the standard formats for Catalyst.jl and ModelingToolkit.jl.","category":"page"},{"location":"comparisons/cppfortran/#cppfortran","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"","category":"section"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"You don't need help if you're a Fortran guru. I'm just kidding, you're not a Lisp developer. If you're coming from C++ or Fortran, you may be familiar with high-performance computing environments similar to SciML, such as PETSc, Trilinos, or Sundials. The following are some points to help the transition.","category":"page"},{"location":"comparisons/cppfortran/#Why-SciML?-High-Level-Workflow-Reasons","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Why SciML? High-Level Workflow Reasons","text":"","category":"section"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"If you're coming from “hardcore” C++/Fortran computing environments, some things to check out with Julia's SciML are:","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"Interactivity - use the interactive REPL to easily investigate numerical details.\nMetaprogramming performance tools - tools like LoopVectorization.jl can be used to generate faster code than even some of the most hand-optimized C++/Fortran code. Current benchmarks show this SIMD-optimized Julia code outperforming OpenBLAS and MKL BLAS implementations in many performance regimes.\nSymbolic modeling languages - writing models by hand can leave a lot of performance on the table. Using high-level modeling tools like ModelingToolkit can automate symbolic simplifications, which improve the stability and performance of numerical solvers. On complex models, even the best handwritten C++/Fortran code is orders of magnitude behind the code that symbolic tearing algorithms can achieve!\nComposable Library Components - In C++/Fortran environments, every package feels like a silo. Arrays made for PETSc cannot easily be used in Trilinos, and converting Sundials NVector outputs to DataFrames for post-simulation data processing is a process itself. The Julia SciML environment embraces interoperability. Don't wait for SciML to do it: by using generic coding with JIT compilation, these connections create new optimized code on the fly and allow for a more expansive feature set than can ever be documented. Take new high-precision number types from a package and stick them into a nonlinear solver. Take a package for Intel GPU arrays and stick it into the differential equation solver to use specialized hardware acceleration.\nWrappers to the Libraries You Know and Trust - Moving to SciML does not have to be a quick transition. SciML has extensive wrappers to many widely-used classical solver environments such as SUNDIALS and Hairer's classic Fortran ODE solvers (dopri5, dop853, etc.). Using these wrapped solvers is painless and can be swapped in for the Julia versions with one line of code. This gives you a way to incrementally adopt new features/methods while retaining the older pieces you know and trust.\nDon't Start from Scratch - SciML builds on the extensive Base library of Julia, and thus grows and improves with every update to the language. With hundreds of monthly contributors to SciML and hundreds of monthly contributors to Julia, SciML is one of the most actively developed open-source scientific computing ecosystems out there!\nEasier High-Performance and Parallel Computing - With Julia's ecosystem, CUDA will automatically install of the required binaries and cu(A)*cu(B) is then all that's required to GPU-accelerate large-scale linear algebra. MPI is easy to install and use. Distributed computing through password-less SSH. Multithreading is automatic and baked into many libraries, with a specialized algorithm to ensure hierarchical usage does not oversubscribe threads. Basically, libraries give you a lot of parallelism for free, and doing the rest is a piece of cake.\nMix Scientific Computing with Machine Learning - Want to automate the discovery of missing physical laws using neural networks embedded in differentiable simulations? Julia's SciML is the ecosystem with the tooling to integrate machine learning into the traditional high-performance scientific computing domains, from multiphysics simulations to partial differential equations.","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"In this plot, Sundials/Hairer in purple/red represent C++/Fortrans most commonly used solvers:","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"(Image: )","category":"page"},{"location":"comparisons/cppfortran/#Why-SciML?-Some-Technical-Details","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Why SciML? Some Technical Details","text":"","category":"section"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"Let's face the facts, in the open benchmarks the pure-Julia solvers tend to outperform the classic “best” C++ and Fortran solvers in almost every example (with a few notable exceptions). But why?","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"The answer is two-fold: Julia is as fast as C++/Fortran, and the algorithms are what matter.","category":"page"},{"location":"comparisons/cppfortran/#Julia-is-as-Fast-as-C/Fortran","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Julia is as Fast as C++/Fortran","text":"","category":"section"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"While Julia code looks high level like Python or MATLAB, its performance is on par with C++ and Fortran. At a technical level, when Julia code is type-stable, i.e. that the types that are returned from a function are deducible at compile-time from the types that go into a function, then Julia can optimize it as much as C++ or Fortran by automatically devirtualizing all dynamic behavior and compile-time optimizing the quasi-static code. This is not an empirical statement, it's a provable type-theoretic result. The resulting compiler used on the resulting quasi-static representation is LLVM, the same optimizing compiler used by clang and LFortran.","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"For more details on how Julia code is optimized and how to optimize your own Julia code, check out this chapter from the SciML Book.","category":"page"},{"location":"comparisons/cppfortran/#SciML's-Julia-Algorithms-Have-Performance-Advantages-in-Many-Common-Regimes","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"SciML's Julia Algorithms Have Performance Advantages in Many Common Regimes","text":"","category":"section"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"There are many ways which Julia's algorithms achieve performance advantages. Some facts to highlight include:","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"Julia is at the forefront of numerical methods research in many domains. This is highlighted in the differential equation solver comparisons, where the Julia solvers were the first to incorporate “newer” optimized Runge-Kutta tableaus, around half a decade before other software. Since then, the literature has only continued to evolve, and only Julia's SciML keeps up. At this point, many of the publication's first implementation is in OrdinaryDiffEq.jl with benchmark results run on the SciML Open Benchmarking platform!\nJulia does not take low-level mathematical functions for granted. The common openlibm implementation of mathematical functions used in many open source projects is maintained by the Julia and SciML developers! However, in modern Julia, every function from   log to ^ has been reimplemented in the Julia standard library to improve numerical correctness and performance. For example, Pumas, the nonlinear mixed effects estimation system built on SciML, and used by Moderna for the vaccine trials, notes in its paper that approximations to such math libraries itself gave a 2x performance improvement in even the most simple non-stiff ODE solvers over matching Fortran implementations. Pure Julia linear algebra tooling, like RecursiveFactorization.jl for LU-factorization, outperforms common LU-factorization implementations used in open-source projects like OpenBLAS by around 5x! This should not be surprising though, given that OpenBLAS was a prior MIT Julia Lab project!\nCompilers are limited on the transformations that they can perform because they do not have high-level context-dependent mathematical knowledge. Julia's SciML makes extensive use of customized symbolic-based compiler transformations to improve performance with context-based code optimizations. Things like sparsity patterns are automatically deduced from code and optimized on. Nonlinear equations are symbolically-torn, changing large nonlinear systems into sequential solving of much smaller systems and benefiting from an O(n^3) cost reduction. These can be orders of magnitude cost reductions which come for free, and unless you know every trick in the book it will be difficult to match SciML's performance!\nPervasive automatic differentiation mixed with compiler tricks wins battles. Many high-performance libraries in C++ and Fortran cannot assume that all of its code is compatible with automatic differentiation, and thus many internal performance tricks are not applied. For example, ForwardDiff.jl's chunk seeding allows for a single call to f to generate multiple columns of a Jacobian. When mixed with sparse coloring tools, entire Jacobians can be constructed with just a few f calls. Studies in applications have shown this greatly outperforms finite differencing, especially when Julia's implicit multithreading is used.","category":"page"},{"location":"comparisons/cppfortran/#Let's-Dig-Deep-Into-One-Case:-Adjoints-of-ODEs-for-Solving-Inverse-Problems","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Let's Dig Deep Into One Case: Adjoints of ODEs for Solving Inverse Problems","text":"","category":"section"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"To really highlight how JIT compilation and automatic differentiation integration can change algorithms, let's look at the problem of differentiating an ODE solver. As is derived and discussed in detail at a seminar with the American Statistical Association, there are many ways to implement well-known “adjoint” methods which are required for performance. Each has different stability and performance trade-offs, and Julia's SciML is the only system to systemically offer all of the trade-off options. In many cases, using analytical adjoints of a solver is not advised due to performance reasons, with the trade-off described in detail here. Likewise, even when analytical adjoints are used, it turns out that for general nonlinear equations there is a trick which uses automatic differentiation in the construction of the analytical adjoint to improve its performance. As demonstrated in this publication, this can lead to about 2-3 orders of magnitude performance improvements. These AD-enhanced adjoints are showcased as the seeding methods in this plot:","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"(Image: )","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"Unless one directly defines special “vjp” functions, this is how the Julia SciML methods achieve orders of magnitude performance advantages over CVODES's adjoints and PETSC's TS-adjoint.","category":"page"},{"location":"comparisons/cppfortran/","page":"Getting Started with Julia's SciML for the C++/Fortran User","title":"Getting Started with Julia's SciML for the C++/Fortran User","text":"Moral of the story, even there are many reasons to use automatic differentiation of a solver, and even if an analytical adjoint rule is used for some specific performance reason, that analytical expression can often times be accelerated by orders of magnitude itself by embedding some form of automatic differentiation into it. This is just one algorithm of many which are optimized in this fashion.","category":"page"},{"location":"getting_started/first_optimization/#first_opt","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Numerical optimization is the process of finding some numerical values that minimize some equation.","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"How much fuel should you put into an airplane to have the minimum weight that can go to its destination?\nWhat parameters should I choose for my simulation so that it minimizes the distance of its predictions from my experimental data?","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"All of these are examples of problems solved by numerical optimization. Let's solve our first optimization problem!","category":"page"},{"location":"getting_started/first_optimization/#Required-Dependencies","page":"Solve your first optimization problem","title":"Required Dependencies","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"The following parts of the SciML Ecosystem will be used in this tutorial:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Module Description\nOptimization.jl The numerical optimization package\nOptimizationNLopt.jl The NLopt optimizers we will use\nForwardDiff.jl The automatic differentiation library for gradients","category":"page"},{"location":"getting_started/first_optimization/#Problem-Setup","page":"Solve your first optimization problem","title":"Problem Setup","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"First, what are we solving? Let's take a look at the Rosenbrock equation:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"L(up) = (p_1 - u_1)^2 + p_2 * (u_2 - u_1^2)^2","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"What we want to do is find the  values of u_1 and u_2 such that L achieves its minimum value possible. We will do this under a few constraints: we want to find this optimum within some bounded domain, i.e. u_i in -11. This should be done with the parameter values p_1 = 10 and p_2 = 1000. What should u = u_1u_2 be to achieve this goal? Let's dive in!","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"note: Note\nThe upper and lower bounds are optional for the solver! If your problem does not need to have such bounds, just leave off the parts with lb and ub!","category":"page"},{"location":"getting_started/first_optimization/#Copy-Pastable-Code","page":"Solve your first optimization problem","title":"Copy-Pastable Code","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"# Import the package\nusing Optimization, OptimizationNLopt, ForwardDiff\n\n# Define the problem to optimize\nL(u, p) = (p[1] - u[1])^2 + p[2] * (u[2] - u[1]^2)^2\nu0 = zeros(2)\np = [1.0, 100.0]\noptfun = OptimizationFunction(L, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optfun, u0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\n\n# Solve the optimization problem\nsol = solve(prob, NLopt.LD_LBFGS())\n\n# Analyze the solution\n@show sol.u, L(sol.u, p)","category":"page"},{"location":"getting_started/first_optimization/#Step-by-Step-Solution","page":"Solve your first optimization problem","title":"Step-by-Step Solution","text":"","category":"section"},{"location":"getting_started/first_optimization/#Step-1:-Import-the-packages","page":"Solve your first optimization problem","title":"Step 1: Import the packages","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"To do this tutorial, we will need a few components:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Optimization.jl, the optimization interface.\nOptimizationNLopt.jl, the optimizers we will use.\nForwardDiff.jl, the automatic differentiation library for gradients","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Note that Optimization.jl is an interface for optimizers, and thus we always have to choose which optimizer we want to use. Here we choose to demonstrate OptimizationNLopt because of its efficiency and versatility. But there are many other possible choices. Check out the solver compatibility chart for a quick overview of what optimizer packages offer.","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"To start, let's add these packages as demonstrated in the installation tutorial:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"using Pkg\nPkg.add([\"Optimization\", \"OptimizationNLopt\", \"ForwardDiff\"])","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Now we're ready. Let's load in these packages:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"using Optimization, OptimizationNLopt, ForwardDiff","category":"page"},{"location":"getting_started/first_optimization/#Step-2:-Define-the-Optimization-Problem","page":"Solve your first optimization problem","title":"Step 2: Define the Optimization Problem","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Now let's define our problem to optimize. We start by defining our loss function. In Optimization.jl's OptimizationProblem interface, the states are given by an array u. Thus we can designate u[1] to be u_1 and u[2] to be u_2, similarly with our parameters, and write out the loss function on a vector-defined state as follows:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"# Define the problem to optimize\nL(u, p) = (p[1] - u[1])^2 + p[2] * (u[2] - u[1]^2)^2","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Next we need to create an OptimizationFunction where we tell Optimization.jl to use the ForwardDiff.jl package for creating the gradient and other derivatives required by the optimizer.","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"#Create the OptimizationFunction\noptfun = OptimizationFunction(L, Optimization.AutoForwardDiff())","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Now we need to define our OptimizationProblem. If you need help remembering how to define the OptimizationProblem, you can always refer to the Optimization.jl problem definition page.","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Thus what we need to define is an initial condition u0 and our parameter vector p. We will make our initial condition have both values as zero, which is done by the Julia shorthand zeros(2) that creates a vector [0.0,0.0]. We manually define the parameter vector p to input our values. Then we set the lower bound and upper bound for the optimization as follows:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"u0 = zeros(2)\np = [1.0, 100.0]\nprob = OptimizationProblem(optfun, u0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])","category":"page"},{"location":"getting_started/first_optimization/#Note-about-defining-uniform-bounds","page":"Solve your first optimization problem","title":"Note about defining uniform bounds","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Note that we can simplify the code a bit for the lower and upper bound definition by using the Julia Base command ones, which returns a vector where each value is a one. Thus for example, ones(2) is equivalent to [1.0,1.0]. Therefore -1 * ones(2) is equivalent to [-1.0,-1.0], meaning we could have written our problem as follows:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"prob = OptimizationProblem(optfun, u0, p, lb = -1 * ones(2), ub = ones(2))","category":"page"},{"location":"getting_started/first_optimization/#Step-3:-Solve-the-Optimization-Problem","page":"Solve your first optimization problem","title":"Step 3: Solve the Optimization Problem","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Now we solve the OptimizationProblem that we have defined. This is done by passing our OptimizationProblem along with a chosen solver to the solve command. At the beginning, we explained that we will use the OptimizationNLopt set of solvers, which are documented in the OptimizationNLopt page. From here, we are choosing the NLopt.LD_LBFGS() for its mixture of robustness and performance. To perform this solve, we do the following:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"# Solve the optimization problem\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"getting_started/first_optimization/#Step-4:-Analyze-the-Solution","page":"Solve your first optimization problem","title":"Step 4: Analyze the Solution","text":"","category":"section"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"Now let's check out the solution. First of all, what kind of thing is the sol? We can see that by asking for its type:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"typeof(sol)","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"From this, we can see that it is an OptimizationSolution. We can see the documentation for how to use the OptimizationSolution by checking the Optimization.jl solution type page. For example, the solution is stored as .u. What is the solution to our optimization, and what is the final loss value? We can check it as follows:","category":"page"},{"location":"getting_started/first_optimization/","page":"Solve your first optimization problem","title":"Solve your first optimization problem","text":"# Analyze the solution\n@show sol.u, L(sol.u, p)","category":"page"},{"location":"showcase/massively_parallel_gpu/#datagpu","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"","category":"section"},{"location":"showcase/massively_parallel_gpu/#Before-we-start:-the-two-ways-to-accelerate-ODE-solvers-with-GPUs","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Before we start: the two ways to accelerate ODE solvers with GPUs","text":"","category":"section"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Before we dive deeper, let us remark that there are two very different ways that one can accelerate an ODE solution with GPUs. There is one case where u is very big and f is very expensive but very structured, and you use GPUs to accelerate the computation of said f. The other use case is where u is very small, but you want to solve the ODE f over many different initial conditions (u0) or parameters p. In that case, you can use GPUs to parallelize over different parameters and initial conditions. In other words:","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Type of Problem SciML Solution\nAccelerate a big ODE Use CUDA.jl's CuArray as u0\nSolve the same ODE with many u0 and p Use DiffEqGPU.jl's EnsembleGPUArray and EnsembleGPUKernel","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"This showcase will focus on the latter case. For the former, see the massively parallel GPU ODE solving showcase.","category":"page"},{"location":"showcase/massively_parallel_gpu/#Supported-GPUs","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Supported GPUs","text":"","category":"section"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"SciML's GPU support extends to a wide array of hardware, including:","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"GPU Manufacturer GPU Kernel Language Julia Support Package Backend Type\nNVIDIA CUDA CUDA.jl CUDA.CUDABackend()\nAMD ROCm AMDGPU.jl AMDGPU.ROCBackend()\nIntel OneAPI OneAPI.jl oneAPI.oneAPIBackend()\nApple (M-Series) Metal Metal.jl Metal.MetalBackend()","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"For this tutorial we will demonstrate the CUDA backend for NVIDIA GPUs, though any of the other GPUs can be used by simply swapping out the backend choice.","category":"page"},{"location":"showcase/massively_parallel_gpu/#Problem-Setup","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Problem Setup","text":"","category":"section"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Let's say we wanted to quantify the uncertainty in the solution of a differential equation. One simple way to do this would be to a Monte Carlo simulation of the same ODE, randomly jiggling around some parameters according to an uncertainty distribution. We could do that on a CPU, but that's not hip. What's hip are GPUs! GPUs have thousands of cores, so could we make each core of our GPU solve the same ODE, but with different parameters? The ensembling tools of DiffEqGPU.jl solve exactly this issue, and today you will learn how to master the GPUniverse.","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Let's dive right in.","category":"page"},{"location":"showcase/massively_parallel_gpu/#Defining-the-Ensemble-Problem-for-CPU","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Defining the Ensemble Problem for CPU","text":"","category":"section"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"DifferentialEquations.jl has an ensemble interface for solving many ODEs. DiffEqGPU conveniently uses exactly the same interface, so just a change of a few characters is all that's required to change a CPU-parallelized code into a GPU-parallelized code. Given that, let's start with the CPU-parallelized code.","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Let's implement the Lorenz equation out-of-place. If you don't know what that means, see the getting started with DifferentialEquations.jl","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"using DiffEqGPU, OrdinaryDiffEq, StaticArrays, CUDA\nfunction lorenz(u, p, t)\n    σ = p[1]\n    ρ = p[2]\n    β = p[3]\n    du1 = σ * (u[2] - u[1])\n    du2 = u[1] * (ρ - u[3]) - u[2]\n    du3 = u[1] * u[2] - β * u[3]\n    return SVector{3}(du1, du2, du3)\nend\n\nu0 = @SVector [1.0f0; 0.0f0; 0.0f0]\ntspan = (0.0f0, 10.0f0)\np = @SVector [10.0f0, 28.0f0, 8 / 3.0f0]\nprob = ODEProblem{false}(lorenz, u0, tspan, p)","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Notice we use SVectors, i.e. StaticArrays, in order to define our arrays. This is important for later, since the GPUs will want a fully non-allocating code to build a kernel on.","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Now, from this problem, we build an EnsembleProblem as per the DifferentialEquations.jl specification. A prob_func jiggles the parameters and we solve 10_000 trajectories:","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"prob_func = (prob, i, repeat) -> remake(prob, p = (@SVector rand(Float32, 3)) .* p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy = false)\nsol = solve(monteprob, Tsit5(), EnsembleThreads(), trajectories = 10_000, saveat = 1.0f0)","category":"page"},{"location":"showcase/massively_parallel_gpu/#Taking-the-Ensemble-to-the-GPU","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Taking the Ensemble to the GPU","text":"","category":"section"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Now uhh, we just change EnsembleThreads() to EnsembleGPUArray()","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"sol = solve(monteprob, Tsit5(), EnsembleGPUArray(CUDA.CUDABackend()),\n    trajectories = 10_000, saveat = 1.0f0)","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Or for a more efficient version, EnsembleGPUKernel(). But that requires special solvers, so we also change to GPUTsit5().","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"sol = solve(\n    monteprob, GPUTsit5(), EnsembleGPUKernel(CUDA.CUDABackend()), trajectories = 10_000)","category":"page"},{"location":"showcase/massively_parallel_gpu/","page":"Massively Data-Parallel ODE Solving on GPUs","title":"Massively Data-Parallel ODE Solving on GPUs","text":"Okay, so that was anticlimactic, but that's the point: if it were harder than that, it wouldn't be automatic! Now go check out DiffEqGPU.jl's documentation for more details, that's the end of our show.","category":"page"},{"location":"showcase/ode_types/#ode_types","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"One of the nice things about DifferentialEquations.jl is that it is designed with Julia's type system in mind. What this means is, if you have properly defined a Number type, you can use this number type in DifferentialEquations.jl's algorithms! There's more than a few useful/interesting types that can be used:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Julia Type Name Julia Package Use case\nBigFloat Base Julia Higher precision solutions\nArbFloat ArbFloats.jl More efficient higher precision solutions\nMeasurement Measurements.jl Uncertainty propagation\nParticles MonteCarloMeasurements.jl Uncertainty propagation\nUnitful Unitful.jl Unit-checked arithmetic\nQuaternion Quaternions.jl Quaternions, duh.\nFun ApproxFun.jl Representing PDEs as ODEs in function spaces\nAbstractOrthoPoly PolyChaos.jl Polynomial Chaos Expansion (PCE) for uncertainty quantification\nNum Symbolics.jl Build symbolic expressions of ODE solution approximations\nTaylor TaylorSeries.jl Build a Taylor series around a solution point\nDual ForwardDiff.jl Perform forward-mode automatic differentiation\nTrackedArray\\TrackedReal ReverseDiff.jl Perform reverse-mode automatic differentiation","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"and on and on. That's only a subset of types people have effectively used on the SciML tools.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"We will look into the BigFloat, Measurement, and Unitful cases to demonstrate the utility of alternative numerical types.","category":"page"},{"location":"showcase/ode_types/#How-Type-Support-Works-in-DifferentialEquations.jl-/-SciML","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"How Type Support Works in DifferentialEquations.jl / SciML","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"DifferentialEquations.jl determines the numbers to use in its solvers via the types that are designated by tspan and the initial condition u0 of the problem. It will keep the time values in the same type as tspan, and the solution values in the same type as the initial condition.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"note: Note\nSupport for this feature is restricted to the native algorithms of OrdinaryDiffEq.jl. The other solvers such as Sundials.jl, and ODEInterface.jl are incompatible with some number systems.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"warn: Warn\nAdaptive timestepping requires that the time type is compatible with sqrt and ^ functions. Thus for example, tspan cannot be Int if adaptive timestepping is chosen.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Let's use this feature in some cool ways!","category":"page"},{"location":"showcase/ode_types/#Arbitrary-Precision:-Rationals-and-BigFloats","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Arbitrary Precision: Rationals and BigFloats","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Let's solve the linear ODE. First, define an easy way to get ODEProblems for the linear ODE:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"using DifferentialEquations\nf(u, p, t) = p * u\nprob_ode_linear = ODEProblem(f, 1 / 2, (0.0, 1.0), 1.01);","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Next, let's solve it using Float64s. To do so, we just need to set u0 to a Float64 (which is done by the default) and dt should be a float as well.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"sol = solve(prob_ode_linear, Tsit5())","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Notice that both the times and the solutions were saved as Float64. Let's change the state to use BigFloat values. We do this by changing the u0 to use BigFloats like:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"prob_ode_linear_bigu = ODEProblem(f, big(1 / 2), (0.0, 1.0), 1.01);\nsol = solve(prob_ode_linear_bigu, Tsit5())","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Now we see that u is in arbitrary precision BigFloats, while t is in Float64. We can then change t to be arbitrary precision BigFloats by changing the types of the tspan like:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"prob_ode_linear_big = ODEProblem(f, big(1 / 2), (big(0.0), big(1.0)), 1.01);\nsol = solve(prob_ode_linear_big, Tsit5())","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Now let's send it into the bizarre territory. Let's use rational values for everything. Let's start by making the time type Rational. Rationals are incompatible with adaptive time stepping since they do not have an L2 norm (this can be worked around by defining internalnorm, but we will skip that in this tutorial). To account for this, let's turn off adaptivity as well. Thus the following is a valid use of rational time (and parameter):","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"prob = ODEProblem(f, 1 / 2, (0 // 1, 1 // 1), 101 // 100);\nsol = solve(prob, RK4(), dt = 1 // 2^(6), adaptive = false)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Now let's change the state to use Rational{BigInt}. You will see that we will need to use the arbitrary-sized integers because... well... there's a reason people use floating-point numbers with ODE solvers:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"prob = ODEProblem(f, BigInt(1) // BigInt(2), (0 // 1, 1 // 1), 101 // 100);\nsol = solve(prob, RK4(), dt = 1 // 2^(6), adaptive = false)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Yeah...","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"sol[end]","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"That's one huge fraction! 0 floating-point error ODE solve achieved.","category":"page"},{"location":"showcase/ode_types/#Unit-Checked-Arithmetic-via-Unitful.jl","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Unit Checked Arithmetic via Unitful.jl","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Units and dimensional analysis are standard tools across the sciences for checking the correctness of your equation. However, most ODE solvers only allow for the equation to be in dimensionless form, leaving it up to the user to both convert the equation to a dimensionless form, punch in the equations, and hopefully not make an error along the way.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"DifferentialEquations.jl allows for one to use Unitful.jl to have unit-checked arithmetic natively in the solvers. Given the dispatch implementation of the Unitful, this has little overhead because the unit checks occur at compile-time and not at runtime, and thus it does not have a runtime effect unless conversions are required (i.e. converting cm to m), which automatically adds a floating-point operation for the multiplication.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Let's see this in action.","category":"page"},{"location":"showcase/ode_types/#Using-Unitful","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Using Unitful","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"To use Unitful, you need to have the package installed. Then you can add units to your variables. For example:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"using Unitful\nt = 1.0u\"s\"","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Notice that t is a variable with units in seconds. If we make another value with seconds, they can add:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"t2 = 1.02u\"s\"\nt + t2","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"and they can multiply:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"t * t2","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"You can even do rational roots:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"sqrt(t)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Many operations work. These operations will check to make sure units are correct, and will throw an error for incorrect operations:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"t + sqrt(t)","category":"page"},{"location":"showcase/ode_types/#Using-Unitful-with-DifferentialEquations.jl","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Using Unitful with DifferentialEquations.jl","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Just like with other number systems, you can choose the units for your numbers by simply specifying the units of the initial condition and the timespan. For example, to solve the linear ODE where the variable has units of Newton's and t is in seconds, we would use:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"using DifferentialEquations\nf(u, p, t) = 0.5 * u\nu0 = 1.5u\"N\"\nprob = ODEProblem(f, u0, (0.0u\"s\", 1.0u\"s\"))\n#sol = solve(prob,Tsit5())","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Notice that we received a unit mismatch error. This is correctly so! Remember that for an ODE:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"fracdydt = f(ty)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"we must have that f is a rate, i.e. f is a change in y per unit time. So, we need to fix the units of f in our example to be N/s. Notice that we then do not receive an error if we do the following:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"f(y, p, t) = 0.5 * y / 3.0u\"s\"\nprob = ODEProblem(f, u0, (0.0u\"s\", 1.0u\"s\"))\nsol = solve(prob, Tsit5())","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"This gives a normal solution object. Notice that the values are all with the correct units:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"print(sol[:])","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"And when we plot the solution, it automatically adds the units:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"using Plots\ngr()\nplot(sol, lw = 3)","category":"page"},{"location":"showcase/ode_types/#Measurements.jl:-Numbers-with-Linear-Uncertainty-Propagation","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Measurements.jl: Numbers with Linear Uncertainty Propagation","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"The result of a measurement should be given as a number with an attached uncertainty, besides the physical unit, and all operations performed involving the result of the measurement should propagate the uncertainty, taking care of correlation between quantities.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"There is a Julia package for dealing with numbers with uncertainties: Measurements.jl. Thanks to Julia's features, DifferentialEquations.jl easily works together with Measurements.jl out-of-the-box.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Let's try to automate uncertainty propagation through number types on some classical physics examples!","category":"page"},{"location":"showcase/ode_types/#Warning-about-Measurement-type","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Warning about Measurement type","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Before going on with the tutorial, we must point up a subtlety of Measurements.jl that you should be aware of:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"using Measurements\n5.23 ± 0.14 === 5.23 ± 0.14","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"(5.23 ± 0.14) - (5.23 ± 0.14)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"(5.23 ± 0.14) / (5.23 ± 0.14)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"The two numbers above, even though have the same nominal value and the same uncertainties, are actually two different measurements that only by chance share the same figures and their difference and their ratio have a non-zero uncertainty.  It is common in physics to get very similar, or even equal, results for a repeated measurement, but the two measurements are not the same thing.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Instead, if you have one measurement and want to perform some operations involving it, you have to assign it to a variable:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"x = 5.23 ± 0.14\nx === x","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"x - x","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"x / x","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"With that in mind, let's start using Measurements.jl for realsies.","category":"page"},{"location":"showcase/ode_types/#Automated-UQ-on-an-ODE:-Radioactive-Decay-of-Carbon-14","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automated UQ on an ODE: Radioactive Decay of Carbon-14","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"The rate of decay of carbon-14 is governed by a first order linear ordinary differential equation:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"fracmathrmdu(t)mathrmdt = -fracu(t)tau","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"where tau is the mean lifetime of carbon-14, which is related to the half-life t_12 = (5730 pm 40) years by the relation tau = t_12ln(2). Writing this in DifferentialEquations.jl syntax, this looks like:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"# Half-life and mean lifetime of radiocarbon, in years\nt_12 = 5730 ± 40\nτ = t_12 / log(2)\n\n#Setup\nu₀ = 1 ± 0\ntspan = (0.0, 10000.0)\n\n#Define the problem\nradioactivedecay(u, p, t) = -u / τ\n\n#Pass to solver\nprob = ODEProblem(radioactivedecay, u₀, tspan)\nsol = solve(prob, Tsit5(), reltol = 1e-8)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"And bingo: numbers with uncertainty went in, so numbers with uncertainty came out. But can we trust those values for the uncertainty?","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"We can check the uncertainty quantification by evaluating an analytical solution to the ODE. Since it's a linear ODE, the analytical solution is simply given by the exponential:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"u = exp.(-sol.t / τ)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"How do the two solutions compare?","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"plot(sol.t, sol.u, label = \"Numerical\", xlabel = \"Years\", ylabel = \"Fraction of Carbon-14\")\nplot!(sol.t, u, label = \"Analytic\")","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"The two curves are perfectly superimposed, indicating that the numerical solution matches the analytic one.  We can check that also the uncertainties are correctly propagated in the numerical solution:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"println(\"Quantity of carbon-14 after \", sol.t[11], \" years:\")\nprintln(\"Numerical: \", sol[11])\nprintln(\"Analytic:  \", u[11])","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Bullseye. Both the value of the numerical solution and its uncertainty match the analytic solution within the requested tolerance.  We can also note that close to 5730 years after the beginning of the decay (half-life of the radioisotope), the fraction of carbon-14 that survived is about 0.5.","category":"page"},{"location":"showcase/ode_types/#Simple-pendulum:-Small-angles-approximation","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Simple pendulum: Small angles approximation","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"The next problem we are going to study is the simple pendulum in the approximation of small angles.  We address this simplified case because there exists an easy analytic solution to compare.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"The differential equation we want to solve is:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"ddottheta + fracgL theta = 0","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"where g = (979 pm 002)mathrmmmathrms^2 is the gravitational acceleration measured where the experiment is carried out, and L = (100 pm 001)mathrmm is the length of the pendulum.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"When you set up the problem for DifferentialEquations.jl remember to define the measurements as variables, as seen above.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"using DifferentialEquations, Measurements, Plots\n\ng = 9.79 ± 0.02; # Gravitational constants\nL = 1.00 ± 0.01; # Length of the pendulum\n\n#Initial Conditions\nu₀ = [0 ± 0, π / 60 ± 0.01] # Initial speed and initial angle\ntspan = (0.0, 6.3)\n\n#Define the problem\nfunction simplependulum(du, u, p, t)\n    θ = u[1]\n    dθ = u[2]\n    du[1] = dθ\n    du[2] = -(g / L) * θ\nend\n\n#Pass to solvers\nprob = ODEProblem(simplependulum, u₀, tspan)\nsol = solve(prob, Tsit5(), reltol = 1e-6)","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"And that's it! What about comparing it this time to the analytical solution?","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"u = u₀[2] .* cos.(sqrt(g / L) .* sol.t)\n\nplot(sol.t, getindex.(sol.u, 2), label = \"Numerical\")\nplot!(sol.t, u, label = \"Analytic\")","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Bingo. Also in this case there is a perfect superimposition between the two curves, including their uncertainties.","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"We can also have a look at the difference between the two solutions:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"plot(sol.t, getindex.(sol.u, 2) .- u, label = \"\")","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Tiny difference on the order of the chosen 1e-6 tolerance.","category":"page"},{"location":"showcase/ode_types/#Simple-pendulum:-Arbitrary-amplitude","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Simple pendulum: Arbitrary amplitude","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Now that we know how to solve differential equations involving numbers with uncertainties, we can solve the simple pendulum problem without any approximation. This time, the differential equation to solve is the following:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"ddottheta + fracgL sin(theta) = 0","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"That would be done via:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"g = 9.79 ± 0.02; # Gravitational constants\nL = 1.00 ± 0.01; # Length of the pendulum\n\n#Initial Conditions\nu₀ = [0 ± 0, π / 3 ± 0.02] # Initial speed and initial angle\ntspan = (0.0, 6.3)\n\n#Define the problem\nfunction simplependulum(du, u, p, t)\n    θ = u[1]\n    dθ = u[2]\n    du[1] = dθ\n    du[2] = -(g / L) * sin(θ)\nend\n\n#Pass to solvers\nprob = ODEProblem(simplependulum, u₀, tspan)\nsol = solve(prob, Tsit5(), reltol = 1e-6)\n\nplot(sol.t, getindex.(sol.u, 2), label = \"Numerical\")","category":"page"},{"location":"showcase/ode_types/#Warning-about-Linear-Uncertainty-Propagation","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Warning about Linear Uncertainty Propagation","text":"","category":"section"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Measurements.jl uses linear uncertainty propagation, which has an error associated with it. MonteCarloMeasurements.jl has a page which showcases where this method can lead to incorrect uncertainty measurements. Thus for more nonlinear use cases, it's suggested that one uses one of the more powerful UQ methods, such as:","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"MonteCarloMeasurements.jl\nPolyChaos.jl\nSciMLExpectations.jl\nThe ProbInts Uncertainty Quantification callbacks","category":"page"},{"location":"showcase/ode_types/","page":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","title":"Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type System","text":"Basically, types can make the algorithm you want to run exceedingly simple to do, but make sure it's the correct algorithm!","category":"page"},{"location":"showcase/pinngpu/#pinngpu","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"Machine learning is all the rage. Everybody thinks physics is cool.","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"Therefore, using machine learning to solve physics equations? 🧠💥","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"So let's be cool and use a physics-informed neural network (PINN) to solve the Heat Equation. Let's be even cooler by using GPUs (ironically, creating even more heat, but it's the heat equation so that's cool).","category":"page"},{"location":"showcase/pinngpu/#Step-1:-Import-Libraries","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 1: Import Libraries","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"To solve PDEs using neural networks, we will use the NeuralPDE.jl package. This package uses ModelingToolkit's symbolic PDESystem as an input, and it generates an Optimization.jl OptimizationProblem which, when solved, gives the weights of the neural network that solve the PDE. In the end, our neural network NN satisfies the PDE equations and is thus the solution to the PDE! Thus our packages look like:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"# High Level Interface\nusing NeuralPDE\nimport ModelingToolkit: Interval\n\n# Optimization Libraries\nusing Optimization, OptimizationOptimisers\n\n# Machine Learning Libraries and Helpers\nusing Lux, LuxCUDA, ComponentArrays\nconst gpud = gpu_device() # allocate a GPU device\n\n# Standard Libraries\nusing Printf, Random\n\n# Plotting\nusing Plots","category":"page"},{"location":"showcase/pinngpu/#Problem-Setup","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Problem Setup","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"Let's solve the 2+1-dimensional Heat Equation. This is the PDE:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"_t u(x y t) = ^2_x u(x y t) + ^2_y u(x y t)  ","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"with the initial and boundary conditions:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"beginalign*\nu(x y 0) = e^x+y cos(x + y)       \nu(0 y t) = e^y   cos(y + 4t)      \nu(2 y t) = e^2+y cos(2 + y + 4t)  \nu(x 0 t) = e^x   cos(x + 4t)      \nu(x 2 t) = e^x+2 cos(x + 2 + 4t)  \nendalign*","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"on the space and time domain:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"x in 0 2   y in 0 2    t in 0 2  ","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"with physics-informed neural networks.","category":"page"},{"location":"showcase/pinngpu/#Step-2:-Define-the-PDESystem","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 2: Define the PDESystem","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"First, let's use ModelingToolkit's PDESystem to represent the PDE. To do this, basically just copy-paste the PDE definition into Julia code. This looks like:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"@parameters t x y\n@variables u(..)\nDxx = Differential(x)^2\nDyy = Differential(y)^2\nDt = Differential(t)\nt_min = 0.0\nt_max = 2.0\nx_min = 0.0\nx_max = 2.0\ny_min = 0.0\ny_max = 2.0\n\n# 2D PDE\neq = Dt(u(t, x, y)) ~ Dxx(u(t, x, y)) + Dyy(u(t, x, y))\n\nanalytic_sol_func(t, x, y) = exp(x + y) * cos(x + y + 4t)\n# Initial and boundary conditions\nbcs = [u(t_min, x, y) ~ analytic_sol_func(t_min, x, y),\n    u(t, x_min, y) ~ analytic_sol_func(t, x_min, y),\n    u(t, x_max, y) ~ analytic_sol_func(t, x_max, y),\n    u(t, x, y_min) ~ analytic_sol_func(t, x, y_min),\n    u(t, x, y_max) ~ analytic_sol_func(t, x, y_max)]\n\n# Space and time domains\ndomains = [t ∈ Interval(t_min, t_max),\n    x ∈ Interval(x_min, x_max),\n    y ∈ Interval(y_min, y_max)]\n\n@named pde_system = PDESystem(eq, bcs, domains, [t, x, y], [u(t, x, y)])","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"note: Note\nWe used the wildcard form of the variable definition @variables u(..) which then requires that we always specify what the dependent variables of u are. This is because in the boundary conditions we change from using u(t,x,y) to more specific points and lines, like u(t,x_max,y).","category":"page"},{"location":"showcase/pinngpu/#Step-3:-Define-the-Lux-Neural-Network","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 3: Define the Lux Neural Network","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"Now let's define the neural network that will act as our solution. We will use a simple multi-layer perceptron, like:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"using Lux\ninner = 25\nchain = Chain(Dense(3, inner, Lux.σ),\n    Dense(inner, inner, Lux.σ),\n    Dense(inner, inner, Lux.σ),\n    Dense(inner, inner, Lux.σ),\n    Dense(inner, 1))\nps = Lux.setup(Random.default_rng(), chain)[1]","category":"page"},{"location":"showcase/pinngpu/#Step-4:-Place-it-on-the-GPU.","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 4: Place it on the GPU.","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"Just plop it on that sucker. We must ensure that our initial parameters for the neural network are on the GPU. If that is done, then the internal computations will all take place on the GPU. This is done by using the gpud function (i.e. the GPU device we created at the start) on the initial parameters, like:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"ps = ps |> ComponentArray |> gpud .|> Float64","category":"page"},{"location":"showcase/pinngpu/#Step-5:-Discretize-the-PDE-via-a-PINN-Training-Strategy","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 5: Discretize the PDE via a PINN Training Strategy","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"strategy = GridTraining(0.05)\ndiscretization = PhysicsInformedNN(chain,\n    strategy,\n    init_params = ps)\nprob = discretize(pde_system, discretization)","category":"page"},{"location":"showcase/pinngpu/#Step-6:-Solve-the-Optimization-Problem","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 6: Solve the Optimization Problem","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"callback = function (state, l)\n    println(\"Current loss is: $l\")\n    return false\nend\n\nres = Optimization.solve(prob, Adam(0.01); callback = callback, maxiters = 2500);","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"We then use the remake function to rebuild the PDE problem to start a new optimization at the optimized parameters, and continue with a lower learning rate:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"prob = remake(prob, u0 = res.u)\nres = Optimization.solve(prob, Adam(0.001); callback = callback, maxiters = 2500);","category":"page"},{"location":"showcase/pinngpu/#Step-7:-Inspect-the-PINN's-Solution","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"Step 7: Inspect the PINN's Solution","text":"","category":"section"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"Finally, we inspect the solution:","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"phi = discretization.phi\nts, xs, ys = [infimum(d.domain):0.1:supremum(d.domain) for d in domains]\nu_real = [analytic_sol_func(t, x, y) for t in ts for x in xs for y in ys]\nu_predict = [first(Array(phi([t, x, y], res.u))) for t in ts for x in xs for y in ys]\n\nfunction plot_(res)\n    # Animate\n    anim = @animate for (i, t) in enumerate(0:0.05:t_max)\n        @info \"Animating frame $i...\"\n        u_real = reshape([analytic_sol_func(t, x, y) for x in xs for y in ys],\n            (length(xs), length(ys)))\n        u_predict = reshape([Array(phi([t, x, y], res.u))[1] for x in xs for y in ys],\n            length(xs), length(ys))\n        u_error = abs.(u_predict .- u_real)\n        title = @sprintf(\"predict, t = %.3f\", t)\n        p1 = plot(xs, ys, u_predict, st = :surface, label = \"\", title = title)\n        title = @sprintf(\"real\")\n        p2 = plot(xs, ys, u_real, st = :surface, label = \"\", title = title)\n        title = @sprintf(\"error\")\n        p3 = plot(xs, ys, u_error, st = :contourf, label = \"\", title = title)\n        plot(p1, p2, p3)\n    end\n    gif(anim, \"3pde.gif\", fps = 10)\nend\n\nplot_(res)","category":"page"},{"location":"showcase/pinngpu/","page":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","title":"GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers","text":"(Image: 3pde)","category":"page"},{"location":"showcase/brusselator/#brusselator","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Solving nonlinear partial differential equations (PDEs) is hard. Solving nonlinear PDEs fast and accurately is even harder. Doing it all in an automated method from just a symbolic description is just plain fun. That's what we'd demonstrate here: how to solve a nonlinear PDE from a purely symbolic definition using the combination of ModelingToolkit, MethodOfLines, and DifferentialEquations.jl.","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"note: Note\nThis example is a combination of the Brusselator tutorial from MethodOfLines.jl and the Solving Large Stiff Equations tutorial from DifferentialEquations.jl.","category":"page"},{"location":"showcase/brusselator/#Required-Dependencies","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Required Dependencies","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"The following parts of the SciML Ecosystem will be used in this tutorial:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Module Description\nModelingToolkit.jl The symbolic modeling environment\nMethodOfLines.jl The symbolic PDE discretization tooling\nDifferentialEquations.jl The numerical differential equation solvers\nLinearSolve.jl The numerical linear solvers","category":"page"},{"location":"showcase/brusselator/#Problem-Setup","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Problem Setup","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"The Brusselator PDE is defined as follows:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"beginalign\nfracpartial upartial t = 1 + u^2v - 44u + alpha(fracpartial^2 upartial x^2 + fracpartial^2 upartial y^2) + f(x y t)\nfracpartial vpartial t = 34u - u^2v + alpha(fracpartial^2 vpartial x^2 + fracpartial^2 vpartial y^2)\nendalign","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"where","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"f(x y t) = begincases\n5  quad textif  (x-03)^2+(y-06)^2  01^2 text and  t  11 \n0  quad textelse\nendcases","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"and the initial conditions are","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"beginalign\nu(x y 0) = 22cdot (y(1-y))^32 \nv(x y 0) = 27cdot (x(1-x))^32\nendalign","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"with the periodic boundary condition","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"beginalign\nu(x+1yt) = u(xyt) \nu(xy+1t) = u(xyt)\nendalign","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"We wish to obtain the solution to this PDE on a timespan of t in 0115.","category":"page"},{"location":"showcase/brusselator/#Defining-the-symbolic-PDEsystem-with-ModelingToolkit.jl","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Defining the symbolic PDEsystem with ModelingToolkit.jl","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"With ModelingToolkit.jl, we first symbolically define the system, see also the docs for PDESystem:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"using ModelingToolkit, MethodOfLines, OrdinaryDiffEq, LinearSolve, DomainSets\n\n@parameters x y t\n@variables u(..) v(..)\nDt = Differential(t)\nDx = Differential(x)\nDy = Differential(y)\nDxx = Differential(x)^2\nDyy = Differential(y)^2\n\n∇²(u) = Dxx(u) + Dyy(u)\n\nbrusselator_f(x, y, t) = (((x - 0.3)^2 + (y - 0.6)^2) <= 0.1^2) * (t >= 1.1) * 5.0\n\nx_min = y_min = t_min = 0.0\nx_max = y_max = 1.0\nt_max = 11.5\n\nα = 10.0\n\nu0(x, y, t) = 22(y * (1 - y))^(3 / 2)\nv0(x, y, t) = 27(x * (1 - x))^(3 / 2)\n\neq = [\n    Dt(u(x, y, t)) ~ 1.0 + v(x, y, t) * u(x, y, t)^2 - 4.4 * u(x, y, t) +\n                     α * ∇²(u(x, y, t)) + brusselator_f(x, y, t),\n    Dt(v(x, y, t)) ~ 3.4 * u(x, y, t) - v(x, y, t) * u(x, y, t)^2 + α * ∇²(v(x, y, t))]\n\ndomains = [x ∈ Interval(x_min, x_max),\n    y ∈ Interval(y_min, y_max),\n    t ∈ Interval(t_min, t_max)]\n\n# Periodic BCs\nbcs = [u(x, y, 0) ~ u0(x, y, 0),\n    u(0, y, t) ~ u(1, y, t),\n    u(x, 0, t) ~ u(x, 1, t), v(x, y, 0) ~ v0(x, y, 0),\n    v(0, y, t) ~ v(1, y, t),\n    v(x, 0, t) ~ v(x, 1, t)]\n\n@named pdesys = PDESystem(eq, bcs, domains, [x, y, t], [u(x, y, t), v(x, y, t)])","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Looks just like the LaTeX description, right? Now let's solve it.","category":"page"},{"location":"showcase/brusselator/#Automated-symbolic-discretization-with-MethodOfLines.jl","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated symbolic discretization with MethodOfLines.jl","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Next we create the discretization. Here we will use the finite difference method via method of lines. Method of lines is a method of recognizing that a discretization of a partial differential equation transforms it into a new numerical problem. For example:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Discretization Form Numerical Problem Type\nFinite Difference, Finite Volume, Finite Element, discretizing all variables NonlinearProblem\nFinite Difference, Finite Volume, Finite Element, discretizing all variables except time ODEProblem/DAEProblem\nPhysics-Informed Neural Network OptimizationProblem\nFeynman-Kac Formula SDEProblem\nUniversal Stochastic Differential Equation (High dimensional PDEs) OptimizationProblem inverse problem over SDEProblem","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Thus the process of solving a PDE is fundamentally about transforming its symbolic form to a standard numerical problem and solving the standard numerical problem using one of the solvers in the SciML ecosystem! Here we will demonstrate one of the most classic methods: the finite difference method. Since the Brusselator is a time-dependent PDE with heavy stiffness in the time-domain, we will leave time undiscretized, which means that we will use the finite difference method in the x and y domains to obtain a representation of the equation at `u_i = u(x_i,y_i)grid point values, obtaining an ODEu_i' = \\ldots that defines how the values at the grid points evolve over time.","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"To do this, we use the MOLFiniteDifference construct of MethodOfLines.jl as follows:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"N = 32\n\ndx = (x_max - x_min) / N\ndy = (y_max - y_min) / N\n\norder = 2\n\ndiscretization = MOLFiniteDifference([x => dx, y => dy], t, approx_order = order,\n    grid_align = center_align)","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Next, we discretize the system, converting the PDESystem in to an ODEProblem:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"prob = discretize(pdesys, discretization);","category":"page"},{"location":"showcase/brusselator/#Solving-the-PDE","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Solving the PDE","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Now your problem can be solved with an appropriate ODE solver. This is just your standard DifferentialEquations.jl usage, though we'll return to this point in a bit to talk about efficiency:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"sol = solve(prob, TRBDF2(), saveat = 0.1);","category":"page"},{"location":"showcase/brusselator/#Examining-Results-via-the-Symbolic-Solution-Interface","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Examining Results via the Symbolic Solution Interface","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Now that we have solved the ODE representation of the PDE, we have an PDETimeSeriesSolution that wraps an ODESolution, which we can get with sol.original_sol. If we look at the original sol, it represents u_i = ldots at each of the grid points. If you check sol.original_sol.u inside the solution, that's those values... but that's not very helpful. How do you interpret original_sol[1]? How do you interpret original_sol[1,:]?","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"To make the handling of such cases a lot simpler, MethodOfLines.jl implements a symbolic interface for the solution object that allows for interpreting the computation through its original representation. For example, if we want to know how to interpret the values of the grid corresponding to the independent variables, we can just index using symbolic variables:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"discrete_x = sol[x];\ndiscrete_y = sol[y];\ndiscrete_t = sol[t];","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"What this tells us is that, for a solution at a given time point, say original_sol[1] for the solution at the initial time (the initial condition), the value original_sol[1][1] is the solution at the grid point (discrete_x[1], discrete_y[1]). For values that are not the initial time point, original_sol[i] corresponds to the solution at discrete_t[i].","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"But we also have two dependent variables, u and v. How do we interpret which of the results correspond to the different dependent variables? This is done by indexing the solution by the dependent variables! For example:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"solu = sol[u(x, y, t)];\nsolv = sol[v(x, y, t)];","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"This then gives an array of results for the u and v separately, each dimension corresponding to the discrete form of the independent variables.","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Using this high-level indexing, we can create an animation of the solution of the Brusselator as follows. For u we receive:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"using Plots\nanim = @animate for k in 1:length(discrete_t)\n    heatmap(solu[2:end, 2:end, k], title = \"$(discrete_t[k])\") # 2:end since end = 1, periodic condition\nend\ngif(anim, \"plots/Brusselator2Dsol_u.gif\", fps = 8)","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"(Image: Brusselator2Dsol_u)","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"and for v:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"anim = @animate for k in 1:length(discrete_t)\n    heatmap(solv[2:end, 2:end, k], title = \"$(discrete_t[k])\")\nend\ngif(anim, \"plots/Brusselator2Dsol_v.gif\", fps = 8)","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"(Image: Brusselator2Dsol_v)","category":"page"},{"location":"showcase/brusselator/#Improving-the-Solution-Process","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Improving the Solution Process","text":"","category":"section"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Now, if all we needed was a single solution, then we're done. Budda bing budda boom, we got a solution, we're outta here. But if for example we're solving an inverse problem on a PDE, or we need to bump it up to higher accuracy, then we will need to make sure we solve this puppy more efficiently. So let's dive into how this can be done.","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"First of all, large PDEs generally are stiff and thus require an implicit solver. However, their stiffness is generally governed by a nonlinear system which as a sparse Jacobian. Handling that implicit system with sparsity is key to solving the system efficiently, so let's do that!","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"In order to enable such options, we simply need to pass the ModelingToolkit.jl problem construction options to the discretize call. This looks like:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"# Analytical Jacobian expression and sparse Jacobian\nprob_sparse = discretize(pdesys, discretization; jac = true, sparse = true)","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"Now when we solve the problem it will be a lot faster. We can use BenchmarkTools.jl to assess this performance difference:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"using BenchmarkTools\n@btime sol = solve(prob, TRBDF2(), saveat = 0.1);\n@btime sol = solve(prob_sparse, TRBDF2(), saveat = 0.1);","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"But we can further improve this as well. Instead of just using the default linear solver, we can change this to a Newton-Krylov method by passing in the GMRES method:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"@btime sol = solve(prob_sparse, TRBDF2(linsolve = KrylovJL_GMRES()), saveat = 0.1);","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"But to further improve performance, we can use an iLU preconditioner. This looks like as follows:","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"using IncompleteLU\nfunction incompletelu(W, du, u, p, t, newW, Plprev, Prprev, solverdata)\n    if newW === nothing || newW\n        Pl = ilu(convert(AbstractMatrix, W), τ = 50.0)\n    else\n        Pl = Plprev\n    end\n    Pl, nothing\nend\n\n@btime solve(prob_sparse,\n    TRBDF2(linsolve = KrylovJL_GMRES(), precs = incompletelu, concrete_jac = true),\n    save_everystep = false);","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"And now we're zooming! For more information on these performance improvements, check out the deeper dive in the DifferentialEquations.jl tutorials.","category":"page"},{"location":"showcase/brusselator/","page":"Automated Efficient Solution of Nonlinear Partial Differential Equations","title":"Automated Efficient Solution of Nonlinear Partial Differential Equations","text":"If you're interested in figuring out what's the fastest current solver for this kind of PDE, check out the Brusselator benchmark in SciMLBenchmarks.jl","category":"page"},{"location":"comparisons/python/#python","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"","category":"section"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"If you're a Python user who has looked into Julia, you're probably wondering what is the equivalent to SciPy is. And you found it: it's the SciML ecosystem! To a Python developer, SciML is SciPy, but with the high-performance GPU, capabilities of PyTorch, and neural network capabilities, all baked right in. With SciML, there is no “separate world” of machine learning sublanguages: there is just one cohesive package ecosystem.","category":"page"},{"location":"comparisons/python/#Why-SciML?-High-Level-Workflow-Reasons","page":"Getting Started with Julia's SciML for the Python User","title":"Why SciML? High-Level Workflow Reasons","text":"","category":"section"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"Performance - The key reason people are moving from SciPy to Julia's SciML in droves is performance. Even simple ODE solvers are much faster!, demonstrating orders of magnitude performance improvements for differential equations, nonlinear solving, optimization, and more. And the performance advantages continue to grow as more complex algorithms are required.\nPackage Management and Versioning - Julia's package manager takes care of dependency management, testing, and continuous delivery in order to make the installation and maintenance process smoother. For package users, this means it's easier to get packages with complex functionality in your hands.\nComposable Library Components - In Python environments, every package feels like a silo. Functions made for one file exchange library cannot easily compose with another. SciML's generic coding with JIT compilation these connections create new optimized code on the fly and allow for a more expansive feature set than can ever be documented. Take new high-precision number types from a package and stick them into a nonlinear solver. Take a package for Intel GPU arrays and stick it into the differential equation solver to use specialized hardware acceleration.\nEasier High-Performance and Parallel Computing - With Julia's ecosystem, CUDA will automatically install of the required binaries and cu(A)*cu(B) is then all that's required to GPU-accelerate large-scale linear algebra. MPI is easy to install and use. Distributed computing through password-less SSH. Multithreading is automatic and baked into many libraries, with a specialized algorithm to ensure hierarchical usage does not oversubscribe threads. Basically, libraries give you a lot of parallelism for free, and doing the rest is a piece of cake.\nMix Scientific Computing with Machine Learning - Want to automate the discovery of missing physical laws using neural networks embedded in differentiable simulations? Julia's SciML is the ecosystem with the tooling to integrate machine learning into the traditional high-performance scientific computing domains, from multiphysics simulations to partial differential equations.","category":"page"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"In this plot, SciPy in yellow represents Python's most commonly used solvers:","category":"page"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"(Image: )","category":"page"},{"location":"comparisons/python/#Need-Help-Translating-from-Python-to-Julia?","page":"Getting Started with Julia's SciML for the Python User","title":"Need Help Translating from Python to Julia?","text":"","category":"section"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"The following resources can be particularly helpful when adopting Julia for SciML for the first time:","category":"page"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"The Julia Manual's Noteworthy Differences from Python page\nDouble-check your results with SciPyDiffEq.jl (automatically converts and runs ODE definitions with SciPy's solvers)\nUse PyCall.jl to more incrementally move code to Julia.","category":"page"},{"location":"comparisons/python/#Python-to-Julia-SciML-Functionality-Translations","page":"Getting Started with Julia's SciML for the Python User","title":"Python to Julia SciML Functionality Translations","text":"","category":"section"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"The following chart will help you get quickly acquainted with Julia's SciML Tools:","category":"page"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"Workflow Element SciML-Supported Julia packages\nMatplotlib Plots, Makie\nscipy.special SpecialFunctions\nscipy.linalg.solve LinearSolve\nscipy.integrate Integrals\nscipy.optimize Optimization\nscipy.optimize.fsolve NonlinearSolve\nscipy.interpolate DataInterpolations\nscipy.fft FFTW\nscipy.linalg Julia's Built-In Linear Algebra\nscipy.sparse SparseArrays, ARPACK\nodeint/solve_ivp DifferentialEquations\nscipy.integrate.solve_bvp Boundary-value problem\nPyTorch Flux, Lux\ngillespy2 Catalyst, JumpProcesses\nscipy.optimize.approx_fprime FiniteDiff\nautograd ForwardDiff*, Enzyme*, DiffEqSensitivity\nStan Turing\nsympy Symbolics","category":"page"},{"location":"comparisons/python/#Why-is-Differentiable-Programming-Important-for-Scientific-Computing?","page":"Getting Started with Julia's SciML for the Python User","title":"Why is Differentiable Programming Important for Scientific Computing?","text":"","category":"section"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"Check out this blog post that goes into detail on how training neural networks in tandem with simulation improves performance by orders of magnitude. But can't you use analytical adjoint definitions? You can, but there are tricks to mix automatic differentiation into the adjoint definitions for a few orders of magnitude improvement too, as explained in this blog post.","category":"page"},{"location":"comparisons/python/","page":"Getting Started with Julia's SciML for the Python User","title":"Getting Started with Julia's SciML for the Python User","text":"These facts, along with many others, compose to algorithmic improvements with the implementation improvements, which leads to orders of magnitude improvements!","category":"page"},{"location":"getting_started/first_simulation/#first_sim","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"In this tutorial, we will build and run our first simulation with SciML!","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"note: Note\nThis tutorial assumes that you have already installed Julia on your system. If you have not done so already, please follow the installation tutorial first.","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"To build our simulation, we will use the ModelingToolkit system for modeling and simulation. ModelingToolkit is a bit higher level than directly defining code for a differential equation system: it's a symbolic system that will automatically simplify our models, optimize our code, and generate compelling visualizations. Sounds neat? Let's dig in.","category":"page"},{"location":"getting_started/first_simulation/#Required-Dependencies","page":"Build and run your first simulation with Julia's SciML","title":"Required Dependencies","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"The following parts of the SciML Ecosystem will be used in this tutorial:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Module Description\nModelingToolkit.jl The symbolic modeling environment\nDifferentialEquations.jl The differential equation solvers\nPlots.jl The plotting and visualization package","category":"page"},{"location":"getting_started/first_simulation/#Our-Problem:-Simulate-the-Lotka-Volterra-Predator-Prey-Dynamics","page":"Build and run your first simulation with Julia's SciML","title":"Our Problem: Simulate the Lotka-Volterra Predator-Prey Dynamics","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"The dynamics of our system are given by the Lotka-Volterra dynamical system: Let x(t) be the number of rabbits in the environment and y(t) be the number of wolves. The equation that defines the evolution of the species is given as follows:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"beginalign\nfracdxdt = alpha x - beta x y\nfracdydt = -gamma y + delta x y\nendalign","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"where alpha beta gamma delta are parameters. Starting from equal numbers of rabbits and wolves, x(0) = 1 and y(0) = 1, we want to simulate this system from time t_0 = 0 to t_f = 10. Luckily, a local guide provided us with some parameters that seem to match the system! These are alpha = 15, beta = 10, gamma = 30, delta = 10. How many rabbits and wolves will there be 10 months from now? And if z = x + y, i.e. the total number of animals at a given time, can we visualize this total number of animals at each time?","category":"page"},{"location":"getting_started/first_simulation/#Solution-as-Copy-Pastable-Code","page":"Build and run your first simulation with Julia's SciML","title":"Solution as Copy-Pastable Code","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"using ModelingToolkit, DifferentialEquations, Plots\n\n# Define our state variables: state(t) = initial condition\n@variables t x(t)=1 y(t)=1 z(t)=2\n\n# Define our parameters\n@parameters α=1.5 β=1.0 γ=3.0 δ=1.0\n\n# Define our differential: takes the derivative with respect to `t`\nD = Differential(t)\n\n# Define the differential equations\neqs = [D(x) ~ α * x - β * x * y\n       D(y) ~ -γ * y + δ * x * y\n       z ~ x + y]\n\n# Bring these pieces together into an ODESystem with independent variable t\n@mtkbuild sys = ODESystem(eqs, t)\n\n# Convert from a symbolic to a numerical problem to simulate\ntspan = (0.0, 10.0)\nprob = ODEProblem(sys, [], tspan)\n\n# Solve the ODE\nsol = solve(prob)\n\n# Plot the solution\np1 = plot(sol, title = \"Rabbits vs Wolves\")\np2 = plot(sol, idxs = z, title = \"Total Animals\")\n\nplot(p1, p2, layout = (2, 1))","category":"page"},{"location":"getting_started/first_simulation/#Step-by-Step-Solution","page":"Build and run your first simulation with Julia's SciML","title":"Step-by-Step Solution","text":"","category":"section"},{"location":"getting_started/first_simulation/#Step-1:-Install-and-Import-the-Required-Packages","page":"Build and run your first simulation with Julia's SciML","title":"Step 1: Install and Import the Required Packages","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"To do this tutorial, we will need a few components:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"ModelingToolkit.jl, our modeling environment\nDifferentialEquations.jl, the differential equation solvers\nPlots.jl, our visualization tool","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"To start, let's add these packages as demonstrated in the installation tutorial:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"using Pkg\nPkg.add([\"ModelingToolkit\", \"DifferentialEquations\", \"Plots\"])","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now we're ready. Let's load in these packages:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"using ModelingToolkit, DifferentialEquations, Plots","category":"page"},{"location":"getting_started/first_simulation/#Step-2:-Define-our-ODE-Equations","page":"Build and run your first simulation with Julia's SciML","title":"Step 2: Define our ODE Equations","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now let's define our ODEs. We use the ModelingToolkit.@variabes statement to declare our variables. We have the independent variable time t, and then define our 3 state variables:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Define our state variables: state(t) = initial condition\n@variables t x(t)=1 y(t)=1 z(t)=2","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Notice here that we use the form state = default, where on the right-hand side the default value of a state is interpreted to be its initial condition. This is then done similarly for parameters, where the default value is now the parameter value:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Define our parameters\n@parameters α=1.5 β=1.0 γ=3.0 δ=1.0","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"note: Note\nJulia's text editors like VS Code are compatible with Unicode defined in a LaTeX form. Thus if you write \\alpha into your REPL and then press Tab, it will auto-complete that into the α symbol. That can make your code look a lot more like the mathematical expressions!","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Next, we define our set of differential equations. To define the Differential operator D, we need to first tell it what to differentiate with respect to, here the independent variable t, Then, once we have the operator, we apply that into the equations.","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"note: Note\nNote that in ModelingToolkit and Symbolics, ~ is used for equation equality. This is separate from = which is the “assignment operator” in the Julia programming language. For example, x = x + 1 is a valid assignment in a programming language, and it is invalid for that to represent “equality”, which is why a separate operator is used!","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Define our differential: takes the derivative with respect to `t`\nD = Differential(t)\n\n# Define the differential equations\neqs = [D(x) ~ α * x - β * x * y\n       D(y) ~ -γ * y + δ * x * y\n       z ~ x + y]","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Notice that in the display, it will automatically generate LaTeX. If one is interested in generating this LaTeX locally, one can simply do:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"using Latexify # add the package first\nlatexify(eqs)","category":"page"},{"location":"getting_started/first_simulation/#Step-3:-Define-the-ODEProblem","page":"Build and run your first simulation with Julia's SciML","title":"Step 3: Define the ODEProblem","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now we bring these pieces together. In ModelingToolkit, we can bring these pieces together to represent an ODESystem with the following:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Bring these pieces together into an ODESystem with independent variable t\n@mtkbuild sys = ODESystem(eqs, t)","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Notice that in our equations we have an algebraic equation z ~ x + y. This is not a differential equation but an algebraic equation, and thus we call this set of equations a Differential-Algebraic Equation (DAE). The symbolic system of ModelingToolkit can eliminate such equations to return simpler forms to numerically approximate.","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Notice that what is returned is an ODESystem, but now with the simplified set of equations. z has been turned into an “observable”, i.e. a state that is not computed but can be constructed on-demand. This is one of the ways that SciML reaches its speed: you can have 100,000 equations, but solve only 1,000 to then automatically reconstruct the full set. Here, it's just 3 equations to 2, but as models get more complex, the symbolic system will find ever more clever interactions!","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now that we have simplified our system, let's turn it into a numerical problem to approximate. This is done with the ODEProblem constructor, that transforms it from a symbolic ModelingToolkit representation to a numerical DifferentialEquations representation. We need to tell it the numerical details now:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Whether to override any of the default values for the initial conditions and parameters.\nWhat is the initial time point.\nHow long to integrate it for.","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"In this case, we will use the default values for all our variables, so we will pass a blank override []. If for example we did want to change the initial condition of x to 2.0 and α to 4.0, we would do [x => 2.0, α => 4.0]. Then secondly, we pass a tuple for the time span, (0.0,10.0) meaning start at 0.0 and end at 10.0. This looks like:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Convert from a symbolic to a numerical problem to simulate\ntspan = (0.0, 10.0)\nprob = ODEProblem(sys, [], tspan)","category":"page"},{"location":"getting_started/first_simulation/#Step-4:-Solve-the-ODE-System","page":"Build and run your first simulation with Julia's SciML","title":"Step 4: Solve the ODE System","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now we solve the ODE system. Julia's SciML solvers have a defaulting system that can automatically determine an appropriate solver for a given system, so we can just tell it to solve:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Solve the ODE\nsol = solve(prob)","category":"page"},{"location":"getting_started/first_simulation/#Step-5:-Visualize-the-Solution","page":"Build and run your first simulation with Julia's SciML","title":"Step 5: Visualize the Solution","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now let's visualize the solution! Notice that our solution only has two states. If we recall, the simplified system only has two states: z was symbolically eliminated. We can access any of the values, even the eliminated values, using the symbolic variable as the index. For example:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"sol[z]","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"returns the time series of the observable z at time points corresponding to sol.t. We can use this with the automated plotting functionality. First let's create a plot of x and y over time using plot(sol) which will plot all of the states. Then next, we will explicitly tell it to make a plot with the index being z, i.e. idxs=z.","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"note: Note\nNote that one can pass an array of indices as well, so idxs=[x,y,z] would make a plot with all three lines together!","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"# Plot the solution\np1 = plot(sol, title = \"Rabbits vs Wolves\")","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"p2 = plot(sol, idxs = z, title = \"Total Animals\")","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Finally, let's make a plot where we merge these two plot elements. To do so, we can take our two plot objects, p1 and p2, and make a plot with both of them. Then we tell Plots to do a layout of (2,1), or 2 rows and 1 columns. Let's see what happens when we bring these together:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"plot(p1, p2, layout = (2, 1))","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"And tada, we have a full analysis of our ecosystem!","category":"page"},{"location":"getting_started/first_simulation/#Bonus-Step:-Emoji-Variables","page":"Build and run your first simulation with Julia's SciML","title":"Bonus Step: Emoji Variables","text":"","category":"section"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"If you made it this far, then congrats, you get to learn a fun fact! Since Julia code can use Unicode, emojis work for variable names. Here's the simulation using emojis of rabbits and wolves to define the system:","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"using ModelingToolkit, DifferentialEquations\n@parameters α=1.5 β=1.0 γ=3.0 δ=1.0\n@variables t 🐰(t)=1.0 🐺(t)=1.0\nD = Differential(t)\neqs = [D(🐰) ~ α * 🐰 - β * 🐰 * 🐺,\n    D(🐺) ~ -γ * 🐺 + δ * 🐰 * 🐺]\n\n@mtkbuild sys = ODESystem(eqs, t)\nprob = ODEProblem(sys, [], (0.0, 10.0))\nsol = solve(prob)","category":"page"},{"location":"getting_started/first_simulation/","page":"Build and run your first simulation with Julia's SciML","title":"Build and run your first simulation with Julia's SciML","text":"Now go make your professor mad that they have to grade a fully emojified code. I'll vouch for you: the documentation told you to do this.","category":"page"},{"location":"highlevels/numerical_utilities/#SciML-Numerical-Utility-Libraries","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"","category":"section"},{"location":"highlevels/numerical_utilities/#ExponentialUtilities.jl:-Faster-Matrix-Exponentials","page":"SciML Numerical Utility Libraries","title":"ExponentialUtilities.jl: Faster Matrix Exponentials","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"ExponentialUtilities.jl is a library for efficient computation of matrix exponentials. While Julia has a built-in exp(A) method, ExponentialUtilities.jl offers many features around this to improve performance in scientific contexts, including:","category":"page"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"Faster methods for (non-allocating) matrix exponentials via exponential!\nMethods for computing matrix exponential that are generic to number types and arrays (i.e. GPUs)\nMethods for computing Arnoldi iterations on Krylov subspaces\nDirect computation of exp(t*A)*v, i.e. exponentiation of a matrix times a vector, without computing the matrix exponential\nDirect computation of ϕ_m(t*A)*v operations, where ϕ_0(z) = exp(z) and ϕ_(k+1)(z) = (ϕ_k(z) - 1) / z","category":"page"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"ExponentialUtilities.jl includes complex adaptive time stepping techniques such as KIOPS in order to perform these calculations in a fast and numerically-stable way.","category":"page"},{"location":"highlevels/numerical_utilities/#QuasiMonteCarlo.jl:-Fast-Quasi-Random-Number-Generation","page":"SciML Numerical Utility Libraries","title":"QuasiMonteCarlo.jl: Fast Quasi-Random Number Generation","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"QuasiMonteCarlo.jl is a library for fast generation of low discrepancy Quasi-Monte Carlo samples, using methods like:","category":"page"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"GridSample(dx) where the grid is given by lb:dx[i]:ub in the ith direction.\nUniformSample for uniformly distributed random numbers.\nSobolSample for the Sobol sequence.\nLatinHypercubeSample for a Latin Hypercube.\nLatticeRuleSample for a randomly-shifted rank-1 lattice rule.\nLowDiscrepancySample(base) where base[i] is the base in the ith direction.\nGoldenSample for a Golden Ratio sequence.\nKroneckerSample(alpha, s0) for a Kronecker sequence, where alpha is a length-d vector of irrational numbers (often sqrt(d)) and s0 is a length-d seed vector (often 0).\nSectionSample(x0, sampler) where sampler is any sampler above and x0 is a vector of either NaN for a free dimension or some scalar for a constrained dimension.","category":"page"},{"location":"highlevels/numerical_utilities/#DataInterpolations.jl:-One-Dimensional-Interpolations","page":"SciML Numerical Utility Libraries","title":"DataInterpolations.jl: One-Dimensional Interpolations","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"DataInterpolations.jl is a library of one-dimensional interpolation schemes which are composable with automatic differentiation and the SciML ecosystem. It includes direct interpolation methods and regression techniques for handling noisy data. Its methods include:","category":"page"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"ConstantInterpolation(u,t) - A piecewise constant interpolation.\nLinearInterpolation(u,t) - A linear interpolation.\nQuadraticInterpolation(u,t) - A quadratic interpolation.\nLagrangeInterpolation(u,t,n) - A Lagrange interpolation of order n.\nQuadraticSpline(u,t) - A quadratic spline interpolation.\nCubicSpline(u,t) - A cubic spline interpolation.\nBSplineInterpolation(u,t,d,pVec,knotVec) - An interpolation B-spline. This is a B-spline which hits each of the data points. The argument choices are:\nd - degree of B-spline\npVec - Symbol to Parameters Vector, pVec = :Uniform for uniform spaced parameters and pVec = :ArcLen for parameters generated by chord length method.\nknotVec - Symbol to Knot Vector, knotVec = :Uniform for uniform knot vector, knotVec = :Average for average spaced knot vector.\nBSplineApprox(u,t,d,h,pVec,knotVec) - A regression B-spline which smooths the fitting curve. The argument choices are the same as the BSplineInterpolation, with the additional parameter h<length(t) which is the number of control points to use, with smaller h indicating more smoothing.\nCurvefit(u,t,m,p,alg) - An interpolation which is done by fitting a user-given functional form m(t,p) where p is the vector of parameters. The user's input p is an initial value for a least-square fitting, alg is the algorithm choice used to optimize the cost function (sum of squared deviations) via Optim.jl and optimal ps are used in the interpolation.","category":"page"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"These interpolations match the SciML interfaces and have direct support for packages like ModelingToolkit.jl.","category":"page"},{"location":"highlevels/numerical_utilities/#PoissonRandom.jl:-Fast-Poisson-Random-Number-Generation","page":"SciML Numerical Utility Libraries","title":"PoissonRandom.jl: Fast Poisson Random Number Generation","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"PoissonRandom.jl is just fast Poisson random number generation for Poisson processes, like chemical master equations.","category":"page"},{"location":"highlevels/numerical_utilities/#PreallocationTools.jl:-Write-Non-Allocating-Code-Easier","page":"SciML Numerical Utility Libraries","title":"PreallocationTools.jl: Write Non-Allocating Code Easier","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"PreallocationTools.jl is a library of tools for writing non-allocating code that interacts well with advanced features like automatic differentiation and symbolics.","category":"page"},{"location":"highlevels/numerical_utilities/#RuntimeGeneratedFunctions.jl:-Efficient-Staged-Programming-in-Julia","page":"SciML Numerical Utility Libraries","title":"RuntimeGeneratedFunctions.jl: Efficient Staged Programming in Julia","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"RuntimeGeneratedFunctions.jl allows for staged programming in Julia, compiling functions at runtime with full optimizations. This is used by many libraries such as ModelingToolkit.jl to allow for runtime code generation for improved performance.","category":"page"},{"location":"highlevels/numerical_utilities/#EllipsisNotation.jl:-Implementation-of-Ellipsis-Array-Slicing","page":"SciML Numerical Utility Libraries","title":"EllipsisNotation.jl: Implementation of Ellipsis Array Slicing","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"EllipsisNotation.jl defines the ellipsis array slicing notation for Julia. It uses .. as a catch-all for “all dimensions”, allowing for indexing like [..,1] to mean [:,:,:,1] on four dimensional arrays, in a way that is generic to the number of dimensions in the underlying array.","category":"page"},{"location":"highlevels/numerical_utilities/#Third-Party-Libraries-to-Note","page":"SciML Numerical Utility Libraries","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/numerical_utilities/#Distributions.jl:-Representations-of-Probability-Distributions","page":"SciML Numerical Utility Libraries","title":"Distributions.jl: Representations of Probability Distributions","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"Distributions.jl is a library for defining distributions in Julia. It's used all throughout the SciML libraries for specifications of probability distributions.","category":"page"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"note: Note\nFor full compatibility with automatic differentiation, see DistributionsAD.jl","category":"page"},{"location":"highlevels/numerical_utilities/#FFTW.jl:-Fastest-Fourier-Transformation-in-the-West","page":"SciML Numerical Utility Libraries","title":"FFTW.jl: Fastest Fourier Transformation in the West","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"FFTW.jl is the preferred library for fast Fourier Transformations on the CPU.","category":"page"},{"location":"highlevels/numerical_utilities/#SpecialFunctions.jl:-Implementations-of-Mathematical-Special-Functions","page":"SciML Numerical Utility Libraries","title":"SpecialFunctions.jl: Implementations of Mathematical Special Functions","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"SpecialFunctions.jl is a library of implementations of special functions, like Bessel functions and error functions (erf). This library is compatible with automatic differentiation.","category":"page"},{"location":"highlevels/numerical_utilities/#LoopVectorization.jl:-Automated-Loop-Accelerator","page":"SciML Numerical Utility Libraries","title":"LoopVectorization.jl: Automated Loop Accelerator","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"LoopVectorization.jl is a library which provides the @turbo and @tturbo macros for accelerating the computation of loops. This can be used to accelerating the model functions sent to the equation solvers, for example, accelerating handwritten PDE discretizations.","category":"page"},{"location":"highlevels/numerical_utilities/#Polyester.jl:-Cheap-Threads","page":"SciML Numerical Utility Libraries","title":"Polyester.jl: Cheap Threads","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"Polyester.jl is a cheaper version of threads for Julia, which use a set pool of threads for lower overhead. Note that Polyester does not compose with the standard Julia composable threading infrastructure, and thus one must take care not to compose two levels of Polyester, as this will oversubscribe the computation and lead to performance degradation. Many SciML solvers have options to use Polyester for threading to achieve the top performance.","category":"page"},{"location":"highlevels/numerical_utilities/#Tullio.jl:-Fast-Tensor-Calculations-and-Einstein-Notation","page":"SciML Numerical Utility Libraries","title":"Tullio.jl: Fast Tensor Calculations and Einstein Notation","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"Tullio.jl is a library for fast tensor calculations with Einstein notation. It allows for defining operations which are compatible with automatic differentiation, GPUs, and more.","category":"page"},{"location":"highlevels/numerical_utilities/#ParallelStencil.jl:-High-Level-Code-for-Parallelized-Stencil-Computations","page":"SciML Numerical Utility Libraries","title":"ParallelStencil.jl: High-Level Code for Parallelized Stencil Computations","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"ParallelStencil.jl is a library for writing high-level code for parallelized stencil computations. It is compatible with SciML equation solvers and is thus a good way to generate GPU and distributed parallel model code.","category":"page"},{"location":"highlevels/numerical_utilities/#Julia-Utilities","page":"SciML Numerical Utility Libraries","title":"Julia Utilities","text":"","category":"section"},{"location":"highlevels/numerical_utilities/#StaticCompiler.jl","page":"SciML Numerical Utility Libraries","title":"StaticCompiler.jl","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"StaticCompiler.jl is a package for generating static binaries from Julia code. It only supports a subset of Julia, so not all equation solver algorithms are compatible with StaticCompiler.jl.","category":"page"},{"location":"highlevels/numerical_utilities/#PackageCompiler.jl","page":"SciML Numerical Utility Libraries","title":"PackageCompiler.jl","text":"","category":"section"},{"location":"highlevels/numerical_utilities/","page":"SciML Numerical Utility Libraries","title":"SciML Numerical Utility Libraries","text":"PackageCompiler.jl is a package for generating shared libraries from Julia code. It builds the entirety of Julia by bundling a system image with the Julia runtime. It thus builds complete binaries that can hold all the functionality of SciML. Furthermore, it can also be used to generate new system images to decrease startup times and remove JIT-compilation from SciML usage.","category":"page"},{"location":"highlevels/developer_documentation/#Developer-Documentation","page":"Developer Documentation","title":"Developer Documentation","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"For uniformity and clarity, the SciML Open-Source Software Organization has many well-defined rules and practices for its development. However, we stress one important principle:","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"Do not be deterred from contributing if you think you do not know everything. No one knows everything. These rules and styles are designed for iterative contributions. Open pull requests and contribute what you can with what you know, and the maintainers will help you learn and do the rest!","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"If you need any help contributing, please feel welcome joining our community channels.","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"The diffeq-bridged and sciml-bridged channels in the Julia Zulip Chat\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"We welcome everybody.","category":"page"},{"location":"highlevels/developer_documentation/#Getting-Started-With-Contributing-to-SciML","page":"Developer Documentation","title":"Getting Started With Contributing to SciML","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"To get started contributing to SciML, check out the following resources:","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"Developing Julia Packages\nGetting Started with Julia (for Experienced Programmers)","category":"page"},{"location":"highlevels/developer_documentation/#SciMLStyle:-The-SciML-Style-Guide-for-Julia","page":"Developer Documentation","title":"SciMLStyle: The SciML Style Guide for Julia","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"(Image: SciML Code Style)","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"This is a style guide for how to program in Julia for SciML contributions. It describes everything one needs to know, from preferred naming schemes of functions to fundamental dogmas for designing traits. We stress that this style guide is meant to be comprehensive for the sake of designing automatic formatters and teaching desired rules, but complete knowledge and adherence to the style guide is not required for contributions!","category":"page"},{"location":"highlevels/developer_documentation/#COLPRAC:-Contributor's-Guide-on-Collaborative-Practices-for-Community-Packages","page":"Developer Documentation","title":"COLPRAC: Contributor's Guide on Collaborative Practices for Community Packages","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"(Image: ColPrac: Contributor's Guide on Collaborative Practices for Community Packages)","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"What are the rules for when PRs should be merged? What are the rules for whether to tag a major, minor, or patch release? All of these development rules are defined in COLPRAC.","category":"page"},{"location":"highlevels/developer_documentation/#DiffEq-Developer-Documentation","page":"Developer Documentation","title":"DiffEq Developer Documentation","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"There are many solver libraries which share similar internals, such as OrdinaryDiffEq.jl, StochasticDiffEq.jl, and DelayDiffEq.jl. This section of the documentation describes the internal systems of these packages and how they are used to quickly write efficient solvers.","category":"page"},{"location":"highlevels/developer_documentation/#Third-Party-Libraries-to-Note","page":"Developer Documentation","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/developer_documentation/#Documenter.jl","page":"Developer Documentation","title":"Documenter.jl","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"Documenter.jl is the documentation generation library that the SciML organization uses, and thus its documentation is the documentation of the documentation.","category":"page"},{"location":"highlevels/developer_documentation/#JuliaFormatter.jl","page":"Developer Documentation","title":"JuliaFormatter.jl","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"JuliaFormatter.jl is the formatter used by the SciML organization to enforce the SciML Style. Setting style = \"sciml\" in a .JuliaFormatter.toml file of a repo and using the standard FormatCheck.yml as part of continuous integration makes JuliaFormatter check for SciML Style compliance on pull requests.","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"To run JuliaFormatter in a SciML repository, do:","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"using JuliaFormatter, DevedPackage\nJuliaFormatter.format(pkgdir(DevedPackage))","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"which will reformat the code according to the SciML Style.","category":"page"},{"location":"highlevels/developer_documentation/#GitHub-Actions-Continuous-Integrations","page":"Developer Documentation","title":"GitHub Actions Continuous Integrations","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"The SciML Organization uses continuous integration testing to always ensure tests are passing when merging pull requests. The organization uses the GitHub Actions supplied by Julia Actions to accomplish this. Common continuous integration scripts are:","category":"page"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"CI.yml, the standard CI script\nDownstream.yml, used to specify packages for downstream testing. This will make packages which depend on the current package also be tested to ensure that “non-breaking changes” do not actually break other packages.\nDocumentation.yml, used to run the documentation automatic generation with Documenter.jl\nFormatCheck.yml, used to check JuliaFormatter SciML Style compliance","category":"page"},{"location":"highlevels/developer_documentation/#CompatHelper","page":"Developer Documentation","title":"CompatHelper","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"CompatHelper is used to automatically create pull requests whenever a dependent package is upper bounded. The results of CompatHelper PRs should be checked to ensure that the latest version of the dependencies are grabbed for the test process. After successful CompatHelper PRs, i.e. if the increase of the upper bound did not cause a break to the tests, a new version tag should follow. It is set up by adding the CompatHelper.yml GitHub action.","category":"page"},{"location":"highlevels/developer_documentation/#TagBot","page":"Developer Documentation","title":"TagBot","text":"","category":"section"},{"location":"highlevels/developer_documentation/","page":"Developer Documentation","title":"Developer Documentation","text":"TagBot automatically creates tags in the GitHub repository whenever a package is registered to the Julia General repository. It is set up by adding the TagBot.yml GitHub action.","category":"page"},{"location":"highlevels/modeling_languages/#Modeling-Languages","page":"Modeling Languages","title":"Modeling Languages","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"While in theory one can build perfect code for all models from scratch, in practice many scientists and engineers need or want some help! The SciML modeling tools provide a higher level interface over the equation solver, which helps the translation from good models to good simulations in a way that abstracts away the mathematical and computational details without giving up performance.","category":"page"},{"location":"highlevels/modeling_languages/#ModelingToolkit.jl:-Acausal-Symbolic-Modeling","page":"Modeling Languages","title":"ModelingToolkit.jl: Acausal Symbolic Modeling","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"Acausal modeling is an extension of causal modeling that is more composable and allows for more code reuse. Build a model of an electric engine, then build a model of a battery, and now declare connections by stating \"the voltage at the engine equals the voltage at the connector of the battery\", and generate the composed model. The tool for this is ModelingToolkit.jl. ModelingToolkit.jl is a sophisticated symbolic modeling library which allows for specifying these types of large-scale differential equation models in a simple way, abstracting away the computational details. However, its symbolic analysis allows for generating much more performant code for differential-algebraic equations than most users could ever write by hand, with its structural_simplify automatically correcting the model to improve parallelism, numerical stability, and automatically remove variables which it can show are redundant.","category":"page"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"ModelingToolkit.jl is the base of the SciML symbolic modeling ecosystem, defining the AbstractSystem types, such as ODESystem, SDESystem, OptimizationSystem, PDESystem, and more, which are then used by all the other modeling tools. As such, when using other modeling tools like Catalyst.jl, the reference for all the things that can be done with the symbolic representation is simply ModelingToolkit.jl.","category":"page"},{"location":"highlevels/modeling_languages/#Catalyst.jl:-Chemical-Reaction-Networks-(CRN),-Systems-Biology,-and-Quantitative-Systems-Pharmacology-(QSP)-Modeling","page":"Modeling Languages","title":"Catalyst.jl: Chemical Reaction Networks (CRN), Systems Biology, and Quantitative Systems Pharmacology (QSP) Modeling","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"Catalyst.jl is a modeling interface for efficient simulation of mass action ODE, chemical Langevin SDE, and stochastic chemical kinetics jump process (i.e. chemical master equation) models for chemical reaction networks and population processes. It uses a highly intuitive chemical reaction syntax interface, which generates all the extra functionality necessary for the fastest use with JumpProcesses.jl, DifferentialEquations.jl, and higher level SciML libraries. Its ReactionSystem type is a programmable extension of the ModelingToolkit AbstractSystem interface, meaning that complex reaction systems are represented symbolically, and then compiled to optimized representations automatically when converting ReactionSystems to concrete ODE/SDE/jump process representations. Catalyst also provides functionality to support chemical reaction network and steady-state analysis.","category":"page"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"For an overview of the library, see Modeling Biochemical Systems with Catalyst.jl - Samuel Isaacson","category":"page"},{"location":"highlevels/modeling_languages/#NBodySimulator.jl:-A-differentiable-simulator-for-N-body-problems,-including-astrophysical-and-molecular-dynamics","page":"Modeling Languages","title":"NBodySimulator.jl: A differentiable simulator for N-body problems, including astrophysical and molecular dynamics","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"NBodySimulator.jl is a differentiable simulator for N-body problems, including astrophysical and molecular dynamics. It uses the DifferentialEquations.jl solvers, allowing for one to choose between a large variety of symplectic integration schemes. It implements many of the thermostats required for doing standard molecular dynamics approximations.","category":"page"},{"location":"highlevels/modeling_languages/#DiffEqFinancial.jl:-Financial-models-for-use-in-the-DifferentialEquations-ecosystem","page":"Modeling Languages","title":"DiffEqFinancial.jl: Financial models for use in the DifferentialEquations ecosystem","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"The goal of DiffEqFinancial.jl is to be a feature-complete set of solvers for the types of problems found in libraries like QuantLib, such as the Heston process or the Black-Scholes model.","category":"page"},{"location":"highlevels/modeling_languages/#ParameterizedFunctions.jl:-Simple-Differential-Equation-Definitions-Made-Easy","page":"Modeling Languages","title":"ParameterizedFunctions.jl: Simple Differential Equation Definitions Made Easy","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"(Image: )","category":"page"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"This image that went viral is actually runnable code from ParameterizedFunctions.jl. Define equations and models using a very simple high-level syntax and let the code generation tools build symbolic fast Jacobian, gradient, etc. functions for you.","category":"page"},{"location":"highlevels/modeling_languages/#Third-Party-Tools-of-Note","page":"Modeling Languages","title":"Third-Party Tools of Note","text":"","category":"section"},{"location":"highlevels/modeling_languages/#MomentClosure.jl:-Automated-Generation-of-Moment-Closure-Equations","page":"Modeling Languages","title":"MomentClosure.jl: Automated Generation of Moment Closure Equations","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"MomentClosure.jl is a library for generating the moment closure equations for a given chemical master equation or stochastic differential equation. Thus instead of solving a stochastic model thousands of times to find the mean and variance, this library can generate the deterministic equations for how the mean and variance evolve in order to be solved in a single run. MomentClosure.jl uses Catalyst ReactionSystem and ModelingToolkit SDESystem types as the input for its symbolic generation processes.","category":"page"},{"location":"highlevels/modeling_languages/#Agents.jl:-Agent-Based-Modeling-Framework-in-Julia","page":"Modeling Languages","title":"Agents.jl: Agent-Based Modeling Framework in Julia","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"If one wants to do agent-based modeling in Julia, Agents.jl is the go-to library. It's fast and flexible, making it a solid foundation for any agent-based model.","category":"page"},{"location":"highlevels/modeling_languages/#Unitful.jl:-A-Julia-package-for-physical-units","page":"Modeling Languages","title":"Unitful.jl: A Julia package for physical units","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"Supports not only SI units, but also any other unit system. Unitful.jl has minimal run-time penalty of units. Includes facilities for dimensional analysis, and integrates easily with the usual mathematical operations and collections that are defined in Julia.","category":"page"},{"location":"highlevels/modeling_languages/#ReactionMechanismSimulator.jl:-Simulation-and-Analysis-of-Large-Chemical-Reaction-Systems","page":"Modeling Languages","title":"ReactionMechanismSimulator.jl: Simulation and Analysis of Large Chemical Reaction Systems","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"ReactionMechanismSimulator.jl is a tool for simulating and analyzing large chemical reaction mechanisms. It interfaces with the ReactionMechanismGenerator suite for automatically constructing reaction pathways from chemical components to quickly build realistic models of chemical systems.","category":"page"},{"location":"highlevels/modeling_languages/#FiniteStateProjection.jl:-Direct-Solution-of-Chemical-Master-Equations","page":"Modeling Languages","title":"FiniteStateProjection.jl: Direct Solution of Chemical Master Equations","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"FiniteStateProjection.jl is a library for finite state projection direct solving of the chemical master equation. It automatically converts the Catalyst ReactionSystem definitions into ModelingToolkit ODESystem representations for the evolution of probability distributions to allow for directly solving the weak form of the stochastic model.","category":"page"},{"location":"highlevels/modeling_languages/#AlgebraicPetri.jl:-Applied-Category-Theory-of-Modeling","page":"Modeling Languages","title":"AlgebraicPetri.jl: Applied Category Theory of Modeling","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"AlgebraicPetri.jl is a library for automating the intuitive generation of dynamical models using a Category theory-based approach.","category":"page"},{"location":"highlevels/modeling_languages/#QuantumOptics.jl:-Simulating-quantum-systems.","page":"Modeling Languages","title":"QuantumOptics.jl: Simulating quantum systems.","text":"","category":"section"},{"location":"highlevels/modeling_languages/","page":"Modeling Languages","title":"Modeling Languages","text":"QuantumOptics.jl makes it easy to simulate various kinds of quantum systems. It is inspired by the Quantum Optics Toolbox for MATLAB and the Python framework QuTiP.","category":"page"},{"location":"highlevels/learning_resources/#Curated-Learning,-Teaching,-and-Training-Resources","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"","category":"section"},{"location":"highlevels/learning_resources/","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"While the SciML documentation is made to be comprehensive, there will always be good alternative resources. The purpose of this section of the documentation is to highlight the alternative resources which can be helpful for learning how to use the SciML Open-Source Software libraries.","category":"page"},{"location":"highlevels/learning_resources/#JuliaCon-and-SciMLCon-Videos","page":"Curated Learning, Teaching, and Training Resources","title":"JuliaCon and SciMLCon Videos","text":"","category":"section"},{"location":"highlevels/learning_resources/","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"Many tutorials and introductions to packages have been taught through previous JuliaCon/SciMLCon workshops and talks. The following is a curated list of such training videos:","category":"page"},{"location":"highlevels/learning_resources/","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"Intro to solving differential equations in Julia\nJuliaCon 2020 | Doing Scientific Machine Learning (SciML) With Julia\nSimulating Big Models in Julia with ModelingToolkit | Workshop | JuliaCon 2021\nStructural Identifiability Tools in Julia: A Tutorial | Ilia Ilmer | SciMLCon 2022\nJuliaCon 2018 | Solving Partial Differential Equations with Julia | Chris Rackauckas","category":"page"},{"location":"highlevels/learning_resources/#SciML-Book:-Parallel-Computing-and-Scientific-Machine-Learning-(SciML):-Methods-and-Applications","page":"Curated Learning, Teaching, and Training Resources","title":"SciML Book: Parallel Computing and Scientific Machine Learning (SciML): Methods and Applications","text":"","category":"section"},{"location":"highlevels/learning_resources/","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"The book Parallel Computing and Scientific Machine Learning (SciML): Methods and Applications is a compilation of the lecture notes from the MIT Course 18.337J/6.338J: Parallel Computing and Scientific Machine Learning. It contains a walkthrough of many of the methods implemented in the SciML libraries, as well as how to understand much of the functionality at a deeper level. This course was intended for MIT graduate students in engineering, computer science, and mathematics and thus may have a high prerequisite requirement than many other resources.","category":"page"},{"location":"highlevels/learning_resources/#sir-julia:-Various-implementations-of-the-classical-SIR-model-in-Julia","page":"Curated Learning, Teaching, and Training Resources","title":"sir-julia: Various implementations of the classical SIR model in Julia","text":"","category":"section"},{"location":"highlevels/learning_resources/","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"For those who like to learn by example, the repository sir-julia is a great resource! It showcases how to use the SciML libraries in many different ways to simulate different variations of the classic SIR epidemic model.","category":"page"},{"location":"highlevels/learning_resources/#Other-Books-Featuring-SciML","page":"Curated Learning, Teaching, and Training Resources","title":"Other Books Featuring SciML","text":"","category":"section"},{"location":"highlevels/learning_resources/","page":"Curated Learning, Teaching, and Training Resources","title":"Curated Learning, Teaching, and Training Resources","text":"Nonlinear Dynamics: A Concise Introduction Interlaced with Code\nNumerical Methods for Scientific Computing: The Definitive Manual for Math Geeks\nFundamentals of Numerical Computation\nStatistics with Julia\nStatistical Rethinking with Julia\nThe Koopman Operator in Systems and Control\n“All simulations have been performed in Julia, with additional Julia packages: LinearAlgebra.jl, Random.jl, Plots.jl, Lasso.jl, DifferentialEquations.jl”","category":"page"},{"location":"showcase/blackhole/#blackhole","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"In this showcase we will demonstrate using Newtonian mechanics as prior known information in a universal differential equation and learning relativistic corrections to the physics via the gravitational waveform.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"This showcase is minimally adapted from Keith et al. 2021.","category":"page"},{"location":"showcase/blackhole/#Starting-Point:-The-Packages-To-Use","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Starting Point: The Packages To Use","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"There are many packages which are used as part of this showcase. Let's detail what they are and how they are used. For the neural network training:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Module Description\nOrdinaryDiffEq.jl (DifferentialEquations.jl) The numerical differential equation solvers\nSciMLSensitivity.jl The adjoint methods, defines gradients of ODE solvers\nOptimization.jl The optimization library\nOptimizationOptimisers.jl The optimization solver package with Adam\nOptimizationOptimJL.jl The optimization solver package with BFGS","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"For the symbolic model discovery:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Module Description\nModelingToolkit.jl The symbolic modeling environment\nDataDrivenDiffEq.jl The symbolic regression interface\nDataDrivenSparse.jl The sparse regression symbolic regression solvers\nZygote.jl The automatic differentiation library for fast gradients","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Julia standard libraries:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Module Description\nLinearAlgebra Required for the norm function\nStatistics Required for the mean function","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"And external libraries:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Module Description\nLux.jl The deep learning (neural network) framework\nComponentArrays.jl For the ComponentArray type to match Lux to SciML\nLineSearches.jl Allows for setting a line search for optimization\nDataFrames.jl A nice and easy data handling format\nCSV.jl Import and export of CSV files\nPlots.jl The plotting and visualization library\nStableRNGs.jl Stable random seeding","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"# SciML Tools\nusing OrdinaryDiffEq, ModelingToolkit, DataDrivenDiffEq, SciMLSensitivity, DataDrivenSparse\nusing Optimization, OptimizationOptimisers, OptimizationOptimJL\n\n# Standard Libraries\nusing LinearAlgebra, Statistics\n\n# External Libraries\nusing ComponentArrays, Lux, Zygote, Plots, StableRNGs, DataFrames, CSV, LineSearches\ngr()\n\n# Set a random seed for reproducible behaviour\nrng = StableRNG(1111)","category":"page"},{"location":"showcase/blackhole/#Problem-Setup","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Problem Setup","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"For this example we will use the known relativistic relations to generate data matching the expected LIGO gravitational waveforms. Details can be found in  Keith et al. 2021.","category":"page"},{"location":"showcase/blackhole/#Feel-free-to-skip-reading-this-setup-code!","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Feel free to skip reading this setup code!","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"<details><summary>The setup of the data and the ODEs for the Newtonian ODE model</summary>","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"\n#=\n    ODE models for orbital mechanics\n=#\n\nfunction NewtonianOrbitModel(u, model_params, t)\n    #=\n        Defines system of odes which describes motion of\n        point like particle with Newtonian physics, uses\n\n        u[1] = χ\n        u[2] = ϕ\n\n        where, p, M, and e are constants\n    =#\n    χ, ϕ = u\n    p, M, e = model_params\n\n    numer = (1 + e * cos(χ))^2\n    denom = M * (p^(3 / 2))\n\n    χ̇ = numer / denom\n    ϕ̇ = numer / denom\n\n    return [χ̇, ϕ̇]\nend\n\nfunction RelativisticOrbitModel(u, model_params, t)\n    #=\n        Defines system of odes which describes motion of\n        point like particle in schwarzschild background, uses\n\n        u[1] = χ\n        u[2] = ϕ\n\n        where, p, M, and e are constants\n    =#\n    χ, ϕ = u\n    p, M, e = model_params\n\n    numer = (p - 2 - 2 * e * cos(χ)) * (1 + e * cos(χ))^2\n    denom = sqrt((p - 2)^2 - 4 * e^2)\n\n    χ̇ = numer * sqrt(p - 6 - 2 * e * cos(χ)) / (M * (p^2) * denom)\n    ϕ̇ = numer / (M * (p^(3 / 2)) * denom)\n\n    return [χ̇, ϕ̇]\nend\n\nfunction AbstractNNOrbitModel(u, model_params, t; NN = nothing, NN_params = nothing)\n    #=\n        Defines system of odes which describes motion of\n        point like particle with Newtonian physics, uses\n\n        u[1] = χ\n        u[2] = ϕ\n\n        where, p, M, and e are constants\n    =#\n    χ, ϕ = u\n    p, M, e = model_params\n\n    if isnothing(NN)\n        nn = [1, 1]\n    else\n        nn = 1 .+ NN([u[1]], NN_params, st)[1]\n    end\n\n    numer = (1 + e * cos(χ))^2\n    denom = M * (p^(3 / 2))\n\n    χ̇ = (numer / denom) * nn[1]\n    ϕ̇ = (numer / denom) * nn[2]\n\n    return [χ̇, ϕ̇]\nend\n\nfunction AbstractNROrbitModel(u, model_params, t;\n        NN_chiphi = nothing, NN_chiphi_params = nothing,\n        NN_pe = nothing, NN_pe_params = nothing)\n    #=\n        Defines system of odes which describes motion of\n        point like particle with Newtonian physics, uses\n\n        u[1] = χ\n        u[2] = ϕ\n        u[3] = p\n        u[4] = e\n\n        q is the mass ratio\n    =#\n    χ, ϕ, p, e = u\n    q = model_params[1]\n    M = 1.0\n\n    if p <= 0\n        println(\"p = \", p)\n    end\n\n    if isnothing(NN_chiphi)\n        nn_chiphi = [1, 1]\n    else\n        nn_chiphi = 1 .+ NN_chiphi(u, NN_chiphi_params, st)\n    end\n\n    if isnothing(NN_pe)\n        nn_pe = [0, 0]\n    else\n        nn_pe = NN_pe(u, NN_pe_params, st)\n    end\n\n    numer = (1 + e * cos(χ))^2\n    denom = M * (abs(p)^(3 / 2))\n\n    χ̇ = (numer / denom) * nn_chiphi[1]\n    ϕ̇ = (numer / denom) * nn_chiphi[2]\n    ṗ = nn_pe[1]\n    ė = nn_pe[2]\n\n    return [χ̇, ϕ̇, ṗ, ė]\nend\n\n#=\n    Axiliary functions for orbital mechanics\n=#\nusing DelimitedFiles\n\nfunction soln2orbit(soln, model_params = nothing)\n    #=\n        Performs change of variables:\n        (χ(t),ϕ(t)) ↦ (x(t),y(t))\n    =#\n    if size(soln, 1) == 2\n        χ = soln[1, :]\n        ϕ = soln[2, :]\n        if length(model_params) == 3\n            p, M, e = model_params\n        else\n            error(\"model_params must have length 3 when size(soln,2) = 2\")\n        end\n    elseif size(soln, 1) == 4\n        χ = soln[1, :]\n        ϕ = soln[2, :]\n        p = soln[3, :]\n        e = soln[4, :]\n    else\n        error(\"size(soln,2) must be either 2 or 4\")\n    end\n\n    r = p ./ (1 .+ e .* cos.(χ))\n    x = r .* cos.(ϕ)\n    y = r .* sin.(ϕ)\n\n    orbit = vcat(x', y')\n    return orbit\nend\n\nfunction orbit2tensor(orbit, component, mass = 1.0)\n    #=\n        Construct trace-free moment tensor Ι(t) for orbit from BH orbit (x(t),y(t))\n\n        component defines the Cartesion indices in x,y. For example,\n        I_{22} is the yy component of the moment tensor.\n    =#\n    x = orbit[1, :]\n    y = orbit[2, :]\n\n    Ixx = x .^ 2\n    Iyy = y .^ 2\n    Ixy = x .* y\n    trace = Ixx .+ Iyy\n\n    if component[1] == 1 && component[2] == 1\n        tmp = Ixx .- (1.0 ./ 3.0) .* trace\n    elseif component[1] == 2 && component[2] == 2\n        tmp = Iyy .- (1.0 ./ 3.0) .* trace\n    else\n        tmp = Ixy\n    end\n\n    return mass .* tmp\nend\n\nfunction d_dt(v::AbstractVector, dt)\n    # uses second-order one-sided difference stencils at the endpoints; see https://doi.org/10.1090/S0025-5718-1988-0935077-0\n    a = -3 / 2 * v[1] + 2 * v[2] - 1 / 2 * v[3]\n    b = (v[3:end] .- v[1:(end - 2)]) / 2\n    c = 3 / 2 * v[end] - 2 * v[end - 1] + 1 / 2 * v[end - 2]\n    return [a; b; c] / dt\nend\n\nfunction d2_dt2(v::AbstractVector, dt)\n    # uses second-order one-sided difference stencils at the endpoints; see https://doi.org/10.1090/S0025-5718-1988-0935077-0\n    a = 2 * v[1] - 5 * v[2] + 4 * v[3] - v[4]\n    b = v[1:(end - 2)] .- 2 * v[2:(end - 1)] .+ v[3:end]\n    c = 2 * v[end] - 5 * v[end - 1] + 4 * v[end - 2] - v[end - 3]\n    return [a; b; c] / (dt^2)\nend\n\nfunction h_22_quadrupole_components(dt, orbit, component, mass = 1.0)\n    #=\n        x(t) and y(t) inputs are the trajectory of the orbiting BH.\n\n       WARNING: assuming x and y are on a uniform grid of spacing dt\n        x_index and y_index are 1,2,3 for x, y, and z indices.\n    =#\n\n    mtensor = orbit2tensor(orbit, component, mass)\n    mtensor_ddot = d2_dt2(mtensor, dt)\n\n    # return mtensor\n    return 2 * mtensor_ddot\nend\n\nfunction h_22_quadrupole(dt, orbit, mass = 1.0)\n    h11 = h_22_quadrupole_components(dt, orbit, (1, 1), mass)\n    h22 = h_22_quadrupole_components(dt, orbit, (2, 2), mass)\n    h12 = h_22_quadrupole_components(dt, orbit, (1, 2), mass)\n    return h11, h12, h22\nend\n\nfunction h_22_strain_one_body(dt, orbit)\n    h11, h12, h22 = h_22_quadrupole(dt, orbit)\n\n    h₊ = h11 - h22\n    hₓ = 2.0 * h12\n\n    scaling_const = sqrt(pi / 5)\n    return scaling_const * h₊, -scaling_const * hₓ\nend\n\nfunction h_22_quadrupole_two_body(dt, orbit1, mass1, orbit2, mass2)\n    h11_1, h12_1, h22_1 = h_22_quadrupole(dt, orbit1, mass1)\n    h11_2, h12_2, h22_2 = h_22_quadrupole(dt, orbit2, mass2)\n    h11 = h11_1 + h11_2\n    h12 = h12_1 + h12_2\n    h22 = h22_1 + h22_2\n    return h11, h12, h22\nend\n\nfunction h_22_strain_two_body(dt, orbit1, mass1, orbit2, mass2)\n    # compute (2,2) mode strain from orbits of BH 1 of mass1 and BH2 of mass 2\n\n    @assert abs(mass1 + mass2 - 1.0)<1e-12 \"Masses do not sum to unity\"\n\n    h11, h12, h22 = h_22_quadrupole_two_body(dt, orbit1, mass1, orbit2, mass2)\n\n    h₊ = h11 - h22\n    hₓ = 2.0 * h12\n\n    scaling_const = sqrt(pi / 5)\n    return scaling_const * h₊, -scaling_const * hₓ\nend\n\nfunction one2two(path, m1, m2)\n    #=\n        We need a very crude 2-body path\n\n        Assume the 1-body motion is a newtonian 2-body position vector r = r1 - r2\n        and use Newtonian formulas to get r1, r2\n        (e.g. Theoretical Mechanics of Particles and Continua 4.3)\n    =#\n\n    M = m1 + m2\n    r1 = m2 / M .* path\n    r2 = -m1 / M .* path\n\n    return r1, r2\nend\n\nfunction compute_waveform(dt, soln, mass_ratio, model_params = nothing)\n    @assert mass_ratio<=1.0 \"mass_ratio must be <= 1\"\n    @assert mass_ratio>=0.0 \"mass_ratio must be non-negative\"\n\n    orbit = soln2orbit(soln, model_params)\n    if mass_ratio > 0\n        mass1 = mass_ratio / (1.0 + mass_ratio)\n        mass2 = 1.0 / (1.0 + mass_ratio)\n\n        orbit1, orbit2 = one2two(orbit, mass1, mass2)\n        waveform = h_22_strain_two_body(dt, orbit1, mass1, orbit2, mass2)\n    else\n        waveform = h_22_strain_one_body(dt, orbit)\n    end\n    return waveform\nend\n\nfunction interpolate_time_series(tsteps, tdata, fdata)\n    @assert length(tdata)==length(fdata) \"lengths of tdata and fdata must match\"\n\n    interp_fdata = zeros(length(tsteps))\n    for j in 1:length(tsteps)\n        for i in 1:(length(tdata) - 1)\n            if tdata[i] <= tsteps[j] < tdata[i + 1]\n                weight = (tsteps[j] - tdata[i]) / (tdata[i + 1] - tdata[i])\n                interp_fdata[j] = (1 - weight) * fdata[i] + weight * fdata[i + 1]\n                break\n            end\n        end\n    end\n\n    return interp_fdata\nend\n\nfunction file2waveform(tsteps, filename = \"waveform.txt\")\n\n    # read in file\n    f = open(filename, \"r\")\n    data = readdlm(f)\n    tdata = data[:, 1]\n    wdata = data[:, 2]\n\n    # interpolate data to tsteps\n    waveform = interpolate_time_series(tsteps, tdata, wdata)\n\n    return waveform\nend\n\nfunction file2trajectory(tsteps, filename = \"trajectoryA.txt\")\n\n    # read in file\n    f = open(filename, \"r\")\n    data = readdlm(f)\n    tdata = data[:, 1]\n    xdata = data[:, 2]\n    ydata = data[:, 3]\n\n    # interpolate data to tsteps\n    x = interpolate_time_series(tsteps, tdata, xdata)\n    y = interpolate_time_series(tsteps, tdata, ydata)\n\n    return x, y\nend","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"</details>","category":"page"},{"location":"showcase/blackhole/#Testing-the-Model-Setup","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Testing the Model Setup","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Now let's test the relativistic orbital model. Let's choose a few parameters of interest:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"mass_ratio = 0.0         # test particle\nu0 = Float64[pi, 0.0]    # initial conditions\ndatasize = 250\ntspan = (0.0f0, 6.0f4)   # timespace for GW waveform\ntsteps = range(tspan[1], tspan[2], length = datasize)  # time at each timestep\ndt_data = tsteps[2] - tsteps[1]\ndt = 100.0\nmodel_params = [100.0, 1.0, 0.5]; # p, M, e","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"and demonstrate the gravitational waveform:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"prob = ODEProblem(RelativisticOrbitModel, u0, tspan, model_params)\nsoln = Array(solve(prob, RK4(), saveat = tsteps, dt = dt, adaptive = false))\nwaveform = compute_waveform(dt_data, soln, mass_ratio, model_params)[1]\nplt = plot(tsteps, waveform,\n    markershape = :circle, markeralpha = 0.25,\n    linewidth = 2, alpha = 0.5,\n    label = \"waveform data\", xlabel = \"Time\", ylabel = \"Waveform\")","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Looks great!","category":"page"},{"location":"showcase/blackhole/#Automating-the-Discovery-of-Relativistic-Equations-from-Newtonian-Physics","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Automating the Discovery of Relativistic Equations from Newtonian Physics","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Now let's learn the relativistic corrections directly from the data. To define the UDE, we will define a Lux neural network and pass it into our Newtonian Physics + Neural Network ODE definition from above:","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"NN = Lux.Chain((x) -> cos.(x),\n    Lux.Dense(1, 32, cos),\n    Lux.Dense(32, 32, cos),\n    Lux.Dense(32, 2))\np, st = Lux.setup(rng, NN)\nNN_params = ComponentArray{Float64}(p)\n\nfunction ODE_model(u, NN_params, t)\n    du = AbstractNNOrbitModel(u, model_params, t, NN = NN, NN_params = NN_params)\n    return du\nend","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Next, we can compute the orbital trajectory and gravitational waveform using the neural network with its initial weights.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"prob_nn = ODEProblem(ODE_model, u0, tspan, NN_params)\nsoln_nn = Array(solve(\n    prob_nn, RK4(), u0 = u0, p = NN_params, saveat = tsteps, dt = dt, adaptive = false))\nwaveform_nn = compute_waveform(dt_data, soln_nn, mass_ratio, model_params)[1]\nplot!(plt, tsteps, waveform_nn,\n    markershape = :circle, markeralpha = 0.25,\n    linewidth = 2, alpha = 0.5,\n    label = \"waveform NN\")\ndisplay(plt)","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"This is the model before training.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Next, we define the objective (loss) function to be minimized when training the neural differential equations.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"function loss(NN_params)\n    first_obs_to_use_for_training = 1\n    last_obs_to_use_for_training = length(waveform)\n    obs_to_use_for_training = first_obs_to_use_for_training:last_obs_to_use_for_training\n\n    pred = Array(solve(\n        prob_nn, RK4(), u0 = u0, p = NN_params, saveat = tsteps, dt = dt, adaptive = false))\n    pred_waveform = compute_waveform(dt_data, pred, mass_ratio, model_params)[1]\n\n    loss = ( sum(abs2, view(waveform,obs_to_use_for_training) .- view(pred_waveform,obs_to_use_for_training) ) )\n    return loss\nend","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"We can test the loss function and see that it returns a pair, a scalar loss and an array with the predicted waveform.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"loss(NN_params)","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"We'll use the following callback to save the history of the loss values.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"losses = []\n\ncallback(state, l; doplot = true) = begin\n    push!(losses, l)\n    #=  Disable plotting as it trains since in docs\n    display(l)\n    waveform = compute_waveform(dt_data, soln, mass_ratio, model_params)[1]\n    # plot current prediction against data\n    plt = plot(tsteps, waveform,\n        markershape=:circle, markeralpha = 0.25,\n        linewidth = 2, alpha = 0.5,\n        label=\"wform data (h22)\", legend=:topleft)\n    plot!(plt, tsteps, pred_waveform,\n        markershape=:circle, markeralpha = 0.25,\n        linewidth = 2, alpha = 0.5,\n        label = \"wform NN\")\n    if doplot\n        display(plot(plt))\n    end\n    # Tell sciml_train to not halt the optimization. If return true, then\n    # optimization stops.\n    =#\n    return false\nend","category":"page"},{"location":"showcase/blackhole/#Running-the-Training","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Running the Training","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"The next cell initializes the weights of the neural network and then trains the neural network. Training uses the BFGS optimizers.  This seems to give good results because the Newtonian model seems to give a very good initial guess.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"NN_params = NN_params .* 0 +\n            Float64(1e-4) * randn(StableRNG(2031), eltype(NN_params), size(NN_params))\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, ComponentVector{Float64}(NN_params))\nres1 = Optimization.solve(\n    optprob, OptimizationOptimisers.Adam(0.001f0), callback = callback, maxiters = 100)\noptprob = Optimization.OptimizationProblem(optf, res1.u)\nres2 = Optimization.solve(\n    optprob, BFGS(initial_stepnorm = 0.01, linesearch = LineSearches.BackTracking()),\n    callback = callback, maxiters = 20)","category":"page"},{"location":"showcase/blackhole/#Result-Analysis","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Result Analysis","text":"","category":"section"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Now, we'll plot the learned solutions of the neural ODE and compare them to our full physical model and the Newtonian model.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"reference_solution = solve(remake(prob, p = model_params, saveat = tsteps, tspan = tspan),\n    RK4(), dt = dt, adaptive = false)\n\noptimized_solution = solve(\n    remake(prob_nn, p = res2.minimizer, saveat = tsteps, tspan = tspan),\n    RK4(), dt = dt, adaptive = false)\nNewtonian_prob = ODEProblem(NewtonianOrbitModel, u0, tspan, model_params)\n\nNewtonian_solution = solve(\n    remake(Newtonian_prob, p = model_params, saveat = tsteps, tspan = tspan),\n    RK4(), dt = dt, adaptive = false)\n\ntrue_orbit = soln2orbit(reference_solution, model_params)\npred_orbit = soln2orbit(optimized_solution, model_params)\nNewt_orbit = soln2orbit(Newtonian_solution, model_params)\n\ntrue_waveform = compute_waveform(dt_data, reference_solution, mass_ratio, model_params)[1]\npred_waveform = compute_waveform(dt_data, optimized_solution, mass_ratio, model_params)[1]\nNewt_waveform = compute_waveform(dt_data, Newtonian_solution, mass_ratio, model_params)[1]\n\ntrue_orbit = soln2orbit(reference_solution, model_params)\npred_orbit = soln2orbit(optimized_solution, model_params)\nNewt_orbit = soln2orbit(Newtonian_solution, model_params)\nplt = plot(true_orbit[1, :], true_orbit[2, :], linewidth = 2, label = \"truth\")\nplot!(plt, pred_orbit[1, :], pred_orbit[2, :],\n    linestyle = :dash, linewidth = 2, label = \"prediction\")\nplot!(plt, Newt_orbit[1, :], Newt_orbit[2, :], linewidth = 2, label = \"Newtonian\")","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"plt = plot(tsteps, true_waveform, linewidth = 2, label = \"truth\",\n    xlabel = \"Time\", ylabel = \"Waveform\")\nplot!(plt, tsteps, pred_waveform, linestyle = :dash, linewidth = 2, label = \"prediction\")\nplot!(plt, tsteps, Newt_waveform, linewidth = 2, label = \"Newtonian\")","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"Now we'll do the same, but extrapolating the model out in time.","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"factor = 5\n\nextended_tspan = (tspan[1], factor * tspan[2])\nextended_tsteps = range(tspan[1], factor * tspan[2], length = factor * datasize)\nreference_solution = solve(\n    remake(prob, p = model_params, saveat = extended_tsteps, tspan = extended_tspan),\n    RK4(), dt = dt, adaptive = false)\noptimized_solution = solve(\n    remake(prob_nn, p = res2.minimizer, saveat = extended_tsteps, tspan = extended_tspan),\n    RK4(), dt = dt, adaptive = false)\nNewtonian_prob = ODEProblem(NewtonianOrbitModel, u0, tspan, model_params)\nNewtonian_solution = solve(\n    remake(\n        Newtonian_prob, p = model_params, saveat = extended_tsteps, tspan = extended_tspan),\n    RK4(), dt = dt, adaptive = false)\ntrue_orbit = soln2orbit(reference_solution, model_params)\npred_orbit = soln2orbit(optimized_solution, model_params)\nNewt_orbit = soln2orbit(Newtonian_solution, model_params)\nplt = plot(true_orbit[1, :], true_orbit[2, :], linewidth = 2, label = \"truth\")\nplot!(plt, pred_orbit[1, :], pred_orbit[2, :],\n    linestyle = :dash, linewidth = 2, label = \"prediction\")\nplot!(plt, Newt_orbit[1, :], Newt_orbit[2, :], linewidth = 2, label = \"Newtonian\")","category":"page"},{"location":"showcase/blackhole/","page":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","title":"Discovering the Relativistic Corrections to Binary Black Hole Dynamics","text":"true_waveform = compute_waveform(dt_data, reference_solution, mass_ratio, model_params)[1]\npred_waveform = compute_waveform(dt_data, optimized_solution, mass_ratio, model_params)[1]\nNewt_waveform = compute_waveform(dt_data, Newtonian_solution, mass_ratio, model_params)[1]\nplt = plot(extended_tsteps, true_waveform, linewidth = 2,\n    label = \"truth\", xlabel = \"Time\", ylabel = \"Waveform\")\nplot!(plt, extended_tsteps, pred_waveform, linestyle = :dash,\n    linewidth = 2, label = \"prediction\")\nplot!(plt, extended_tsteps, Newt_waveform, linewidth = 2, label = \"Newtonian\")","category":"page"},{"location":"highlevels/implicit_layers/#Implicit-Layer-Deep-Learning","page":"Implicit Layer Deep Learning","title":"Implicit Layer Deep Learning","text":"","category":"section"},{"location":"highlevels/implicit_layers/","page":"Implicit Layer Deep Learning","title":"Implicit Layer Deep Learning","text":"Implicit layer deep learning is a field which uses implicit rules, such as differential equations and nonlinear solvers, to define the layers of neural networks. This field has brought the potential to automatically optimize network depth and improve training performance. SciML's differentiable solver ecosystem is specifically designed to accommodate implicit layer methodologies, and provides libraries with pre-built layers for common methods.","category":"page"},{"location":"highlevels/implicit_layers/#DiffEqFlux.jl:-High-Level-Pre-Built-Architectures-for-Implicit-Deep-Learning","page":"Implicit Layer Deep Learning","title":"DiffEqFlux.jl: High Level Pre-Built Architectures for Implicit Deep Learning","text":"","category":"section"},{"location":"highlevels/implicit_layers/","page":"Implicit Layer Deep Learning","title":"Implicit Layer Deep Learning","text":"DiffEqFlux.jl is a library of pre-built architectures for implicit deep learning, including layer definitions for methods like:","category":"page"},{"location":"highlevels/implicit_layers/","page":"Implicit Layer Deep Learning","title":"Implicit Layer Deep Learning","text":"Neural Ordinary Differential Equations (Neural ODEs)\nCollocation-Based Neural ODEs (Neural ODEs without a solver, by far the fastest way!)\nMultiple Shooting Neural Ordinary Differential Equations\nNeural Stochastic Differential Equations (Neural SDEs)\nNeural Differential-Algebraic Equations (Neural DAEs)\nNeural Delay Differential Equations (Neural DDEs)\nAugmented Neural ODEs\nHamiltonian Neural Networks (with specialized second order and symplectic integrators)\nContinuous Normalizing Flows (CNF) and FFJORD","category":"page"},{"location":"highlevels/implicit_layers/#DeepEquilibriumNetworks.jl:-Deep-Equilibrium-Models-Made-Fast","page":"Implicit Layer Deep Learning","title":"DeepEquilibriumNetworks.jl: Deep Equilibrium Models Made Fast","text":"","category":"section"},{"location":"highlevels/implicit_layers/","page":"Implicit Layer Deep Learning","title":"Implicit Layer Deep Learning","text":"DeepEquilibriumNetworks.jl is a library of optimized layer implementations for Deep Equilibrium Models (DEQs). It uses special training techniques such as implicit-explicit regularization in order to accelerate the convergence over traditional implementations, all while using the optimized and flexible SciML libraries under the hood.","category":"page"},{"location":"getting_started/fit_simulation/#fit_simulation","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Running simulations is only half of the battle. Many times, in order to make the simulation realistic, you need to fit the simulation to data. The SciML ecosystem has integration with automatic differentiation and adjoint methods to automatically make the fitting process stable and efficient. Let's see this in action.","category":"page"},{"location":"getting_started/fit_simulation/#Required-Dependencies","page":"Fit a simulation to a dataset","title":"Required Dependencies","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"The following parts of the SciML Ecosystem will be used in this tutorial:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Module Description\nDifferentialEquations.jl The differential equation solvers\nOptimization.jl The numerical optimization package\nOptimizationPolyalgorithms.jl The optimizers we will use\nSciMLSensitivity.jl The connection of the SciML ecosystems to differentiation","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Along with the following general ecosystem packages:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Module Description\nPlots.jl The plotting and visualization package\nForwardDiff.jl The automatic differentiation package","category":"page"},{"location":"getting_started/fit_simulation/#Problem-Setup:-Fitting-Lotka-Volterra-Data","page":"Fit a simulation to a dataset","title":"Problem Setup: Fitting Lotka-Volterra Data","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Assume that we know that the dynamics of our system are given by the Lotka-Volterra dynamical system: Let x(t) be the number of rabbits in the environment and y(t) be the number of wolves. This is the same dynamical system as the first tutorial! The equation that defines the evolution of the species is given as follows:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"beginalign\nfracdxdt = alpha x - beta x y\nfracdydt = -gamma y + delta x y\nendalign","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"where alpha beta gamma delta are parameters. Starting from equal numbers of rabbits and wolves, x(0) = 1 and y(0) = 1.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now, in the first tutorial, we assumed:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Luckily, a local guide provided us with some parameters that seem to match the system!","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Sadly, magical nymphs do not always show up and give us parameters. Thus in this case, we will need to use Optimization.jl to optimize the model parameters to best fit some experimental data. We are given experimentally observed data of both rabbit and wolf populations over a time span of t_0 = 0 to t_f = 10 at every Delta t = 1. Can we figure out what the parameter values should be directly from the data?","category":"page"},{"location":"getting_started/fit_simulation/#Solution-as-Copy-Pastable-Code","page":"Fit a simulation to a dataset","title":"Solution as Copy-Pastable Code","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"using DifferentialEquations, Optimization, OptimizationPolyalgorithms, SciMLSensitivity\nusing ForwardDiff, Plots\n\n# Define experimental data\nt_data = 0:10\nx_data = [1.000 2.773 6.773 0.971 1.886 6.101 1.398 1.335 4.353 3.247 1.034]\ny_data = [1.000 0.259 2.015 1.908 0.323 0.629 3.458 0.508 0.314 4.547 0.906]\nxy_data = vcat(x_data, y_data)\n\n# Plot the provided data\nscatter(t_data, xy_data', label = [\"x Data\" \"y Data\"])\n\n# Setup the ODE function\nfunction lotka_volterra!(du, u, p, t)\n    x, y = u\n    α, β, δ, γ = p\n    du[1] = dx = α * x - β * x * y\n    du[2] = dy = -δ * y + γ * x * y\nend\n\n# Initial condition\nu0 = [1.0, 1.0]\n\n# Simulation interval\ntspan = (0.0, 10.0)\n\n# LV equation parameter. p = [α, β, δ, γ]\npguess = [1.0, 1.2, 2.5, 1.2]\n\n# Set up the ODE problem with our guessed parameter values\nprob = ODEProblem(lotka_volterra!, u0, tspan, pguess)\n\n# Solve the ODE problem with our guessed parameter values\ninitial_sol = solve(prob, saveat = 1)\n\n# View the guessed model solution\nplt = plot(initial_sol, label = [\"x Prediction\" \"y Prediction\"])\nscatter!(plt, t_data, xy_data', label = [\"x Data\" \"y Data\"])\n\n# Define a loss metric function to be minimized\nfunction loss(newp)\n    newprob = remake(prob, p = newp)\n    sol = solve(newprob, saveat = 1)\n    loss = sum(abs2, sol .- xy_data)\n    return loss\nend\n\n# Define a callback function to monitor optimization progress\nfunction callback(state, l)\n    display(l)\n    newprob = remake(prob, p = state.u)\n    sol = solve(newprob, saveat = 1)\n    plt = plot(sol, ylim = (0, 6), label = [\"Current x Prediction\" \"Current y Prediction\"])\n    scatter!(plt, t_data, xy_data', label = [\"x Data\" \"y Data\"])\n    display(plt)\n    return false\nend\n\n# Set up the optimization problem with our loss function and initial guess\nadtype = AutoForwardDiff()\npguess = [1.0, 1.2, 2.5, 1.2]\noptf = OptimizationFunction((x, _) -> loss(x), adtype)\noptprob = OptimizationProblem(optf, pguess)\n\n# Optimize the ODE parameters for best fit to our data\npfinal = solve(optprob, PolyOpt(),\n    callback = callback,\n    maxiters = 200)\nα, β, γ, δ = round.(pfinal, digits = 1)","category":"page"},{"location":"getting_started/fit_simulation/#Step-by-Step-Solution","page":"Fit a simulation to a dataset","title":"Step-by-Step Solution","text":"","category":"section"},{"location":"getting_started/fit_simulation/#Step-1:-Install-and-Import-the-Required-Packages","page":"Fit a simulation to a dataset","title":"Step 1: Install and Import the Required Packages","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"To do this tutorial, we will need a few components. This is done using the Julia Pkg REPL:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"using Pkg\nPkg.add([\n    \"DifferentialEquations\",\n    \"Optimization\",\n    \"OptimizationPolyalgorithms\",\n    \"SciMLSensitivity\",\n    \"ForwardDiff\",\n    \"Plots\"\n])","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now we're ready. Let's load in these packages:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"using DifferentialEquations, Optimization, OptimizationPolyalgorithms, SciMLSensitivity\nusing ForwardDiff, Plots","category":"page"},{"location":"getting_started/fit_simulation/#Step-2:-View-the-Training-Data","page":"Fit a simulation to a dataset","title":"Step 2: View the Training Data","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"In our example, we are given observed values for x and y populations at eleven instances in time. Let's make that the training data for our Lotka-Volterra dynamical system model.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"# Define experimental data\nt_data = 0:10\nx_data = [1.000 2.773 6.773 0.971 1.886 6.101 1.398 1.335 4.353 3.247 1.034]\ny_data = [1.000 0.259 2.015 1.908 0.323 0.629 3.458 0.508 0.314 4.547 0.906]\nxy_data = vcat(x_data, y_data)\n\n# Plot the provided data\nscatter(t_data, xy_data', label = [\"x Data\" \"y Data\"])","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"note: Note\nThe Array xy_data above has been oriented with time instances as columns so that it can be directly compared with an ODESolution object. (See Solution Handling for more information on accessing DifferentialEquation.jl solution data.) However, plotting an Array with Plots.jl requires the variables to be columns and the time instances to be rows. Thus, whenever the experimental data is plotted, the transpose xy_data' will be used.","category":"page"},{"location":"getting_started/fit_simulation/#Step-3:-Set-Up-the-ODE-Model","page":"Fit a simulation to a dataset","title":"Step 3: Set Up the ODE Model","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"We know that our system will behave according to the Lotka-Volterra ODE model, so let's set up that model with an initial guess at the parameter values: \\alpha, \\beta, \\gamma, and \\delta. Unlike the first tutorial, which used ModelingToolkit, let's demonstrate using DifferentialEquations.jl to directly define the ODE for the numerical solvers.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"To do this, we define a vector-based mutating function that calculates the derivatives for our system. We will define our system as a vector u = [x,y], and thus u[1] = x and u[2] = y. This means that we need to calculate the derivative as du = [dx,dy]. Our parameters will simply be the vector p = [α, β, δ, γ]. Writing down the Lotka-Volterra equations in the DifferentialEquations.jl direct form thus looks like the following:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"function lotka_volterra!(du, u, p, t)\n    x, y = u\n    α, β, δ, γ = p\n    du[1] = dx = α * x - β * x * y\n    du[2] = dy = -δ * y + γ * x * y\nend","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now we need to define the initial condition, time span, and parameter vector in order to solve this differential equation. We do not currently know the parameter values, but we will guess some values to start with and optimize them later. Following the problem setup, this looks like:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"# Initial condition\nu0 = [1.0, 1.0]\n\n# Simulation interval\ntspan = (0.0, 10.0)\n\n# LV equation parameter. p = [α, β, δ, γ]\npguess = [1.0, 1.2, 2.5, 1.2]","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now we bring these pieces all together to define the ODEProblem and solve it. Note that we solve this equation with the keyword argument saveat = 1 so that it saves a point at every Delta t = 1 to match our experimental data.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"# Set up the ODE problem with our guessed parameter values\nprob = ODEProblem(lotka_volterra!, u0, tspan, pguess)\n\n# Solve the ODE problem with our guessed parameter values\ninitial_sol = solve(prob, saveat = 1)\n\n# View the guessed model solution\nplt = plot(initial_sol, label = [\"x Prediction\" \"y Prediction\"])\nscatter!(plt, t_data, xy_data', label = [\"x Data\" \"y Data\"])","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Clearly the parameter values that we guessed are not correct to model this system.\nHowever, we can use Optimization.jl together with DifferentialEquations.jl\nto fit our parameters to our training data.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"note: Note\nFor more details on using DifferentialEquations.jl, check out the getting started with DifferentialEquations.jl tutorial.","category":"page"},{"location":"getting_started/fit_simulation/#Step-4:-Set-Up-the-Loss-Function-for-Optimization","page":"Fit a simulation to a dataset","title":"Step 4: Set Up the Loss Function for Optimization","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now let's start the optimization process. First, let's define a loss function to be minimized. (It is also sometimes referred to as a cost function.) For our loss function, we want to take a set of parameters, create a new ODE which has everything the same except for the changed parameters, solve this ODE with new parameters, and compare the ODE solution against the provided data. In this case, the loss returned from the loss function is a quantification of the difference between the current solution and the desired solution. When this difference is minimized, our model prediction will closely approximate the observed system data.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"To change our parameter values, there is a useful functionality in the SciML problems interface called remake which creates a new version of an existing SciMLProblem with the aspect you want changed. For example, if we wanted to change the initial condition u0 of our ODE, we could do remake(prob, u0 = newu0) For our case, we want to change around just the parameters, so we can do remake(prob, p = newp). It is faster to remake an existing SciMLProblem than to create a new problem every iteration.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"note: Note\nremake can change multiple items at once by passing more keyword arguments, i.e., remake(prob, u0 = newu0, p = newp). This can be used to extend the example to simultaneously learn the initial conditions and parameters!","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now use remake to build the loss function. After we solve the new problem, we will calculate the sum of squared errors as our loss metric. The sum of squares can be quickly written in Julia via sum(abs2,x). Using this information, our loss function looks like:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"function loss(newp)\n    newprob = remake(prob, p = newp)\n    sol = solve(newprob, saveat = 1)\n    l = sum(abs2, sol .- xy_data)\n    return l\nend","category":"page"},{"location":"getting_started/fit_simulation/#Step-5:-Solve-the-Optimization-Problem","page":"Fit a simulation to a dataset","title":"Step 5: Solve the Optimization Problem","text":"","category":"section"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"This step will look very similar to the first optimization tutorial, The Optimization.solve function can accept an optional callback function to monitor the optimization process using extra arguments returned from loss.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"The callback syntax is always:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"callback(\n    state,\n    the current loss value,\n)","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"In this case, we will provide the callback the arguments (state, l), since it always takes the current state of the optimization first (state) then the current loss value (l). The return value of the callback function should default to false. Optimization.solve will halt if/when the callback function returns true instead. Typically the return statement would monitor the loss value and stop once some criteria is reached, e.g. return loss < 0.0001, but we will stop after a set number of iterations instead. More details about callbacks in Optimization.jl can be found here.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"function callback(state, l)\n    display(l)\n    newprob = remake(prob, p = state.u)\n    sol = solve(newprob, saveat = 1)\n    plt = plot(sol, ylim = (0, 6), label = [\"Current x Prediction\" \"Current y Prediction\"])\n    scatter!(plt, t_data, xy_data', label = [\"x Data\" \"y Data\"])\n    display(plt)\n    return false\nend","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"With this callback function, every step of the optimization will display both the loss value and a plot of how the solution compares to the training data. Since we want to track the fit visually we plot the simulation at each iteration and compare it to the data. This is expensive since it requires an extra solve call and a plotting step for each iteration.","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Now, just like the first optimization tutorial, we set up our OptimizationFunction and OptimizationProblem, and then solve the OptimizationProblem. We will initialize the OptimizationProblem with the same pguess we used when setting up the ODE Model in Step 3. Observe how Optimization.solve brings the model closer to the experimental data as it iterates towards better ODE parameter values!","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"Note that we are using the PolyOpt() solver choice here which is discussed https://docs.sciml.ai/Optimization/dev/optimization_packages/polyopt/ since parameter estimation of non-linear differential equations is generally a non-convex problem so we want to run a stochastic algorithm (Adam) to get close to the minimum and then finish off with a quasi-newton method (L-BFGS) to find the optima. Together, this looks like:","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"# Set up the optimization problem with our loss function and initial guess\nadtype = AutoForwardDiff()\npguess = [1.0, 1.2, 2.5, 1.2]\noptf = OptimizationFunction((x, _) -> loss(x), adtype)\noptprob = OptimizationProblem(optf, pguess)\n\n# Optimize the ODE parameters for best fit to our data\npfinal = solve(optprob,\n    PolyOpt(),\n    callback = callback,\n    maxiters = 200)\nα, β, γ, δ = round.(pfinal, digits = 1)","category":"page"},{"location":"getting_started/fit_simulation/","page":"Fit a simulation to a dataset","title":"Fit a simulation to a dataset","text":"note: Note\nWhen referencing the documentation for DifferentialEquations.jl and Optimization.jl simultaneously, note that the variables f, u, and p will refer to different quantities.DifferentialEquations.jl:fracdudt = f(upt)f in ODEProblem is the function defining the derivative du in the ODE.\nHere: lotka_volterra!\nu in ODEProblem contains the state variables of f.\nHere: x and y\np in ODEProblem contains the parameter variables of f.\nHere: \\alpha, \\beta, \\gamma, and \\delta\nt is the independent (time) variable.\nHere: indirectly defined with tspan in ODEProblem and saveat in solveOptimization.jl:min_u f(up)f in OptimizationProblem is the function to minimize (optimize).\nHere: the anonymous function (x, _) -> loss(x)\nu in OptimizationProblem contains the state variables of f to be optimized.\nHere: the ODE parameters \\alpha, \\beta, \\gamma, and \\delta stored in p\np in OptimizationProblem contains any fixed hyperparameters of f.\nHere: our loss function does not require any hyperparameters, so we pass _ for this p.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#Partial-Differential-Equations-(PDE)","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/#NeuralPDE.jl:-Physics-Informed-Neural-Network-(PINN)-PDE-Solvers","page":"Partial Differential Equations (PDE)","title":"NeuralPDE.jl: Physics-Informed Neural Network (PINN) PDE Solvers","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"NeuralPDE.jl is a partial differential equation solver library which uses physics-informed neural networks (PINNs) to solve the equations. It uses the ModelingToolkit.jl symbolic PDESystem as its input and can handle a wide variety of equation types, including systems of partial differential equations, partial differential-algebraic equations, and integro-differential equations. Its benefit is its flexibility, and it can be used to easily generate surrogate solutions over entire parameter ranges. However, its downside is solver speed: PINN solvers tend to be a lot slower than other methods for solving PDEs.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#MethodOflines.jl:-Automated-Finite-Difference-Method-(FDM)","page":"Partial Differential Equations (PDE)","title":"MethodOflines.jl: Automated Finite Difference Method (FDM)","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"MethodOflines.jl is a partial differential equation solver library which automates the discretization of PDEs via the finite difference method. It uses the ModelingToolkit.jl symbolic PDESystem as its input, and generates AbstractSystems and SciMLProblems whose numerical solution gives the solution to the PDE.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#FEniCS.jl:-Wrappers-for-the-Finite-Element-Method-(FEM)","page":"Partial Differential Equations (PDE)","title":"FEniCS.jl: Wrappers for the Finite Element Method (FEM)","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"FEniCS.jl is a wrapper for the popular FEniCS finite element method library.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#HighDimPDE.jl:-High-dimensional-PDE-Solvers","page":"Partial Differential Equations (PDE)","title":"HighDimPDE.jl:  High-dimensional PDE Solvers","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"HighDimPDE.jl is a partial differential equation solver library which implements algorithms that break down the curse of dimensionality to solve the equations. It implements deep-learning based and Picard-iteration based methods to approximately solve high-dimensional, nonlinear, non-local PDEs in up to 10,000 dimensions. Its cons are accuracy: high-dimensional solvers are stochastic, and might result in wrong solutions if the solver meta-parameters are not appropriate.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#NeuralOperators.jl:-(Fourier)-Neural-Operators-and-DeepONets-for-PDE-Solving","page":"Partial Differential Equations (PDE)","title":"NeuralOperators.jl: (Fourier) Neural Operators and DeepONets for PDE Solving","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"NeuralOperators.jl is a library for operator learning based PDE solvers. This includes techniques like:","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"Fourier Neural Operators (FNO)\nDeep Operator Networks (DeepONets)\nMarkov Neural Operators (MNO)","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"Currently, its connection to PDE solving must be specified manually, though an interface for ModelingToolkit PDESystems is in progress.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#DiffEqOperators.jl:-Operators-for-Finite-Difference-Method-(FDM)-Discretizations","page":"Partial Differential Equations (PDE)","title":"DiffEqOperators.jl: Operators for Finite Difference Method (FDM) Discretizations","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"DiffEqOperators.jl is a library for defining finite difference operators to easily perform manual FDM semi-discretizations of partial differential equations. This library is fairly incomplete and most cases should receive better performance using MethodOflines.jl.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#Third-Party-Libraries-to-Note","page":"Partial Differential Equations (PDE)","title":"Third-Party Libraries to Note","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"A more exhaustive list of Julia PDE packages can be found here: https://github.com/JuliaPDE/SurveyofPDEPackages","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#ApproxFun.jl:-Automated-Spectral-Discretizations","page":"Partial Differential Equations (PDE)","title":"ApproxFun.jl: Automated Spectral Discretizations","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"ApproxFun.jl is a package for approximating functions in basis sets. One particular use case is with spectral basis sets, such as Chebyshev functions and Fourier decompositions, making it easy to represent spectral and pseudospectral discretizations of partial differential equations as ordinary differential equations for the SciML equation solvers.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#Ferrite.jl:-Finite-Element-Toolbox-for-Julia","page":"Partial Differential Equations (PDE)","title":"Ferrite.jl: Finite Element Toolbox for Julia","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"Ferrite.jl is a performant and extensible library which provides algorithms and data structures to develop finite element software. This library aims at users which need fine grained control over all algorithmic details, as for example often necessary in research when developing new grid-based PDE discretizations or other more advanced problem formulations for example found in continuum mechanics.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#Gridap.jl:-Julia-Based-Tools-for-Finite-Element-Discretizations","page":"Partial Differential Equations (PDE)","title":"Gridap.jl: Julia-Based Tools for Finite Element Discretizations","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"Gridap.jl is a package for grid-based approximation of partial differential equations, particularly notable for its use of conforming and nonconforming finite element (FEM) discretizations.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#Trixi.jl:-Adaptive-High-Order-Numerical-Simulations-of-Hyperbolic-Equations","page":"Partial Differential Equations (PDE)","title":"Trixi.jl: Adaptive High-Order Numerical Simulations of Hyperbolic Equations","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"Trixi.jl is a package for numerical simulation of hyperbolic conservation laws, i.e. a large set of hyperbolic partial differential equations, which interfaces and uses the SciML ordinary differential equation solvers.","category":"page"},{"location":"highlevels/partial_differential_equation_solvers/#VoronoiFVM.jl:-Tools-for-the-Voronoi-Finite-Volume-Discretizations","page":"Partial Differential Equations (PDE)","title":"VoronoiFVM.jl: Tools for the Voronoi Finite Volume Discretizations","text":"","category":"section"},{"location":"highlevels/partial_differential_equation_solvers/","page":"Partial Differential Equations (PDE)","title":"Partial Differential Equations (PDE)","text":"VoronoiFVM.jl is a library for generating FVM discretizations of systems of PDEs. It interfaces with many of the SciML equation solver libraries to allow for ease of discretization and flexibility in the solver choice.","category":"page"},{"location":"showcase/gpu_spde/#gpuspde","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Let's solve stochastic PDEs in Julia using GPU parallelism. To do this, we will use the type-genericness of the DifferentialEquations.jl library in order to write a code that uses within-method GPU-parallelism on the system of PDEs. The OrdinaryDiffEq.jl solvers of DifferentialEquations.jl, including implicit solvers with GMRES, etc., and the same for SDEs, DAEs, DDEs, etc. are all GPU-compatible with a fast form of broadcast.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"note: Note\nThe non-native Julia solvers, like Sundials are incompatible with arbitrary input types and thus not compatible with GPUs.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Let's dive into showing how to accelerate ODE solving with GPUs!","category":"page"},{"location":"showcase/gpu_spde/#Before-we-start:-the-two-ways-to-accelerate-ODE-solvers-with-GPUs","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Before we start: the two ways to accelerate ODE solvers with GPUs","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Before we dive deeper, let us remark that there are two very different ways that one can accelerate an ODE solution with GPUs. There is one case where u is very big and f is very expensive, but very structured, and you use GPUs to accelerate the computation of said f. The other use case is where u is very small but you want to solve the ODE f over many different initial conditions (u0) or parameters p. In that case, you can use GPUs to parallelize over different parameters and initial conditions. In other words:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Type of Problem SciML Solution\nAccelerate a big ODE Use CUDA.jl's CuArray as u0\nSolve the same ODE with many u0 and p Use DiffEqGPU.jl's EnsembleGPUArray and EnsembleGPUKernel","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"This showcase will focus on the former case. For the latter, see the massively parallel GPU ODE solving showcase.","category":"page"},{"location":"showcase/gpu_spde/#Our-Problem:-2-dimensional-Reaction-Diffusion-Equations","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Our Problem: 2-dimensional Reaction-Diffusion Equations","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"The reaction-diffusion equation is a PDE commonly handled in systems biology, which is a diffusion equation plus a nonlinear reaction term. The dynamics are defined as:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"u_t = D Delta u + f(tu)","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"But this doesn't need to only have a single “reactant” u: this can be a vector of reactants and the f is then the nonlinear vector equations describing how these different pieces react together. Let's settle on a specific equation to make this easier to explain. Let's use a simple model of a 3-component system where A can diffuse through space to bind with the non-diffusive B to form the complex C (also non-diffusive, assume B is too big and gets stuck in a cell which causes C=A+B to be stuck as well). Other than the binding, we make each of these undergo a simple birth-death process, and we write down the equations which result from mass-action kinetics. If this all is meaningless to you, just understand that it gives the system of PDEs:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"beginalign\nA_t = D Delta A + alpha_A(x) - beta_A  A - r_1 A B + r_2 C\nB_t = alpha_B - beta_B B - r_1 A B + r_2 C\nC_t = alpha_C - beta_C C + r_1 A B - r_2 C\nendalign","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"One addition that was made to the model is that we let alpha_A(x) be the production of A, and we let that be a function of space so that way it only is produced on one side of our equation. Let's make it a constant when x>80, and 0 otherwise, and let our spatial domain be x in 0100 and y in 0100.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"This model is spatial: each reactant u(txy) is defined at each point in space, and all of the reactions are local, meaning that f at spatial point (xy) only uses u_i(txy). This is an important fact which will come up later for parallelization.","category":"page"},{"location":"showcase/gpu_spde/#Discretizing-the-PDE-into-ODEs","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Discretizing the PDE into ODEs","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"In order to solve this via a method of lines (MOL) approach, we need to discretize the PDE into a system of ODEs. Let's do a simple uniformly-spaced grid finite difference discretization. Choose dx = 1 and dy = 1 so that we have 100*100=10000 points for each reactant. Notice how fast that grows! Put the reactants in a matrix such that A[i,j] = A(x_j,y_i), i.e. the columns of the matrix are the x values and the rows are the y values (this way looking at the matrix is essentially like looking at the discretized space).","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"So now we have 3 matrices (A, B, and C) for our reactants. How do we discretize the PDE? In this case, the diffusion term simply becomes a tridiagonal matrix M where 1-21 is the central band. You can notice that MA performs diffusion along the columns of A, and so this is diffusion along the y. Similarly, AM flips the indices and thus does diffusion along the rows of A making this diffusion along x. Thus D(M_yA + AM_x) is the discretized Laplacian (we could have separate diffusion constants and dx neq dy if we want by using different constants on the M, but let's not do that for this simple example. We leave that as an exercise for the reader). We enforced a Neumann boundary condition with zero derivative (also known as a no-flux boundary condition) by reflecting the changes over the boundary. Thus the derivative operator is generated as:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"using LinearAlgebra\n\n# Define the constants for the PDE\nconst α₂ = 1.0\nconst α₃ = 1.0\nconst β₁ = 1.0\nconst β₂ = 1.0\nconst β₃ = 1.0\nconst r₁ = 1.0\nconst r₂ = 1.0\nconst D = 100.0\nconst γ₁ = 0.1\nconst γ₂ = 0.1\nconst γ₃ = 0.1\nconst N = 100\nconst X = reshape([i for i in 1:100 for j in 1:100], N, N)\nconst Y = reshape([j for i in 1:100 for j in 1:100], N, N)\nconst α₁ = 1.0 .* (X .>= 80)\n\nconst Mx = Tridiagonal([1.0 for i in 1:(N - 1)], [-2.0 for i in 1:N],\n    [1.0 for i in 1:(N - 1)])\nconst My = copy(Mx)\n# Do the reflections, different for x and y operators\nMx[2, 1] = 2.0\nMx[end - 1, end] = 2.0\nMy[1, 2] = 2.0\nMy[end, end - 1] = 2.0","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"note: Note\nWe could have also done these discretization steps using DiffEqOperators.jl or MethodOfLines.jl. However, we are going to keep it in this form, so we can show the full code, making it easier to see how to define GPU-ready code!","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Since all of the reactions are local, we only have each point in space react separately. Thus this represents itself as element-wise equations on the reactants. Thus we can write it out quite simply. The ODE which then represents the PDE is thus in pseudo Julia code:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"DA = D * (Mx * A + A * My)\n@. DA + α₁ - β₁ * A - r₁ * A * B + r₂ * C\n@. α₂ - β₂ * B - r₁ * A * B + r₂ * C\n@. α₃ - β₃ * C + r₁ * A * B - r₂ * C","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Note here that I am using α₁ as a matrix (or row-vector, since that will broadcast just fine) where every point in space with x<80 has this zero, and all of the others have it as a constant. The other coefficients are all scalars.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"How do we do this with the ODE solver?","category":"page"},{"location":"showcase/gpu_spde/#Our-Representation-via-Views-of-3-Tensors","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Our Representation via Views of 3-Tensors","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"We can represent our problem with a 3-dimensional tensor, taking each 2-dimensional slice as our (A,B,C). This means that we can define:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"u0 = zeros(N, N, 3);","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Now we can decompose it like:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"A = @view u[:, :, 1]\nB = @view u[:, :, 2]\nC = @view u[:, :, 3]\ndA = @view du[:, :, 1]\ndB = @view du[:, :, 2]\ndC = @view du[:, :, 3]","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"These views will not construct new arrays and will instead just be pointers to the (contiguous) memory pieces, so this is a nice and efficient way to handle this. Together, our ODE using this tensor as its container can be written as follows:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"function f(du, u, p, t)\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    DA = D * (Mx * A + A * My)\n    @. dA = DA + α₁ - β₁ * A - r₁ * A * B + r₂ * C\n    @. dB = α₂ - β₂ * B - r₁ * A * B + r₂ * C\n    @. dC = α₃ - β₃ * C + r₁ * A * B - r₂ * C\nend","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"where this is using @. to do inplace updates on our du to say how the full tensor should update in time. Note that we can make this more efficient by adding some cache variables to the diffusion matrix multiplications and using mul!, but let's ignore that for now.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Together, the ODE which defines our PDE is thus:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"using DifferentialEquations\n\nprob = ODEProblem(f, u0, (0.0, 100.0))\n@time sol = solve(prob, ROCK2());","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"@time sol = solve(prob, ROCK2());","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"if I want to solve it on t in 0100. Done! The solution gives back our tensors (and interpolates to create new ones if you use sol(t)). We can plot it in Plots.jl:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"using Plots\np1 = surface(X, Y, sol[end][:, :, 1], title = \"[A]\")\np2 = surface(X, Y, sol[end][:, :, 2], title = \"[B]\")\np3 = surface(X, Y, sol[end][:, :, 3], title = \"[C]\")\nplot(p1, p2, p3, layout = grid(3, 1))","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"and see the pretty gradients. Using this 2nd order ROCK method we solve this equation in about 2 seconds. That's okay.","category":"page"},{"location":"showcase/gpu_spde/#Some-Optimizations","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Some Optimizations","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"There are some optimizations that can still be done. When we do A*B as matrix multiplication, we create another temporary matrix. These allocations can bog down the system. Instead, we can pre-allocate the outputs and use the inplace functions mul! to make better use of memory. The easiest way to store these cache arrays are constant globals, but you can use closures (anonymous functions which capture data, i.e. (x)->f(x,y)) or call-overloaded types to do it without globals. The globals way (the easy way) is simply:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"const MyA = zeros(N, N)\nconst AMx = zeros(N, N)\nconst DA = zeros(N, N)\nfunction f(du, u, p, t)\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    mul!(MyA, My, A)\n    mul!(AMx, A, Mx)\n    @. DA = D * (MyA + AMx)\n    @. dA = DA + α₁ - β₁ * A - r₁ * A * B + r₂ * C\n    @. dB = α₂ - β₂ * B - r₁ * A * B + r₂ * C\n    @. dC = α₃ - β₃ * C + r₁ * A * B - r₂ * C\nend","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"For reference, closures looks like:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"MyA = zeros(N, N)\nAMx = zeros(N, N)\nDA = zeros(N, N)\nfunction f_full(du, u, p, t, MyA, AMx, DA)\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    mul!(MyA, My, A)\n    mul!(AMx, A, Mx)\n    @. DA = D * (MyA + AMx)\n    @. dA = DA + α₁ - β₁ * A - r₁ * A * B + r₂ * C\n    @. dB = α₂ - β₂ * B - r₁ * A * B + r₂ * C\n    @. dC = α₃ - β₃ * C + r₁ * A * B - r₂ * C\nend\nf(du, u, p, t) = f_full(du, u, p, t, MyA, AMx, DA)","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"and a call overloaded type looks like:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"struct MyFunction{T} <: Function\n    MyA::T\n    AMx::T\n    DA::T\nend\n\n# Now define the overload\nfunction (ff::MyFunction)(du, u, p, t)\n    # This is a function which references itself via ff\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    mul!(ff.MyA, My, A)\n    mul!(ff.AMx, A, Mx)\n    @. ff.DA = D * (ff.MyA + ff.AMx)\n    @. dA = f.DA + α₁ - β₁ * A - r₁ * A * B + r₂ * C\n    @. dB = α₂ - β₂ * B - r₁ * A * B + r₂ * C\n    @. dC = α₃ - β₃ * C + r₁ * A * B - r₂ * C\nend\n\nMyA = zeros(N, N)\nAMx = zeros(N, N)\nDA = zeros(N, N)\n\nf = MyFunction(MyA, AMx, DA)\n# Now f(du,u,p,t) is our function!","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"These last two ways enclose the pointer to our cache arrays locally but still present a function f(du,u,p,t) to the ODE solver.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Now, since PDEs are large, many times we don't care about getting the whole timeseries. Using the output controls from DifferentialEquations.jl, we can make it only output the final timepoint.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"prob = ODEProblem(f, u0, (0.0, 100.0))\n@time sol = solve(prob, ROCK2(), progress = true, save_everystep = false,\n    save_start = false);\n@time sol = solve(prob, ROCK2(), progress = true, save_everystep = false,\n    save_start = false);","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Around 0.4 seconds. Much better. Also, if you're using VS Code, this'll give you a nice progress bar, so you can track how it's going.","category":"page"},{"location":"showcase/gpu_spde/#Quick-Note-About-Performance","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Quick Note About Performance","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"note: Note\nWe are using the ROCK2 method here because it's a method for stiff equations with eigenvalues that are real-dominated (as opposed to dominated by the imaginary parts). If we wanted to use a more conventional implicit ODE solver, we would need to make use of the sparsity pattern. This is covered in the advanced ODE tutorial It turns out that ROCK2 is more efficient anyway (and doesn't require sparsity handling), so we will keep this setup.","category":"page"},{"location":"showcase/gpu_spde/#Quick-Summary:-full-PDE-ODE-Code","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Quick Summary: full PDE ODE Code","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"As a summary, here's a full PDE code:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"using OrdinaryDiffEq, LinearAlgebra\n\n# Define the constants for the PDE\nconst α₂ = 1.0\nconst α₃ = 1.0\nconst β₁ = 1.0\nconst β₂ = 1.0\nconst β₃ = 1.0\nconst r₁ = 1.0\nconst r₂ = 1.0\nconst D = 100.0\nconst γ₁ = 0.1\nconst γ₂ = 0.1\nconst γ₃ = 0.1\nconst N = 100\nconst X = reshape([i for i in 1:100 for j in 1:100], N, N)\nconst Y = reshape([j for i in 1:100 for j in 1:100], N, N)\nconst α₁ = 1.0 .* (X .>= 80)\n\nconst Mx = Array(Tridiagonal([1.0 for i in 1:(N - 1)], [-2.0 for i in 1:N],\n    [1.0 for i in 1:(N - 1)]))\nconst My = copy(Mx)\nMx[2, 1] = 2.0\nMx[end - 1, end] = 2.0\nMy[1, 2] = 2.0\nMy[end, end - 1] = 2.0\n\n# Define the initial condition as normal arrays\nu0 = zeros(N, N, 3)\n\nconst MyA = zeros(N, N);\nconst AMx = zeros(N, N);\nconst DA = zeros(N, N)\n# Define the discretized PDE as an ODE function\nfunction f(du, u, p, t)\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    mul!(MyA, My, A)\n    mul!(AMx, A, Mx)\n    @. DA = D * (MyA + AMx)\n    @. dA = DA + α₁ - β₁ * A - r₁ * A * B + r₂ * C\n    @. dB = α₂ - β₂ * B - r₁ * A * B + r₂ * C\n    @. dC = α₃ - β₃ * C + r₁ * A * B - r₂ * C\nend\n\n# Solve the ODE\nprob = ODEProblem(f, u0, (0.0, 100.0))\nsol = solve(prob, ROCK2(), progress = true, save_everystep = false, save_start = false)\n\nusing Plots;\ngr();\np1 = surface(X, Y, sol[end][:, :, 1], title = \"[A]\")\np2 = surface(X, Y, sol[end][:, :, 2], title = \"[B]\")\np3 = surface(X, Y, sol[end][:, :, 3], title = \"[C]\")\nplot(p1, p2, p3, layout = grid(3, 1))","category":"page"},{"location":"showcase/gpu_spde/#Making-Use-of-GPU-Parallelism","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"Making Use of GPU Parallelism","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"That was all using the CPU. How do we turn on GPU parallelism with DifferentialEquations.jl? Well, you don't. DifferentialEquations.jl \"doesn't have GPU bits\". So, wait... can we not do GPU parallelism? No, this is the glory of type-genericness, especially in broadcasted operations. To make things use the GPU, we simply use a CuArray from CUDA.jl. If instead of zeros(N,M) we used CuArray(zeros(N,M)), then the array lives on the GPU. CuArray naturally overrides broadcast such that dotted operations are performed on the GPU. DifferentialEquations.jl uses broadcast internally, and thus just by putting the array as a CuArray, the array-type will take over how all internal updates are performed and turn this algorithm into a fully GPU-parallelized algorithm that doesn't require copying to the CPU. Wasn't that simple?","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"From that you can probably also see how to multithread everything, or how to set everything up with distributed parallelism. You can make the ODE solvers do whatever you want by defining an array type where the broadcast does whatever special behavior you want.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"So to recap, the entire difference from above is changing to:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"using CUDA\nconst gMx = CuArray(Float32.(Mx))\nconst gMy = CuArray(Float32.(My))\nconst gα₁ = CuArray(Float32.(α₁))\ngu0 = CuArray(Float32.(u0))\n\nconst gMyA = CuArray(zeros(Float32, N, N))\nconst AgMx = CuArray(zeros(Float32, N, N))\nconst gDA = CuArray(zeros(Float32, N, N))\nfunction gf(du, u, p, t)\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    mul!(gMyA, gMy, A)\n    mul!(AgMx, A, gMx)\n    @. gDA = D * (gMyA + AgMx)\n    @. dA = gDA + gα₁ - β₁ * A - r₁ * A * B + r₂ * C\n    @. dB = α₂ - β₂ * B - r₁ * A * B + r₂ * C\n    @. dC = α₃ - β₃ * C + r₁ * A * B - r₂ * C\nend\n\nprob2 = ODEProblem(gf, gu0, (0.0, 100.0))\nCUDA.allowscalar(false) # makes sure none of the slow fallbacks are used\n@time sol = solve(prob2, ROCK2(), progress = true, dt = 0.003, save_everystep = false,\n    save_start = false);","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"@time sol = solve(prob2, ROCK2(), progress = true, dt = 0.003, save_everystep = false,\n    save_start = false);","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Go have fun.","category":"page"},{"location":"showcase/gpu_spde/#And-Stochastic-PDEs?","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"And Stochastic PDEs?","text":"","category":"section"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Why not make it an SPDE? All that we need to do is extend each of the PDE equations to have a noise function. In this case, let's use multiplicative noise on each reactant. This means that our noise update equation is:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"function g(du, u, p, t)\n    A = @view u[:, :, 1]\n    B = @view u[:, :, 2]\n    C = @view u[:, :, 3]\n    dA = @view du[:, :, 1]\n    dB = @view du[:, :, 2]\n    dC = @view du[:, :, 3]\n    @. dA = γ₁ * A\n    @. dB = γ₂ * A\n    @. dC = γ₃ * A\nend","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"Now we just define and solve the system of SDEs:","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"prob = SDEProblem(f, g, u0, (0.0, 100.0))\n@time sol = solve(prob, SRIW1());","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"using Plots;\ngr();\n\n# Use `Array` to transform the result back into a CPU-based `Array` for plotting\np1 = surface(X, Y, Array(sol[end][:, :, 1]), title = \"[A]\")\np2 = surface(X, Y, Array(sol[end][:, :, 2]), title = \"[B]\")\np3 = surface(X, Y, Array(sol[end][:, :, 3]), title = \"[C]\")\nplot(p1, p2, p3, layout = grid(3, 1))","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"We can see the cool effect that diffusion dampens the noise in [A] but is unable to dampen the noise in [B] which results in a very noisy [C]. The stiff SPDE takes much longer to solve even using high order plus adaptivity because stochastic problems are just that much more difficult (current research topic is to make new algorithms for this!). It gets GPU'd just by using CuArray like before. But there we go: solving systems of stochastic PDEs using high order adaptive algorithms with within-method GPU parallelism. That's gotta be a first? The cool thing is that nobody ever had to implement the GPU-parallelism either, it just exists by virtue of the Julia type system.","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"(Note: We can also use one of the SROCK methods for better performance here, but they will require a choice of dt. This is left to the reader to try.)","category":"page"},{"location":"showcase/gpu_spde/","page":"GPU-Accelerated Stochastic Partial Differential Equations","title":"GPU-Accelerated Stochastic Partial Differential Equations","text":"note: Note\nThis can take a while to solve! An explicit Runge-Kutta algorithm isn't necessarily great here, though to use a stiff solver on a problem of this size requires once again smartly choosing sparse linear solvers. The high order adaptive method is pretty much necessary though, since something like Euler-Maruyama is simply not stable enough to solve this at a reasonable dt. Also, the current algorithms are not so great at handling this problem. Good thing there's a publication coming along with some new stuff...","category":"page"},{"location":"showcase/bayesian_neural_ode/#bnode","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"In this tutorial, we show how SciML can combine the differential equation solvers seamlessly with Bayesian estimation libraries like AdvancedHMC.jl and Turing.jl. This enables converting Neural ODEs to Bayesian Neural ODEs, which enables us to estimate the error in the Neural ODE estimation and forecasting. In this tutorial, a working example of the Bayesian Neural ODE: NUTS sampler is shown.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"note: Note\nFor more details, have a look at this paper: https://arxiv.org/abs/2012.07244","category":"page"},{"location":"showcase/bayesian_neural_ode/#Step-1:-Import-Libraries","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Step 1: Import Libraries","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"For this example, we will need the following libraries:","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"# SciML Libraries\nusing SciMLSensitivity, DifferentialEquations\n\n# ML Tools\nusing Lux, Zygote\n\n# External Tools\nusing Random, Plots, AdvancedHMC, MCMCChains, StatsPlots, ComponentArrays","category":"page"},{"location":"showcase/bayesian_neural_ode/#Setup:-Get-the-data-from-the-Spiral-ODE-example","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Setup: Get the data from the Spiral ODE example","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"We will also need data to fit against. As a demonstration, we will generate our data using a simple cubic ODE u' = A*u^3 as follows:","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"u0 = [2.0; 0.0]\ndatasize = 40\ntspan = (0.0, 1)\ntsteps = range(tspan[1], tspan[2], length = datasize)\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"We will want to train a neural network to capture the dynamics that fit ode_data.","category":"page"},{"location":"showcase/bayesian_neural_ode/#Step-2:-Define-the-Neural-ODE-architecture.","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Step 2: Define the Neural ODE architecture.","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"Note that this step potentially offers a lot of flexibility in the number of layers/ number of units in each layer. It may not necessarily be true that a 100 units architecture is better at prediction/forecasting than a 50 unit architecture. On the other hand, a complicated architecture can take a huge computational time without increasing performance.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"dudt2 = Lux.Chain(x -> x .^ 3,\n    Lux.Dense(2, 50, tanh),\n    Lux.Dense(50, 2))\n\nrng = Random.default_rng()\np, st = Lux.setup(rng, dudt2)\nconst _st = st\nfunction neuralodefunc(u, p, t)\n    dudt2(u, p, _st)[1]\nend\nfunction prob_neuralode(u0, p)\n    prob = ODEProblem(neuralodefunc, u0, tspan, p)\n    sol = solve(prob, Tsit5(), saveat = tsteps)\nend\np = ComponentArray{Float64}(p)\nconst _p = p","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"Note that the f64 is required to put the Lux neural network into Float64 precision.","category":"page"},{"location":"showcase/bayesian_neural_ode/#Step-3:-Define-the-loss-function-for-the-Neural-ODE.","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Step 3: Define the loss function for the Neural ODE.","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"function predict_neuralode(p)\n    p = p isa ComponentArray ? p : convert(typeof(_p), p)\n    Array(prob_neuralode(u0, p))\nend\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend","category":"page"},{"location":"showcase/bayesian_neural_ode/#Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Step 4: Now we start integrating the Bayesian estimation workflow as prescribed by the AdvancedHMC interface with the NeuralODE defined above","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"The AdvancedHMC interface requires us to specify: (a) the Hamiltonian log density and its gradient , (b) the sampler and (c) the step size adaptor function.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"For the Hamiltonian log density, we use the loss function. The θ*θ term denotes the use of Gaussian priors.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"The user can make several modifications to Step 4. The user can try different acceptance ratios, warmup samples and posterior samples. One can also use the Variational Inference (ADVI) framework, which doesn't work quite as well as NUTS. The SGLD (Stochastic Gradient Langevin Descent) sampler is seen to have a better performance than NUTS. Have a look at https://sebastiancallh.github.io/post/langevin/ for a brief introduction to SGLD.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"l(θ) = -sum(abs2, ode_data .- predict_neuralode(θ)) - sum(θ .* θ)\nfunction dldθ(θ)\n    x, lambda = Zygote.pullback(l, θ)\n    grad = first(lambda(1))\n    return x, grad\nend\n\nmetric = DiagEuclideanMetric(length(p))\nh = Hamiltonian(metric, l, dldθ)","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"We use the NUTS sampler with an acceptance ratio of δ= 0.45 in this example. In addition, we use Nesterov Dual Averaging for the Step Size adaptation.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"We sample using 500 warmup samples and 500 posterior samples.","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"integrator = Leapfrog(find_good_stepsize(h, p))\nkernel = HMCKernel(Trajectory{MultinomialTS}(integrator, GeneralisedNoUTurn()))\nadaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(0.45, integrator))\nsamples, stats = sample(h, kernel, p, 500, adaptor, 500; progress = true)","category":"page"},{"location":"showcase/bayesian_neural_ode/#Step-5:-Plot-diagnostics","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Step 5: Plot diagnostics","text":"","category":"section"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"Now let's make sure the fit is good. This can be done by looking at the chain mixing plot and the autocorrelation plot. First, let's create the chain mixing plot using the plot recipes from ????","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"samples = hcat(samples...)\nsamples_reduced = samples[1:5, :]\nsamples_reshape = reshape(samples_reduced, (500, 5, 1))\nChain_Spiral = Chains(samples_reshape)\nplot(Chain_Spiral)","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"Now we check the autocorrelation plot:","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"autocorplot(Chain_Spiral)","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"As another diagnostic, let's check the result on retrodicted data. To do this, we generate solutions of the Neural ODE on samples of the neural network parameters, and check the results of the predictions against the data. Let's start by looking at the time series:","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"pl = scatter(tsteps, ode_data[1, :], color = :red, label = \"Data: Var1\", xlabel = \"t\",\n    title = \"Spiral Neural ODE\")\nscatter!(tsteps, ode_data[2, :], color = :blue, label = \"Data: Var2\")\nfor k in 1:300\n    resol = predict_neuralode(samples[:, 100:end][:, rand(1:400)])\n    plot!(tsteps, resol[1, :], alpha = 0.04, color = :red, label = \"\")\n    plot!(tsteps, resol[2, :], alpha = 0.04, color = :blue, label = \"\")\nend\n\nlosses = map(x -> loss_neuralode(x)[1], eachcol(samples))\nidx = findmin(losses)[2]\nprediction = predict_neuralode(samples[:, idx])\nplot!(tsteps, prediction[1, :], color = :black, w = 2, label = \"\")\nplot!(tsteps, prediction[2, :], color = :black, w = 2, label = \"Best fit prediction\",\n    ylims = (-2.5, 3.5))","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"That showed the time series form. We can similarly do a phase-space plot:","category":"page"},{"location":"showcase/bayesian_neural_ode/","page":"Uncertainty Quantified Deep Bayesian Model Discovery","title":"Uncertainty Quantified Deep Bayesian Model Discovery","text":"pl = scatter(ode_data[1, :], ode_data[2, :], color = :red, label = \"Data\", xlabel = \"Var1\",\n    ylabel = \"Var2\", title = \"Spiral Neural ODE\")\nfor k in 1:300\n    resol = predict_neuralode(samples[:, 100:end][:, rand(1:400)])\n    plot!(resol[1, :], resol[2, :], alpha = 0.04, color = :red, label = \"\")\nend\nplot!(prediction[1, :], prediction[2, :], color = :black, w = 2,\n    label = \"Best fit prediction\", ylims = (-2.5, 3))","category":"page"},{"location":"overview/#overview","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"","category":"section"},{"location":"overview/#SciML:-Combining-High-Performance-Scientific-Computing-and-Machine-Learning","page":"Detailed Overview of the SciML Software Ecosystem","title":"SciML: Combining High-Performance Scientific Computing and Machine Learning","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"SciML is not standard machine learning, SciML is the combination of scientific computing techniques with machine learning. Thus the SciML organization is not an organization for machine learning libraries (see FluxML for machine learning in Julia), rather SciML is an organization dedicated to the development of scientific computing tools which work seamlessly in conjunction with next-generation machine learning workflows. This includes:","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"High-performance and accurate tools for standard scientific computing modeling and simulation\nCompatibility with differentiable programming and automatic differentiation\nTools for building complex multiscale models\nMethods for handling inverse problems, model calibration, controls, and Bayesian analysis\nSymbolic modeling tools for generating efficient code for numerical equation solvers\nMethods for automatic discovery of (bio)physical equations","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"and much more. For an overview of the broad goals of the SciML organization, watch:","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"The Use and Practice of Scientific Machine Learning\nState of SciML Scientific Machine Learning","category":"page"},{"location":"overview/#Overview-of-Computational-Science-in-Julia-with-SciML","page":"Detailed Overview of the SciML Software Ecosystem","title":"Overview of Computational Science in Julia with SciML","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"Below is a simplification of the user-facing packages for use in scientific computing and SciML workflows.","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"Workflow Element SciML-Supported Julia packages\nPlotting and Visualization Plots*, Makie*\nSparse matrix SparseArrays*\nInterpolation/approximation DataInterpolations*, ApproxFun*\nLinear system / least squares LinearSolve\nNonlinear system / rootfinding NonlinearSolve\nPolynomial roots Polynomials*\nIntegration Integrals\nNonlinear Optimization Optimization\nOther Optimization (linear, quadratic, convex, etc.) JuMP*\nInitial-value problem DifferentialEquations\nBoundary-value problem DifferentialEquations\nContinuous-Time Markov Chains (Poisson Jumps), Jump Diffusions JumpProcesses\nFinite differences FiniteDifferences*, FiniteDiff*\nAutomatic Differentiation ForwardDiff*, Enzyme*, DiffEqSensitivity\nBayesian Modeling Turing*\nDeep Learning Flux*\nAcausal Modeling / DAEs ModelingToolkit\nChemical Reaction Networks Catalyst\nSymbolic Computing Symbolics\nFast Fourier Transform FFTW*\nPartial Differential Equation Discretizations Associated Julia packages\n–- –-\nFinite Differences MethodOfLines\nDiscontinuous Galerkin Trixi*\nFinite Element Gridap*\nPhysics-Informed Neural Networks NeuralPDE\nNeural Operators NeuralOperators\nHigh Dimensional Deep Learning HighDimPDE","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"* Denotes a non-SciML package that is heavily tested against as part of SciML workflows and has frequent collaboration with the SciML developers.","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"(Image: SciML Mind Map)","category":"page"},{"location":"overview/#Domains-of-SciML","page":"Detailed Overview of the SciML Software Ecosystem","title":"Domains of SciML","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"The SciML common interface covers the following domains:","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"Linear systems (LinearProblem)\nDirect methods for dense and sparse\nIterative solvers with preconditioning\nNonlinear Systems (NonlinearProblem)\nSystems of nonlinear equations\nScalar bracketing systems\nIntegrals (quadrature) (IntegralProblem)\nDifferential Equations\nDiscrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem and JumpProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (DEProblems with callbacks and JumpProblem)\nOptimization (OptimizationProblem)\nNonlinear (constrained) optimization\n(Stochastic/Delay/Differential-Algebraic) Partial Differential Equations (PDESystem)\nFinite difference and finite volume methods\nInterfaces to finite element methods\nPhysics-Informed Neural Networks (PINNs)\nIntegro-Differential Equations\nFractional Differential Equations\nSpecialized Forms\nPartial Integro-Differential Equations (PIPDEProblem)\nData-driven modeling\nDiscrete-time data-driven dynamical systems (DiscreteDataDrivenProblem)\nContinuous-time data-driven dynamical systems (ContinuousDataDrivenProblem)\nSymbolic regression (DirectDataDrivenProblem)\nUncertainty quantification and expected values (ExpectationProblem)","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"The SciML common interface also includes ModelingToolkit.jl for defining such systems symbolically, allowing for optimizations like automated generation of parallel code, symbolic simplification, and generation of sparsity patterns.","category":"page"},{"location":"overview/#Inverse-Problems,-Parameter-Estimation,-and-Structural-Identification","page":"Detailed Overview of the SciML Software Ecosystem","title":"Inverse Problems, Parameter Estimation, and Structural Identification","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"Parameter estimation and inverse problems are solved directly on their constituent problem types using tools like SciMLSensitivity.jl. Thus for example, there is no ODEInverseProblem, and instead ODEProblem is used to find the parameters p that solve the inverse problem. Check out the SciMLSensitivity documentation for a discussion on connections to automatic differentiation, optimization, and adjoints.","category":"page"},{"location":"overview/#Common-Interface-High-Level-Overview","page":"Detailed Overview of the SciML Software Ecosystem","title":"Common Interface High-Level Overview","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"The SciML interface is common as the usage of arguments is standardized across all of the problem domains. Underlying high-level ideas include:","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"All domains use the same interface of defining a AbstractSciMLProblem which is then solved via solve(prob,alg;kwargs), where alg is a AbstractSciMLAlgorithm. The keyword argument namings are standardized across the organization.\nAbstractSciMLProblems are generally defined by a AbstractSciMLFunction which can define extra details about a model function, such as its analytical Jacobian, its sparsity patterns and so on.\nThere is an organization-wide method for defining linear and nonlinear solvers used within other solvers, giving maximum control of performance to the user.\nTypes used within the packages are defined by the input types. For example, packages attempt to internally use the type of the initial condition as the type for the state within differential equation solvers.\nsolve calls should be thread-safe and parallel-safe.\ninit(prob,alg;kwargs) returns an iterator which allows for directly iterating over the solution process\nHigh performance is key. Any performance that is not at the top level is considered a bug and should be reported as such.\nAll functions have an in-place and out-of-place form, where the in-place form is made to utilize mutation for high performance on large-scale problems and the out-of-place form is for compatibility with tooling like static arrays and some reverse-mode automatic differentiation systems.","category":"page"},{"location":"overview/#Flowchart-Example-for-PDE-Constrained-Optimal-Control","page":"Detailed Overview of the SciML Software Ecosystem","title":"Flowchart Example for PDE-Constrained Optimal Control","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"The following example showcases how the pieces of the common interface connect to solve a problem that mixes inference, symbolics, and numerics.","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"(Image: )","category":"page"},{"location":"overview/#External-Binding-Libraries","page":"Detailed Overview of the SciML Software Ecosystem","title":"External Binding Libraries","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"diffeqr\nSolving differential equations in R using DifferentialEquations.jl with ModelingToolkit for JIT compilation and GPU-acceleration\ndiffeqpy\nSolving differential equations in Python using DifferentialEquations.jl","category":"page"},{"location":"overview/#Note-About-Third-Party-Libraries","page":"Detailed Overview of the SciML Software Ecosystem","title":"Note About Third-Party Libraries","text":"","category":"section"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"The SciML documentation references and recommends many third-party libraries for improving ones modeling, simulation, and analysis workflow in Julia. Take these as a positive affirmation of the quality of these libraries, as these libraries are commonly tested by SciML developers who are in contact with the development teams of these groups. It also documents the libraries which are commonly chosen by SciML as dependencies. Do not take omissions as negative affirmations against a given library, i.e. a library left off of the list by SciML is not a negative endorsement. Rather, it means that compatibility with SciML is untested, SciML developers may have a personal preference for another choice, or SciML developers may be simply unaware of the library's existence. If one would like to add a third-party library to the SciML documentation, open a pull request with the requested text.","category":"page"},{"location":"overview/","page":"Detailed Overview of the SciML Software Ecosystem","title":"Detailed Overview of the SciML Software Ecosystem","text":"Note that the libraries in this documentation are only those that are meant to be used in the SciML extended universe of modeling, simulation, and analysis and thus there are many high-quality libraries in other domains (machine learning, data science, etc.) which are purposefully not included. For an overview of the Julia package ecosystem, see the JuliaHub Search Engine.","category":"page"},{"location":"highlevels/symbolic_tools/#Symbolic-Model-Tooling-and-JuliaSymbolics","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolic Model Tooling and JuliaSymbolics","text":"","category":"section"},{"location":"highlevels/symbolic_tools/","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolic Model Tooling and JuliaSymbolics","text":"JuliaSymbolics is a sister organization of SciML. It spawned out of the symbolic modeling tools being developed within SciML (ModelingToolkit.jl) to become its own organization dedicated to building a fully-featured Julia-based Computer Algebra System (CAS). As such, the two organizations are closely aligned in terms of its developer community, and many of the SciML libraries use Symbolics.jl extensively.","category":"page"},{"location":"highlevels/symbolic_tools/#ModelOrderReduction.jl:-Automated-Model-Reduction-for-Fast-Approximations-of-Solutions","page":"Symbolic Model Tooling and JuliaSymbolics","title":"ModelOrderReduction.jl: Automated Model Reduction for Fast Approximations of Solutions","text":"","category":"section"},{"location":"highlevels/symbolic_tools/","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolic Model Tooling and JuliaSymbolics","text":"ModelOrderReduction.jl is a package for automating the reduction of models. These methods function a submodel with a projection, where solving the smaller model provides approximation information about the full model. MOR.jl uses ModelingToolkit.jl as a system description and automatically transforms equations to the subform, defining the observables to automatically lazily reconstruct the full model on-demand in a fast and stable form.","category":"page"},{"location":"highlevels/symbolic_tools/#Symbolics.jl:-The-Computer-Algebra-System-(CAS)-of-the-Julia-Programming-Language","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolics.jl: The Computer Algebra System (CAS) of the Julia Programming Language","text":"","category":"section"},{"location":"highlevels/symbolic_tools/","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolic Model Tooling and JuliaSymbolics","text":"Symbolics.jl is the CAS of the Julia programming language. If something needs to be done symbolically, most likely Symbolics.jl is the answer.","category":"page"},{"location":"highlevels/symbolic_tools/#MetaTheory.jl:-E-Graphs-to-Automate-Symbolic-Transformations","page":"Symbolic Model Tooling and JuliaSymbolics","title":"MetaTheory.jl: E-Graphs to Automate Symbolic Transformations","text":"","category":"section"},{"location":"highlevels/symbolic_tools/","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolic Model Tooling and JuliaSymbolics","text":"Metatheory.jl is a library for defining e-graph rewriters for use on the common symbolic interface. This can be used to do all sorts of analysis and code transformations, such as improving code performance, numerical stability, and more. See Automated Code Optimization with E-Graphs for more details.","category":"page"},{"location":"highlevels/symbolic_tools/#SymbolicUtils.jl:-Define-Your-Own-Computer-Algebra-System","page":"Symbolic Model Tooling and JuliaSymbolics","title":"SymbolicUtils.jl: Define Your Own Computer Algebra System","text":"","category":"section"},{"location":"highlevels/symbolic_tools/","page":"Symbolic Model Tooling and JuliaSymbolics","title":"Symbolic Model Tooling and JuliaSymbolics","text":"SymbolicUtils.jl is the underlying utility library and rule-based rewriting language on which Symbolics.jl is developed. Symbolics.jl is standardized type and rule definitions built using SymbolicUtils.jl. However, if non-standard types are required, such as symbolic computing over Fock algebras, then SymbolicUtils.jl is the library from which the new symbolic types can be implemented.","category":"page"},{"location":"#SciML:-Differentiable-Modeling-and-Simulation-Combined-with-Machine-Learning","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Differentiable Modeling and Simulation Combined with Machine Learning","text":"","category":"section"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"The SciML organization is a collection of tools for solving equations and modeling systems developed in the Julia programming language with bindings to other languages such as R and Python. The organization provides well-maintained tools which compose together as a coherent ecosystem. It has a coherent development principle, unified APIs over large collections of equation solvers, pervasive differentiability and sensitivity analysis, and features many of the highest performance and parallel implementations one can find.","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"Scientific Machine Learning (SciML) = Scientific Computing + Machine Learning","category":"page"},{"location":"#Where-to-Start?","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"Where to Start?","text":"","category":"section"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"Want to get started running some code? Check out the Getting Started tutorials.\nWhat is SciML? Check out our Overview.\nWant to see some cool end-to-end examples? Check out the SciML Showcase.\nCurious about our performance claims? Check out the SciML Open Benchmarks.\nWant to learn more about how SciML does scientific machine learning? Check out the SciML Book (from MIT's 18.337 graduate course).\nWant to chat with someone? Check out our chat room and forums.\nWant to see our code? Check out the SciML GitHub organization.","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"And for diving into the details, use the bar on the top to navigate to the submodule of interest!","category":"page"},{"location":"#Reproducibility","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"<details><summary>The documentation of the <a href=\"showcase/showcase/#showcase\">SciML Showcase</a> was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"</details>","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"</details>","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"</details>","category":"page"},{"location":"","page":"SciML: Open Source Software for Scientific Machine Learning with Julia","title":"SciML: Open Source Software for Scientific Machine Learning with Julia","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"}]
}
