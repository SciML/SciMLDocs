<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Fit a simulation to a dataset · Overview of Julia&#39;s SciML</title><meta name="title" content="Fit a simulation to a dataset · Overview of Julia&#39;s SciML"/><meta property="og:title" content="Fit a simulation to a dataset · Overview of Julia&#39;s SciML"/><meta property="twitter:title" content="Fit a simulation to a dataset · Overview of Julia&#39;s SciML"/><meta name="description" content="Documentation for Overview of Julia&#39;s SciML."/><meta property="og:description" content="Documentation for Overview of Julia&#39;s SciML."/><meta property="twitter:description" content="Documentation for Overview of Julia&#39;s SciML."/><meta property="og:url" content="https://docs.sciml.ai/stable/getting_started/fit_simulation/"/><meta property="twitter:url" content="https://docs.sciml.ai/stable/getting_started/fit_simulation/"/><link rel="canonical" href="https://docs.sciml.ai/stable/getting_started/fit_simulation/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Overview of Julia&#39;s SciML logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Overview of Julia&#39;s SciML</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">SciML: Open Source Software for Scientific Machine Learning with Julia</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../getting_started/">Getting Started with Julia&#39;s SciML</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox" checked/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">New User Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../installation/">Installing SciML Software</a></li><li><a class="tocitem" href="../first_simulation/">Build and run your first simulation with Julia&#39;s SciML</a></li><li><a class="tocitem" href="../first_optimization/">Solve your first optimization problem</a></li><li class="is-active"><a class="tocitem" href>Fit a simulation to a dataset</a><ul class="internal"><li><a class="tocitem" href="#Required-Dependencies"><span>Required Dependencies</span></a></li><li><a class="tocitem" href="#Problem-Setup:-Fitting-Lotka-Volterra-Data"><span>Problem Setup: Fitting Lotka-Volterra Data</span></a></li><li><a class="tocitem" href="#Solution-as-Copy-Pastable-Code"><span>Solution as Copy-Pastable Code</span></a></li><li><a class="tocitem" href="#Step-by-Step-Solution"><span>Step-by-Step Solution</span></a></li></ul></li><li><a class="tocitem" href="../find_root/">Find the root of an equation (i.e. solve f(u)=0)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Comparison With Other Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../comparisons/python/">Getting Started with Julia&#39;s SciML for the Python User</a></li><li><a class="tocitem" href="../../comparisons/matlab/">Getting Started with  Julia&#39;s SciML for the MATLAB User</a></li><li><a class="tocitem" href="../../comparisons/r/">Getting Started with Julia&#39;s SciML for the R User</a></li><li><a class="tocitem" href="../../comparisons/cppfortran/">Getting Started with Julia&#39;s SciML for the C++/Fortran User</a></li></ul></li></ul></li><li><span class="tocitem">Showcase of Cool Examples</span><ul><li><a class="tocitem" href="../../showcase/showcase/">The SciML Showcase</a></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Automated Model Discovery</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../showcase/missing_physics/">Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations</a></li><li><a class="tocitem" href="../../showcase/bayesian_neural_ode/">Uncertainty Quantified Deep Bayesian Model Discovery</a></li><li><a class="tocitem" href="../../showcase/optimal_data_gathering_for_missing_physics/">Optimal Data Gathering for Missing Physics</a></li><li><a class="tocitem" href="../../showcase/blackhole/">Discovering the Relativistic Corrections to Binary Black Hole Dynamics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Solving Difficult Equations Efficiently</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../showcase/brusselator/">Automated Efficient Solution of Nonlinear Partial Differential Equations</a></li><li><a class="tocitem" href="../../showcase/pinngpu/">GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers</a></li><li><a class="tocitem" href="../../showcase/massively_parallel_gpu/">Massively Data-Parallel ODE Solving on GPUs</a></li><li><a class="tocitem" href="../../showcase/gpu_spde/">GPU-Accelerated Stochastic Partial Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Useful Cool Wonky Things</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../showcase/ode_types/">Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia&#39;s Type System</a></li><li><a class="tocitem" href="../../showcase/symbolic_analysis/">Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability</a></li><li><a class="tocitem" href="../../showcase/optimization_under_uncertainty/">Optimization Under Uncertainty</a></li></ul></li></ul></li><li><span class="tocitem">What is SciML?</span><ul><li><a class="tocitem" href="../../overview/">Detailed Overview of the SciML Software Ecosystem</a></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Solvers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/equation_solvers/">Equation Solvers</a></li><li><a class="tocitem" href="../../highlevels/inverse_problems/">Parameter Estimation, Bayesian Analysis, and Inverse Problems</a></li><li><a class="tocitem" href="../../highlevels/partial_differential_equation_solvers/">Partial Differential Equations (PDE)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Modeling Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/modeling_languages/">Modeling Languages</a></li><li><a class="tocitem" href="../../highlevels/model_libraries_and_importers/">Model Libraries and Importers</a></li><li><a class="tocitem" href="../../highlevels/symbolic_tools/">Symbolic Model Tooling and JuliaSymbolics</a></li><li><a class="tocitem" href="../../highlevels/array_libraries/">Modeling Array Libraries</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Simulation Analysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/parameter_analysis/">Parameter Analysis Utilities</a></li><li><a class="tocitem" href="../../highlevels/uncertainty_quantification/">Uncertainty Quantification</a></li><li><a class="tocitem" href="../../highlevels/plots_visualization/">SciML-Supported Plotting and Visualization Libraries</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Machine Learning</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/function_approximation/">Function Approximation</a></li><li><a class="tocitem" href="../../highlevels/implicit_layers/">Implicit Layer Deep Learning</a></li><li><a class="tocitem" href="../../highlevels/symbolic_learning/">Symbolic Learning and Artificial Intelligence</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-6" type="checkbox"/><label class="tocitem" for="menuitem-4-6"><span class="docs-label">Developer Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/numerical_utilities/">SciML Numerical Utility Libraries</a></li><li><a class="tocitem" href="../../highlevels/interfaces/">The SciML Interface Libraries</a></li><li><a class="tocitem" href="../../highlevels/developer_documentation/">Developer Documentation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-7" type="checkbox"/><label class="tocitem" for="menuitem-4-7"><span class="docs-label">Extra Learning Resources</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/learning_resources/">Curated Learning, Teaching, and Training Resources</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Getting Started</a></li><li><a class="is-disabled">New User Tutorials</a></li><li class="is-active"><a href>Fit a simulation to a dataset</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Fit a simulation to a dataset</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/SciMLDocs" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/SciMLDocs/blob/main/docs/src/getting_started/fit_simulation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="fit_simulation"><a class="docs-heading-anchor" href="#fit_simulation">Fit a simulation to a dataset</a><a id="fit_simulation-1"></a><a class="docs-heading-anchor-permalink" href="#fit_simulation" title="Permalink"></a></h1><p>Running simulations is only half of the battle. Many times, in order to make the simulation realistic, you need to fit the simulation to data. The SciML ecosystem has <strong>integration with automatic differentiation and adjoint methods</strong> to automatically make the fitting process stable and efficient. Let&#39;s see this in action.</p><h2 id="Required-Dependencies"><a class="docs-heading-anchor" href="#Required-Dependencies">Required Dependencies</a><a id="Required-Dependencies-1"></a><a class="docs-heading-anchor-permalink" href="#Required-Dependencies" title="Permalink"></a></h2><p>The following parts of the SciML Ecosystem will be used in this tutorial:</p><table><tr><th style="text-align: left">Module</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left"><a href="https://docs.sciml.ai/DiffEqDocs/stable/">DifferentialEquations.jl</a></td><td style="text-align: left">The differential equation solvers</td></tr><tr><td style="text-align: left"><a href="https://docs.sciml.ai/Optimization/stable/">Optimization.jl</a></td><td style="text-align: left">The numerical optimization package</td></tr><tr><td style="text-align: left"><a href="https://github.com/SciML/Optimization.jl/blob/master/lib/OptimizationPolyalgorithms/src/OptimizationPolyalgorithms.jl">OptimizationPolyalgorithms.jl</a></td><td style="text-align: left">The optimizers we will use</td></tr><tr><td style="text-align: left"><a href="https://docs.sciml.ai/SciMLSensitivity/dev/">SciMLSensitivity.jl</a></td><td style="text-align: left">The connection of the SciML ecosystems to differentiation</td></tr></table><p>Along with the following general ecosystem packages:</p><table><tr><th style="text-align: left">Module</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left"><a href="https://docs.juliaplots.org/stable/">Plots.jl</a></td><td style="text-align: left">The plotting and visualization package</td></tr><tr><td style="text-align: left"><a href="https://juliadiff.org/ForwardDiff.jl/stable/">ForwardDiff.jl</a></td><td style="text-align: left">The automatic differentiation package</td></tr></table><h2 id="Problem-Setup:-Fitting-Lotka-Volterra-Data"><a class="docs-heading-anchor" href="#Problem-Setup:-Fitting-Lotka-Volterra-Data">Problem Setup: Fitting Lotka-Volterra Data</a><a id="Problem-Setup:-Fitting-Lotka-Volterra-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Problem-Setup:-Fitting-Lotka-Volterra-Data" title="Permalink"></a></h2><p>Assume that we know that the dynamics of our system are given by the <a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations">Lotka-Volterra dynamical system</a>: Let <span>$x(t)$</span> be the number of rabbits in the environment and <span>$y(t)$</span> be the number of wolves. This is the same dynamical system as <a href="../first_simulation/#first_sim">the first tutorial!</a> The equation that defines the evolution of the species is given as follows:</p><p class="math-container">\[\begin{align}
\frac{dx}{dt} &amp;= \alpha x - \beta x y\\
\frac{dy}{dt} &amp;= -\gamma y + \delta x y
\end{align}\]</p><p>where <span>$\alpha, \beta, \gamma, \delta$</span> are parameters. Starting from equal numbers of rabbits and wolves, <span>$x(0) = 1$</span> and <span>$y(0) = 1$</span>.</p><p>Now, in <a href="../first_simulation/#first_sim">the first tutorial</a>, we assumed:</p><blockquote><p>Luckily, a local guide provided us with some parameters that seem to match the system!</p></blockquote><p>Sadly, magical nymphs do not always show up and give us parameters. Thus in this case, we will need to use Optimization.jl to optimize the model parameters to best fit some experimental data. We are given experimentally observed data of both rabbit and wolf populations over a time span of <span>$t_0 = 0$</span> to <span>$t_f = 10$</span> at every <span>$\Delta t = 1$</span>. Can we figure out what the parameter values should be directly from the data?</p><h2 id="Solution-as-Copy-Pastable-Code"><a class="docs-heading-anchor" href="#Solution-as-Copy-Pastable-Code">Solution as Copy-Pastable Code</a><a id="Solution-as-Copy-Pastable-Code-1"></a><a class="docs-heading-anchor-permalink" href="#Solution-as-Copy-Pastable-Code" title="Permalink"></a></h2><pre><code class="language-julia hljs">using DifferentialEquations, Optimization, OptimizationPolyalgorithms, SciMLSensitivity
using ForwardDiff, Plots

# Define experimental data
t_data = 0:10
x_data = [1.000 2.773 6.773 0.971 1.886 6.101 1.398 1.335 4.353 3.247 1.034]
y_data = [1.000 0.259 2.015 1.908 0.323 0.629 3.458 0.508 0.314 4.547 0.906]
xy_data = vcat(x_data, y_data)

# Plot the provided data
scatter(t_data, xy_data&#39;, label = [&quot;x Data&quot; &quot;y Data&quot;])

# Setup the ODE function
function lotka_volterra!(du, u, p, t)
    x, y = u
    α, β, δ, γ = p
    du[1] = dx = α * x - β * x * y
    du[2] = dy = -δ * y + γ * x * y
end

# Initial condition
u0 = [1.0, 1.0]

# Simulation interval
tspan = (0.0, 10.0)

# LV equation parameter. p = [α, β, δ, γ]
pguess = [1.0, 1.2, 2.5, 1.2]

# Set up the ODE problem with our guessed parameter values
prob = ODEProblem(lotka_volterra!, u0, tspan, pguess)

# Solve the ODE problem with our guessed parameter values
initial_sol = solve(prob, saveat = 1)

# View the guessed model solution
plt = plot(initial_sol, label = [&quot;x Prediction&quot; &quot;y Prediction&quot;])
scatter!(plt, t_data, xy_data&#39;, label = [&quot;x Data&quot; &quot;y Data&quot;])

# Define a loss metric function to be minimized
function loss(newp)
    newprob = remake(prob, p = newp)
    sol = solve(newprob, saveat = 1)
    loss = sum(abs2, sol .- xy_data)
    return loss
end

# Define a callback function to monitor optimization progress
function callback(state, l)
    display(l)
    newprob = remake(prob, p = state.u)
    sol = solve(newprob, saveat = 1)
    plt = plot(sol, ylim = (0, 6), label = [&quot;Current x Prediction&quot; &quot;Current y Prediction&quot;])
    scatter!(plt, t_data, xy_data&#39;, label = [&quot;x Data&quot; &quot;y Data&quot;])
    display(plt)
    return false
end

# Set up the optimization problem with our loss function and initial guess
adtype = AutoForwardDiff()
pguess = [1.0, 1.2, 2.5, 1.2]
optf = OptimizationFunction((x, _) -&gt; loss(x), adtype)
optprob = OptimizationProblem(optf, pguess)

# Optimize the ODE parameters for best fit to our data
pfinal = solve(optprob, PolyOpt(),
    callback = callback,
    maxiters = 200)
α, β, γ, δ = round.(pfinal, digits = 1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 1.5
 1.0
 3.0
 1.0</code></pre><h2 id="Step-by-Step-Solution"><a class="docs-heading-anchor" href="#Step-by-Step-Solution">Step-by-Step Solution</a><a id="Step-by-Step-Solution-1"></a><a class="docs-heading-anchor-permalink" href="#Step-by-Step-Solution" title="Permalink"></a></h2><h3 id="Step-1:-Install-and-Import-the-Required-Packages"><a class="docs-heading-anchor" href="#Step-1:-Install-and-Import-the-Required-Packages">Step 1: Install and Import the Required Packages</a><a id="Step-1:-Install-and-Import-the-Required-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Install-and-Import-the-Required-Packages" title="Permalink"></a></h3><p>To do this tutorial, we will need a few components. This is done using the Julia Pkg REPL:</p><pre><code class="language-julia hljs">using Pkg
Pkg.add([
    &quot;DifferentialEquations&quot;,
    &quot;Optimization&quot;,
    &quot;OptimizationPolyalgorithms&quot;,
    &quot;SciMLSensitivity&quot;,
    &quot;ForwardDiff&quot;,
    &quot;Plots&quot;
])</code></pre><p>Now we&#39;re ready. Let&#39;s load in these packages:</p><pre><code class="language-julia hljs">using DifferentialEquations, Optimization, OptimizationPolyalgorithms, SciMLSensitivity
using ForwardDiff, Plots</code></pre><h3 id="Step-2:-View-the-Training-Data"><a class="docs-heading-anchor" href="#Step-2:-View-the-Training-Data">Step 2: View the Training Data</a><a id="Step-2:-View-the-Training-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-View-the-Training-Data" title="Permalink"></a></h3><p>In our example, we are given observed values for <code>x</code> and <code>y</code> populations at eleven instances in time. Let&#39;s make that the training data for our Lotka-Volterra dynamical system model.</p><pre><code class="language-julia hljs"># Define experimental data
t_data = 0:10
x_data = [1.000 2.773 6.773 0.971 1.886 6.101 1.398 1.335 4.353 3.247 1.034]
y_data = [1.000 0.259 2.015 1.908 0.323 0.629 3.458 0.508 0.314 4.547 0.906]
xy_data = vcat(x_data, y_data)

# Plot the provided data
scatter(t_data, xy_data&#39;, label = [&quot;x Data&quot; &quot;y Data&quot;])</code></pre><img src="537c719c.svg" alt="Example block output"/><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <code>Array</code> <code>xy_data</code> above has been oriented with time instances as columns so that it can be directly compared with an <code>ODESolution</code> object. (See <a href="https://docs.sciml.ai/DiffEqDocs/stable/basics/solution/#solution">Solution Handling</a> for more information on accessing DifferentialEquation.jl solution data.) However, plotting an <code>Array</code> with Plots.jl requires the variables to be columns and the time instances to be rows. Thus, whenever the experimental data is plotted, the transpose <code>xy_data&#39;</code> will be used.</p></div></div><h3 id="Step-3:-Set-Up-the-ODE-Model"><a class="docs-heading-anchor" href="#Step-3:-Set-Up-the-ODE-Model">Step 3: Set Up the ODE Model</a><a id="Step-3:-Set-Up-the-ODE-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Set-Up-the-ODE-Model" title="Permalink"></a></h3><p>We know that our system will behave according to the Lotka-Volterra ODE model, so let&#39;s set up that model with an initial guess at the parameter values: <code>\alpha</code>, <code>\beta</code>, <code>\gamma</code>, and <code>\delta</code>. Unlike <a href="../first_simulation/#first_sim">the first tutorial</a>, which used ModelingToolkit, let&#39;s demonstrate using <a href="https://docs.sciml.ai/DiffEqDocs/stable/">DifferentialEquations.jl</a> to directly define the ODE for the numerical solvers.</p><p>To do this, we define a vector-based mutating function that calculates the derivatives for our system. We will define our system as a vector <code>u = [x,y]</code>, and thus <code>u[1] = x</code> and <code>u[2] = y</code>. This means that we need to calculate the derivative as <code>du = [dx,dy]</code>. Our parameters will simply be the vector <code>p = [α, β, δ, γ]</code>. Writing down the Lotka-Volterra equations in the DifferentialEquations.jl direct form thus looks like the following:</p><pre><code class="language-julia hljs">function lotka_volterra!(du, u, p, t)
    x, y = u
    α, β, δ, γ = p
    du[1] = dx = α * x - β * x * y
    du[2] = dy = -δ * y + γ * x * y
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">lotka_volterra! (generic function with 1 method)</code></pre><p>Now we need to define the initial condition, time span, and parameter vector in order to solve this differential equation. We do not currently know the parameter values, but we will guess some values to start with and optimize them later. Following the problem setup, this looks like:</p><pre><code class="language-julia hljs"># Initial condition
u0 = [1.0, 1.0]

# Simulation interval
tspan = (0.0, 10.0)

# LV equation parameter. p = [α, β, δ, γ]
pguess = [1.0, 1.2, 2.5, 1.2]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 1.0
 1.2
 2.5
 1.2</code></pre><p>Now we bring these pieces all together to define the <code>ODEProblem</code> and solve it. Note that we solve this equation with the keyword argument <code>saveat = 1</code> so that it saves a point at every <span>$\Delta t = 1$</span> to match our experimental data.</p><pre><code class="language-julia hljs"># Set up the ODE problem with our guessed parameter values
prob = ODEProblem(lotka_volterra!, u0, tspan, pguess)

# Solve the ODE problem with our guessed parameter values
initial_sol = solve(prob, saveat = 1)

# View the guessed model solution
plt = plot(initial_sol, label = [&quot;x Prediction&quot; &quot;y Prediction&quot;])
scatter!(plt, t_data, xy_data&#39;, label = [&quot;x Data&quot; &quot;y Data&quot;])</code></pre><img src="7e41dd7e.svg" alt="Example block output"/><pre><code class="nohighlight hljs">Clearly the parameter values that we guessed are not correct to model this system.
However, we can use Optimization.jl together with DifferentialEquations.jl
to fit our parameters to our training data.</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For more details on using DifferentialEquations.jl, check out the <a href="https://docs.sciml.ai/DiffEqDocs/stable/getting_started/">getting started with DifferentialEquations.jl tutorial</a>.</p></div></div><h3 id="Step-4:-Set-Up-the-Loss-Function-for-Optimization"><a class="docs-heading-anchor" href="#Step-4:-Set-Up-the-Loss-Function-for-Optimization">Step 4: Set Up the Loss Function for Optimization</a><a id="Step-4:-Set-Up-the-Loss-Function-for-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Set-Up-the-Loss-Function-for-Optimization" title="Permalink"></a></h3><p>Now let&#39;s start the optimization process. First, let&#39;s define a loss function to be minimized. (It is also sometimes referred to as a cost function.) For our loss function, we want to take a set of parameters, create a new ODE which has everything the same except for the changed parameters, solve this ODE with new parameters, and compare the ODE solution against the provided data. In this case, the <em>loss</em> returned from the loss function is a quantification of the difference between the current solution and the desired solution. When this difference is minimized, our model prediction will closely approximate the observed system data.</p><p>To change our parameter values, there is a useful functionality in the <a href="https://docs.sciml.ai/DiffEqDocs/stable/basics/problem/#Modification-of-problem-types">SciML problems interface</a> called <code>remake</code> which creates a new version of an existing <code>SciMLProblem</code> with the aspect you want changed. For example, if we wanted to change the initial condition <code>u0</code> of our ODE, we could do <code>remake(prob, u0 = newu0)</code> For our case, we want to change around just the parameters, so we can do <code>remake(prob, p = newp)</code>. It is faster to <code>remake</code> an existing <code>SciMLProblem</code> than to create a new problem every iteration.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>remake</code> can change multiple items at once by passing more keyword arguments, i.e., <code>remake(prob, u0 = newu0, p = newp)</code>. This can be used to extend the example to simultaneously learn the initial conditions and parameters!</p></div></div><p>Now use <code>remake</code> to build the loss function. After we solve the new problem, we will calculate the sum of squared errors as our loss metric. The sum of squares can be quickly written in Julia via <code>sum(abs2,x)</code>. Using this information, our loss function looks like:</p><pre><code class="language-julia hljs">function loss(newp)
    newprob = remake(prob, p = newp)
    sol = solve(newprob, saveat = 1)
    l = sum(abs2, sol .- xy_data)
    return l
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">loss (generic function with 1 method)</code></pre><h3 id="Step-5:-Solve-the-Optimization-Problem"><a class="docs-heading-anchor" href="#Step-5:-Solve-the-Optimization-Problem">Step 5: Solve the Optimization Problem</a><a id="Step-5:-Solve-the-Optimization-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#Step-5:-Solve-the-Optimization-Problem" title="Permalink"></a></h3><p>This step will look very similar to <a href="../first_optimization/#first_opt">the first optimization tutorial</a>, The <code>Optimization.solve</code> function can accept an optional callback function to monitor the optimization process using extra arguments returned from <code>loss</code>.</p><p>The callback syntax is always:</p><pre><code class="nohighlight hljs">callback(
    state,
    the current loss value,
)</code></pre><p>In this case, we will provide the callback the arguments <code>(state, l)</code>, since it always takes the current state of the optimization first (<code>state</code>) then the current loss value (<code>l</code>). The return value of the callback function should default to <code>false</code>. <code>Optimization.solve</code> will halt if/when the callback function returns <code>true</code> instead. Typically the <code>return</code> statement would monitor the loss value and stop once some criteria is reached, e.g. <code>return loss &lt; 0.0001</code>, but we will stop after a set number of iterations instead. More details about callbacks in Optimization.jl can be found <a href="https://docs.sciml.ai/Optimization/stable/API/solve/">here</a>.</p><pre><code class="language-julia hljs">function callback(state, l)
    display(l)
    newprob = remake(prob, p = state.u)
    sol = solve(newprob, saveat = 1)
    plt = plot(sol, ylim = (0, 6), label = [&quot;Current x Prediction&quot; &quot;Current y Prediction&quot;])
    scatter!(plt, t_data, xy_data&#39;, label = [&quot;x Data&quot; &quot;y Data&quot;])
    display(plt)
    return false
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">callback (generic function with 1 method)</code></pre><p>With this callback function, every step of the optimization will display both the loss value and a plot of how the solution compares to the training data. Since we want to track the fit visually we plot the simulation at each iteration and compare it to the data. This is expensive since it requires an extra <code>solve</code> call and a plotting step for each iteration.</p><p>Now, just like <a href="../first_optimization/#first_opt">the first optimization tutorial</a>, we set up our <code>OptimizationFunction</code> and <code>OptimizationProblem</code>, and then <code>solve</code> the <code>OptimizationProblem</code>. We will initialize the <code>OptimizationProblem</code> with the same <code>pguess</code> we used when setting up the ODE Model in Step 3. Observe how <code>Optimization.solve</code> brings the model closer to the experimental data as it iterates towards better ODE parameter values!</p><p>Note that we are using the <code>PolyOpt()</code> solver choice here which is discussed https://docs.sciml.ai/Optimization/dev/optimization_packages/polyopt/ since parameter estimation of non-linear differential equations is generally a non-convex problem so we want to run a stochastic algorithm (Adam) to get close to the minimum and then finish off with a quasi-newton method (L-BFGS) to find the optima. Together, this looks like:</p><pre><code class="language-julia hljs"># Set up the optimization problem with our loss function and initial guess
adtype = AutoForwardDiff()
pguess = [1.0, 1.2, 2.5, 1.2]
optf = OptimizationFunction((x, _) -&gt; loss(x), adtype)
optprob = OptimizationProblem(optf, pguess)

# Optimize the ODE parameters for best fit to our data
pfinal = solve(optprob,
    PolyOpt(),
    callback = callback,
    maxiters = 200)
α, β, γ, δ = round.(pfinal, digits = 1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 1.5
 1.0
 3.0
 1.0</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>When referencing the documentation for DifferentialEquations.jl and Optimization.jl simultaneously, note that the variables <code>f</code>, <code>u</code>, and <code>p</code> will refer to different quantities.</p><p>DifferentialEquations.jl:</p><p class="math-container">\[\frac{du}{dt} = f(u,p,t)\]</p><ul><li><p><code>f</code> in <code>ODEProblem</code> is the function defining the derivative <code>du</code> in the ODE.</p><p>Here: <code>lotka_volterra!</code></p></li><li><p><code>u</code> in <code>ODEProblem</code> contains the state variables of <code>f</code>.</p><p>Here: <code>x</code> and <code>y</code></p></li><li><p><code>p</code> in <code>ODEProblem</code> contains the parameter variables of <code>f</code>.</p><p>Here: <code>\alpha</code>, <code>\beta</code>, <code>\gamma</code>, and <code>\delta</code></p></li><li><p><code>t</code> is the independent (time) variable.</p><p>Here: indirectly defined with <code>tspan</code> in <code>ODEProblem</code> and <code>saveat</code> in <code>solve</code></p></li></ul><p>Optimization.jl:</p><p class="math-container">\[\min_{u} f(u,p)\]</p><ul><li><p><code>f</code> in <code>OptimizationProblem</code> is the function to minimize (optimize).</p><p>Here: the <a href="https://docs.julialang.org/en/v1/manual/functions/#man-anonymous-functions">anonymous function</a> <code>(x, _) -&gt; loss(x)</code></p></li><li><p><code>u</code> in <code>OptimizationProblem</code> contains the state variables of <code>f</code> to be optimized.</p><p>Here: the ODE parameters <code>\alpha</code>, <code>\beta</code>, <code>\gamma</code>, and <code>\delta</code> stored in <code>p</code></p></li><li><p><code>p</code> in <code>OptimizationProblem</code> contains any fixed <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</a> of <code>f</code>.</p><p>Here: our <code>loss</code> function does not require any hyperparameters, so we pass <code>_</code> for this <code>p</code>.</p></li></ul></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../first_optimization/">« Solve your first optimization problem</a><a class="docs-footer-nextpage" href="../find_root/">Find the root of an equation (i.e. solve f(u)=0) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Friday 7 March 2025 17:15">Friday 7 March 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
